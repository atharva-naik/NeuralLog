{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "from pqdict import pqdict\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "paraphraseTokenizer = AutoTokenizer.from_pretrained(\"textattack/roberta-base-MRPC\")  \n",
    "paraphraseModel = AutoModelForSequenceClassification.from_pretrained(\"textattack/roberta-base-MRPC\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "classes = [\"not paraphrase\", \"is paraphrase\"]\n",
    "\n",
    "def inference_mrpc(seq1s, seq2s):\n",
    "    for i in range(len(seq1s)):\n",
    "        paraphrase = paraphraseTokenizer.encode_plus(\n",
    "            seq1s[i], seq2s[i], return_tensors=\"pt\")\n",
    "        logits = paraphraseModel(**paraphrase)[0]\n",
    "        paraphrase_results = torch.softmax(logits, dim=1).tolist()[0]\n",
    "        print(f\"{classes[1]}: {round(paraphrase_results[1] * 100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-12-25 23:38:42 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | gum       |\n",
      "| pos       | gum       |\n",
      "| lemma     | gum       |\n",
      "| depparse  | gum       |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2020-12-25 23:38:42 INFO: Use device: cpu\n",
      "2020-12-25 23:38:42 INFO: Loading: tokenize\n",
      "2020-12-25 23:38:42 INFO: Loading: pos\n",
      "2020-12-25 23:38:43 INFO: Loading: lemma\n",
      "2020-12-25 23:38:43 INFO: Loading: depparse\n",
      "2020-12-25 23:38:44 INFO: Loading: sentiment\n",
      "2020-12-25 23:38:45 INFO: Loading: ner\n",
      "2020-12-25 23:38:46 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from Udep2Mono.binarization import BinaryDependencyTree\n",
    "from Udep2Mono.polarization import PolarizationPipeline\n",
    "from Udep2Mono.util import btreeToList\n",
    "from copy import deepcopy\n",
    "\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.structured_prediction\n",
    "\n",
    "ie_extractor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import pluralize, singularize\n",
    "\n",
    "def fix_info(desc):\n",
    "    out = desc.replace(\"ARG0: \", \"\")\n",
    "    out = out.replace(\"ARG1: \", \"\")\n",
    "    out = out.replace(\"V: \", \"\")\n",
    "    out = out.replace(\"[\", \"\")\n",
    "    out = out.replace(\"]\", \",\")\n",
    "    out = out.split(\",\")\n",
    "    out = list(map(lambda x: x.strip(), out))\n",
    "    out = list(map(lambda x: x.split(\" \"), out))\n",
    "    return out\n",
    "\n",
    "# TODO: Verb Phrase Patterns\n",
    "# 1.Intransitive: subject + VI\n",
    "# 2.Linking: subject + VL + NP/AdjP\n",
    "# 3.Transitive: subject + VT + NP\n",
    "# 4.Ditransitive: subject + VD + NP(indirect) + NP(direct)\n",
    "# 5.Complex Transitive: subject + VC + NP(direct) + NP/AdjP\n",
    "# 6.Open clausal complement: VB + to/that VP\n",
    "class PhrasalGenerator:\n",
    "    def __init__(self):\n",
    "        self.deptree = None\n",
    "        self.annotated = None\n",
    "        self.kb = {}\n",
    "        self.tree_log = []\n",
    "        self.sent_log = []\n",
    "        self.mod_at_left = [\n",
    "            \"advmod\", \"amod\", \"advmod:count\", \"acl:relcl\", \n",
    "            \"acl\", \"advcl\", \"xcomp\", \"ccomp\", \"appos\"]\n",
    "        self.mod_at_right = []\n",
    "        \n",
    "        '''\n",
    "            \"ccomp\": self.generate_ccomp,\n",
    "            \"compound\": self.generate_inherite,\n",
    "            \"compound:prt\": self.generate_inherite,\n",
    "            \"cop\": self.generate_inherite,\n",
    "            \n",
    "            \"expl\": self.generate_expl,\n",
    "            \"nmod\": self.generate_nmod,\n",
    "            \"nmod:npmod\": self.generate_nmod,\n",
    "            \"nmod:tmod\": self.generate_nmod,\n",
    "            \"nmod:poss\": self.generate_nmod_poss,\n",
    "            \n",
    "            \"nummod\": self.generate_nummod,\n",
    "            \"obl\": self.generate_obj,\n",
    "            \"obl:npmod\": self.generate_oblnpmod,\n",
    "            \"obl:tmod\": self.generate_inherite,\n",
    "        '''\n",
    "\n",
    "    def deptree_generate(self, tree, annotated, original):\n",
    "        self.tree_log = []\n",
    "        self.sent_log = []\n",
    "        self.deptree = tree\n",
    "        self.annotated = annotated\n",
    "        self.ie_pred = {}\n",
    "        verbs = ie_extractor.predict(original)['verbs']\n",
    "        for verb in verbs:\n",
    "            self.ie_pred[verb['verb']] = fix_info(verb['description'])        \n",
    "        self.generate(self.deptree)\n",
    "\n",
    "    def generate(self, tree):\n",
    "        if tree.val in self.mod_at_left:\n",
    "            self.left_modifier_generate(tree)\n",
    "        elif tree.val == \"conj\" and tree.mark == \"+\":\n",
    "            self.generate_conj(tree)\n",
    "        elif tree.left != \"N\":\n",
    "            self.generate_default(tree)\n",
    "\n",
    "    def delete_left_modifier(self, tree):\n",
    "        tree.val = tree.right.val\n",
    "        tree.mark = tree.right.mark\n",
    "        tree.npos = tree.right.npos\n",
    "        tree.id = tree.right.id\n",
    "        tree.left = tree.right.left\n",
    "        tree.right = tree.right.right\n",
    "\n",
    "    def rollback(self, tree, backup):\n",
    "        tree.val = backup.val\n",
    "        tree.left = deepcopy(backup.left)\n",
    "        tree.right = deepcopy(backup.right)\n",
    "        tree.mark = backup.mark\n",
    "        tree.npos = backup.npos\n",
    "        tree.id = backup.id\n",
    "\n",
    "    def left_modifier_generate(self, tree):\n",
    "        # adv + VB | VB + adv => VB\n",
    "        # amod + Noun => Noun\n",
    "        # Noun + relcl => Noun\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "        backup = deepcopy(tree)\n",
    "\n",
    "        if right.mark == \"+\":\n",
    "            self.delete_left_modifier(tree)\n",
    "            self.save_tree(isTree=True)\n",
    "            self.rollback(tree, backup)   \n",
    "\n",
    "        self.generate(tree.left)\n",
    "        self.generate(tree.right) \n",
    "\n",
    "    def rollback_annotation(self, generated, original):\n",
    "        word_id = self.annotated[generated]\n",
    "        del self.annotated[generated]\n",
    "        self.annotated[original] = word_id\n",
    "\n",
    "    def generate_conj(self, tree):\n",
    "        backup = deepcopy(tree)\n",
    "        self.left_modifier_generate(tree)\n",
    "\n",
    "        tree.val = tree.left.right.val\n",
    "        tree.mark = tree.left.right.mark\n",
    "        tree.npos = tree.left.right.npos\n",
    "        tree.id = tree.left.right.id\n",
    "        tree.left = backup.left.right.left\n",
    "        tree.right = backup.left.right.right\n",
    "        self.save_tree(isTree=True)\n",
    "        self.rollback(tree, backup)\n",
    "\n",
    "    def add_modifier(self, tree, mod, head, direct=0):\n",
    "        if direct == 0:\n",
    "            generated = ' '. join([mod, head])\n",
    "        else:\n",
    "            generated = ' '. join([head, mod])\n",
    "        word_id = self.annotated[head]\n",
    "        del self.annotated[head]\n",
    "        self.annotated[generated] = word_id\n",
    "        self.save_tree(isTree=False)\n",
    "        self.rollback_annotation(generated, head)\n",
    "\n",
    "    def generate_default(self, tree):\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "\n",
    "        if right.npos is not None:\n",
    "            if \"NN\" in right.npos and right.mark == \"-\":\n",
    "                for adj in kb[\"ADJ\"]:\n",
    "                    self.add_modifier(tree, adj, right.val)\n",
    "                for rel in kb[\"RCL\"]:\n",
    "                    self.add_modifier(tree, rel, right.val, 1)\n",
    "            elif \"VB\" in right.npos and right.mark == \"-\":\n",
    "                for adv in kb[\"ADV\"]:\n",
    "                    self.add_modifier(tree, adv, right.val)\n",
    "                    description = self.ie_pred[right.val]\n",
    "                    arg1 = description[2][-1]\n",
    "                    self.add_modifier(tree, adv, arg1, 1)\n",
    "\n",
    "        self.generate(left)\n",
    "        self.generate(right)  \n",
    "\n",
    "    def save_tree(self, isTree):\n",
    "        if isTree:\n",
    "            self.tree_log.append(deepcopy(self.deptree))\n",
    "        else:\n",
    "            self.sent_log.append(deepcopy(self.annotated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AStarSearch:\n",
    "    def __init__(self):    \n",
    "        self.closed_forward = set()                        \n",
    "        self.closed_backward = set()                     \n",
    "        self.entailments = set()\n",
    "        self.contradictions = set()\n",
    "        self.hypothesis = \"\"\n",
    "        self.phrasalGenerator = PhrasalGenerator()\n",
    "\n",
    "        model_name = \"roberta-large-nli-stsb-mean-tokens\"\n",
    "        self.sbert = SentenceTransformer(model_name)\n",
    "\n",
    "    def generate_premises(self, start):\n",
    "        pipeline = PolarizationPipeline([start], verbose=0, parser=\"stanza\")\n",
    "        pipeline.run_polarize_pipeline()\n",
    "        print(\"\\nPolarization Complete\")\n",
    "\n",
    "        for annotation in pipeline.annotations:\n",
    "            print(\"\\n====================================\")\n",
    "            print(\"\\nInit Premise: \" + annotation['annotated'])\n",
    "            #polarized = annotation['polarized']\n",
    "            #btreeViz = Tree.fromstring(polarized.replace('[', '(').replace(']', ')'))\n",
    "            #jupyter_draw_nltk_tree(btreeViz) \n",
    "            self.phrasalGenerator.deptree_generate(\n",
    "                annotation['polarized_tree'], annotation['word_dict'], annotation['original'])\n",
    "            for gen_tree in phrasalGenerator.tree_log:\n",
    "                generated, queue, _, _ = btreeToList(gen_tree, len(annotation['original']), {}, 0)\n",
    "                annotated = list(queue.popkeys())\n",
    "                print(\"\\nNext Premise: \" + ' '.join(annotated))\n",
    "            for gen_sent in phrasalGenerator.sent_log:\n",
    "                print(\"\\nNext Premise: \" + ' '.join(gen_sent.popkeys()))\n",
    "\n",
    "    def word_similarity(self, s1, s2):\n",
    "        num_sim = 0\n",
    "        seq1 = s1.split(\" \")\n",
    "        for w in seq1:\n",
    "            if w in s2:\n",
    "                num_sim += 1\n",
    "        return num_sim / len(seq1)\n",
    "\n",
    "    def inference_sts(self, seqs1, seqs2):\n",
    "        embeddings1 = self.sbert.encode(seqs1, convert_to_tensor=True)\n",
    "        embeddings2 = self.sbert.encode(seqs2, convert_to_tensor=True)\n",
    "        cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "        for i in range(len(seqs1)):\n",
    "            cost1 = cosine_scores[i][i]\n",
    "            cost2 = self.word_similarity(seqs1[i], seqs2[i])\n",
    "            cost = cost1 * cost2\n",
    "            return cost\n",
    "\n",
    "    def clear(self):\n",
    "        self.closedF.clear()\n",
    "        self.closedR.clear()\n",
    "\n",
    "    def generate_motion(self, open_set, side):\n",
    "        closed = self.closed_forward if side == 0 else self.closed_backward\n",
    "        opened = open_set[side]\n",
    "        self.generate_premises()\n",
    "        for premise in self.entailments:\n",
    "            if premise in closed:\n",
    "                continue\n",
    "            cost = self.inference_sts([premise], [self.hypothesis])\n",
    "            if premise not in opened:\n",
    "                opened[premise] = cost\n",
    "            elif cost > opened[premise]:\n",
    "                opened[premise] = cost\n",
    "\n",
    "    def query(self, premises, hypothesis):\n",
    "        self.clear()\n",
    "        self.hypothesis = hypothesis\n",
    "        kb = {\"ADJ\": [\"beautiful\", \"red\", \"fragret\"], \n",
    "              \"ADV\": [\"ergently\", \"clearly\", \"neccesaraly\"],\n",
    "              \"RCL\": [\"which is beautiful\", \"which opens at night\"]}\n",
    "        self.phrasalGenerator.kb = kb\n",
    "        open_lists = [pqdict({}), pqdict({})]\n",
    "        open_lists[0][premises] = self.inference_sts([premise], [hypothesis])\n",
    "        open_lists[0][hypothesis] = self.inference_sts([hypothesis], [hypothesis])\n",
    "\n",
    "        while open_lists[0] or open_lists[1]:\n",
    "            while open_lists[0]:\n",
    "                optimal = open_lists[0].pop()\n",
    "                break\n",
    "            self.generate_motion(open_list, 0)\n",
    "            if optimal in self.closed_backward:\n",
    "                break\n",
    "            self.closed_forward.add(optimal)\n",
    "\n",
    "            while open[1]:\n",
    "                optimal = open_lists[1].pop()\n",
    "                break\n",
    "            self.generate_motion(open_list, 0)\n",
    "            if optimal in self.closed_forward:\n",
    "                break\n",
    "            self.closed_backward.add(optimal)\n",
    "\n",
    "        self.closed_forward = self.closed_forward | self.closed_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'SentenceTransformer' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-94d44aa65782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAStarSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-6f02ea3e3474>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"roberta-large-nli-stsb-mean-tokens\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_premises\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SentenceTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "search = AStarSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.query(\"All flowers need light\", \"All red flowers need light\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}