{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pqdict import pqdict\n",
    "\n",
    "import torch\n",
    "#from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "#paraphraseTokenizer = AutoTokenizer.from_pretrained(\"textattack/roberta-base-MRPC\")  \n",
    "#paraphraseModel = AutoModelForSequenceClassification.from_pretrained(\"textattack/#roberta-base-MRPC\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model_name = \"roberta-large-nli-stsb-mean-tokens\"\n",
    "sentenceBERT = SentenceTransformer(model_name)\n",
    "classes = [\"not paraphrase\", \"is paraphrase\"]\n",
    "\n",
    "def inference_mrpc(seq1s, seq2s):\n",
    "    for i in range(len(seq1s)):\n",
    "        paraphrase = paraphraseTokenizer.encode_plus(\n",
    "            seq1s[i], seq2s[i], return_tensors=\"pt\")\n",
    "        logits = paraphraseModel(**paraphrase)[0]\n",
    "        paraphrase_results = torch.softmax(logits, dim=1).tolist()[0]\n",
    "        print(f\"{classes[1]}: {round(paraphrase_results[1] * 100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:stanza:Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | gum       |\n",
      "| pos       | gum       |\n",
      "| lemma     | gum       |\n",
      "| depparse  | gum       |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "INFO:stanza:Use device: gpu\n",
      "INFO:stanza:Loading: tokenize\n",
      "INFO:stanza:Loading: pos\n",
      "INFO:stanza:Loading: lemma\n",
      "INFO:stanza:Loading: depparse\n",
      "INFO:stanza:Loading: sentiment\n",
      "INFO:stanza:Loading: ner\n",
      "INFO:stanza:Done loading processors!\n",
      "WARNING:allennlp.common.params:error loading _jsonnet (this is expected on Windows), treating C:\\Users\\ZEMING~1\\AppData\\Local\\Temp\\tmpviqy1_4i\\config.json as plain json\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from Udep2Mono.util import btree2list\n",
    "from Udep2Mono.binarization import BinaryDependencyTree\n",
    "from Udep2Mono.polarization import PolarizationPipeline\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.structured_prediction\n",
    "\n",
    "ie_extractor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import pluralize, singularize\n",
    "from copy import copy\n",
    "\n",
    "def fix_info(desc):\n",
    "    out = desc.replace(\"ARG0: \", \"\")\n",
    "    out = out.replace(\"ARG1: \", \"\")\n",
    "    out = out.replace(\"V: \", \"\")\n",
    "    out = out.replace(\"[\", \"\")\n",
    "    out = out.replace(\"]\", \",\")\n",
    "    out = out.split(\",\")\n",
    "    out = list(map(lambda x: x.strip(), out))\n",
    "    return out\n",
    "\n",
    "class PhrasalGenerator:\n",
    "    def __init__(self):\n",
    "        self.deptree = None\n",
    "        self.annotated = None\n",
    "        self.original = None\n",
    "        self.kb = {}\n",
    "        self.tree_log = []\n",
    "        self.sent_log = []\n",
    "        self.mod_at_left = [\n",
    "            \"advmod\", \"amod\", \"advmod:count\", \"acl:relcl\", \n",
    "            \"acl\", \"advcl\", \"xcomp\", \"ccomp\", \"appos\"]\n",
    "        self.mod_at_right = []\n",
    "        \n",
    "        '''\n",
    "            \"ccomp\": self.generate_ccomp,\n",
    "            \"compound\": self.generate_inherite,\n",
    "            \"compound:prt\": self.generate_inherite,\n",
    "            \"cop\": self.generate_inherite,\n",
    "            \n",
    "            \"expl\": self.generate_expl,\n",
    "            \"nmod\": self.generate_nmod,\n",
    "            \"nmod:npmod\": self.generate_nmod,\n",
    "            \"nmod:tmod\": self.generate_nmod,\n",
    "            \"nmod:poss\": self.generate_nmod_poss,\n",
    "            \n",
    "            \"nummod\": self.generate_nummod,\n",
    "            \"obl\": self.generate_obj,\n",
    "            \"obl:npmod\": self.generate_oblnpmod,\n",
    "            \"obl:tmod\": self.generate_inherite,\n",
    "        '''\n",
    "\n",
    "    def deptree_generate(self, tree, annotated, original):\n",
    "        self.tree_log = []\n",
    "        self.sent_log = []\n",
    "        self.deptree = tree\n",
    "        self.original = original\n",
    "        self.annotated = annotated\n",
    "        self.ie_pred = {}\n",
    "        verbs = ie_extractor.predict(original)['verbs']\n",
    "        for verb in verbs:\n",
    "            self.ie_pred[verb['verb']] = fix_info(verb['description'])        \n",
    "        self.generate(self.deptree)\n",
    "\n",
    "    def generate(self, tree):\n",
    "        if tree.val in self.mod_at_left:\n",
    "            self.left_modifier_generate(tree)\n",
    "        elif tree.val == \"conj\" and tree.mark == \"+\":\n",
    "            self.generate_conj(tree)\n",
    "        elif tree.is_tree:\n",
    "            self.generate_default(tree)\n",
    "\n",
    "    def delete_left_modifier(self, tree):\n",
    "        tree.val = tree.right.val\n",
    "        tree.mark = tree.right.mark\n",
    "        tree.pos = tree.right.pos\n",
    "        tree.id = tree.right.id\n",
    "        \n",
    "        tree.is_tree = tree.right.is_tree\n",
    "        tree.is_root = tree.right.is_root\n",
    "\n",
    "        tree.left = tree.right.left\n",
    "        tree.right = tree.right.right\n",
    "\n",
    "    def rollback(self, tree, backup):\n",
    "        tree.val = backup.val\n",
    "        tree.left = deepcopy(backup.left)\n",
    "        tree.right = deepcopy(backup.right)\n",
    "        tree.mark = backup.mark\n",
    "        tree.pos = backup.pos\n",
    "        tree.id = backup.id\n",
    "        tree.is_tree = backup.is_tree\n",
    "        tree.is_root = backup.is_root\n",
    "\n",
    "    def left_modifier_generate(self, tree):\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "        backup = deepcopy(tree)\n",
    "\n",
    "        if right.mark == \"+\" or right.mark == \"=\":\n",
    "            self.delete_left_modifier(tree)\n",
    "            self.save_tree(isTree=True)\n",
    "            self.rollback(tree, backup)   \n",
    "        \n",
    "        self.generate(tree.left)\n",
    "        self.generate(tree.right)\n",
    "\n",
    "    def rollback_annotation(self, generated, original):\n",
    "        word_id = self.annotated[generated]\n",
    "        del self.annotated[generated]\n",
    "        self.annotated[original] = word_id\n",
    "\n",
    "    def generate_conj(self, tree):\n",
    "        backup = deepcopy(tree)\n",
    "        self.left_modifier_generate(tree)\n",
    "\n",
    "        tree.val = tree.left.right.val\n",
    "        tree.mark = tree.left.right.mark\n",
    "        tree.pos = tree.left.right.pos\n",
    "        tree.id = tree.left.right.id\n",
    "        tree.left = backup.left.right.left\n",
    "        tree.right = backup.left.right.right\n",
    "        self.save_tree(isTree=True)\n",
    "        self.rollback(tree, backup)\n",
    "\n",
    "    def add_modifier(self, tree, mod, head, direct=0):\n",
    "        if direct == 0:\n",
    "            generated = ' '. join([mod, head])\n",
    "        else:\n",
    "            generated = ' '. join([head, mod])\n",
    "\n",
    "        orig_key = (head, tree.pos, tree.mark)\n",
    "        gen_key = (generated, tree.pos, tree.mark)\n",
    "\n",
    "        word_id = self.annotated[orig_key]\n",
    "        del self.annotated[orig_key]\n",
    "        self.annotated[gen_key] = word_id\n",
    "        self.save_tree(isTree=False)\n",
    "        self.rollback_annotation(gen_key, orig_key)\n",
    "\n",
    "    def generate_default(self, tree):\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "\n",
    "        if right.pos is not None:\n",
    "            if \"NN\" in right.pos and right.mark == \"-\":\n",
    "                for adj in self.kb[\"ADJ\"]:\n",
    "                    self.add_modifier(right, adj, right.val)\n",
    "                for rel in self.kb[\"RCL\"]:\n",
    "                    self.add_modifier(right, rel, right.val, 1)\n",
    "            elif \"VB\" in right.pos and right.mark == \"-\":\n",
    "                for adv in self.kb[\"ADV\"]:\n",
    "                    self.add_modifier(right, adv, right.val)\n",
    "                    self.add_modifier(right, adv, right.val, 1)\n",
    "                    description = self.ie_pred[right.val]\n",
    "                    arg1 = description[2]\n",
    "                    self.sent_log.append(\n",
    "                        self.original.replace(\n",
    "                            arg1, ' '.join([arg1, adv])))\n",
    "\n",
    "        self.generate(tree.left)\n",
    "        self.generate(tree.right)  \n",
    "\n",
    "    def save_tree(self, isTree):\n",
    "        if isTree:\n",
    "            #leaves = self.deptree.sorted_leaves().popkeys()\n",
    "            #sentence = ' '.join([x[0] for x in leaves])\n",
    "            #print(sentence)\n",
    "            self.tree_log.append(self.deptree.copy())\n",
    "            #leaves = copy(self.deptree).sorted_leaves().popkeys()\n",
    "            #sentence = ' '.join([x[0] for x in leaves])\n",
    "            #print(sentence)\n",
    "        else:\n",
    "            annotated_cp = deepcopy(self.annotated)\n",
    "            self.sent_log.append(\n",
    "                ' '.join([word[0] for word in list(annotated_cp.popkeys())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from wordnet import *\n",
    "from Udep2Mono.util import det_mark, det_type\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.UdepLog\n",
    "quantifier = db.quantifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LexicalGenerator:\n",
    "    def __init__(self):\n",
    "        self.postags = None\n",
    "        self.hypothesis = \"\"\n",
    "        self.sent_log = []\n",
    "        self.replacement_log = []\n",
    "        self.key_tokens = [\n",
    "            'NN','NNS','NNP','NNPS','VBD',\n",
    "            'VBG','VBN','VBZ','VB']\n",
    "\n",
    "    def filter_words(self, word_set):\n",
    "        filtered = []\n",
    "        for word in word_set:\n",
    "            if word in self.hypothesis:\n",
    "                filtered.append(word)\n",
    "        return filtered\n",
    "\n",
    "    def get_word_knowledge(self, word):\n",
    "        hyper = [] \n",
    "        hypo = [] \n",
    "        syn = [] \n",
    "        ant = []\n",
    "        hyper, hypo, syn, ant = get_word_sets(\n",
    "            singularize(word[0]), word[1].lower())\n",
    "        hyper_fil = self.filter_words(hyper)\n",
    "        hypo_fil = self.filter_words(hypo)\n",
    "        syn_fil = self.filter_words(syn)\n",
    "        ant_fil = self.filter_words(ant)\n",
    "        return hyper_fil, hypo_fil, syn_fil, ant_fil\n",
    "\n",
    "    def replace_token(self, orig, word_set):\n",
    "        prev = orig\n",
    "        for word in word_set:\n",
    "            if prev[0] == word[0]:\n",
    "                continue\n",
    "            item = self.postags[prev]\n",
    "            del self.postags[prev]\n",
    "            self.postags[(word, prev[1], prev[2])] = item\n",
    "            postags_cp = deepcopy(self.postags)\n",
    "            self.sent_log.append(\n",
    "                ' '.join([word[0] for word in list(postags_cp.popkeys())]))\n",
    "            self.replacement_log.append(\n",
    "                \"{} => {}\".format(prev[0], word))\n",
    "            del self.postags[(word, prev[1], prev[2])]\n",
    "            self.postags[prev] = item\n",
    "            prev = (word, prev[1], prev[2])\n",
    "\n",
    "    def generate(self, postags):  \n",
    "        self.postags = deepcopy(postags)  \n",
    "        for word in postags:    \n",
    "            if word[1] in self.key_tokens:\n",
    "                hyper, hypo, syn, ant = self.get_word_knowledge(word)\n",
    "                self.replace_token(word, syn)\n",
    "                self.replace_token(word, ant)\n",
    "\n",
    "                if word[2] == \"+\":                \n",
    "                    self.replace_token(word, hyper)\n",
    "                if word[2] == \"-\":\n",
    "                    self.replace_token(word, hypo)\n",
    "        \n",
    "            elif word[1] == \"DET\":    \n",
    "                kb = quantifier.find({\"word\": tree.left.val.lower()})[0]\n",
    "                self.replace_token(tree.left.val, kb[\"=\"])\n",
    "                if word[2] == \"+\":\n",
    "                    self.replace_token(tree.left.val, kb[\"<\"])   \n",
    "                if word[2] == \"-\":\n",
    "                    self.replace_token(tree.left.val, kb[\">\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pqdict import nlargest\n",
    "import time\n",
    "\n",
    "class AStarSearch:\n",
    "    def __init__(self):    \n",
    "        self.closed_forward = set()                   \n",
    "        self.entailments = set()\n",
    "        self.contradictions = set()\n",
    "        self.hypothesis = \"\"\n",
    "        self.sbert = sentenceBERT\n",
    "        self.pipeline = PolarizationPipeline()\n",
    "        self.phrasalGenerator = PhrasalGenerator()\n",
    "        self.lexicalGenerator = LexicalGenerator()\n",
    "\n",
    "    def generate_premises(self, start):\n",
    "        self.entailments.clear()\n",
    "        self.contradictions.clear()\n",
    "\n",
    "        #tic = time.perf_counter()\n",
    "        annotation = self.pipeline.single_polarization(start)\n",
    "        #toc = time.perf_counter()\n",
    "        #print(f\"Polarize 1 Premise: {toc - tic:0.4f} seconds\")\n",
    "        #print(\"\\nPolarization Complete\")\n",
    "        \n",
    "        #print(\"\\n====================================\")\n",
    "        #print(\"\\nInit Premise: \" + annotation['annotated'])\n",
    "        #polarized = annotation['polarized']\n",
    "        #btreeViz = Tree.fromstring(polarized.replace('[', '(').replace(']', ')'))\n",
    "        #jupyter_draw_nltk_tree(btreeViz) \n",
    "        #print(annotation['word_dict'])\n",
    "\n",
    "        #self.lexicalGenerator.generate(annotation['annotated'])\n",
    "        #for gen_sent in self.lexicalGenerator.sent_log:\n",
    "        #    self.entailments.add(gen_sent)\n",
    "        #toc = time.perf_counter()\n",
    "        #print(f\"Lexical Generate 1 Premise: {toc - tic:0.4f} seconds\")\n",
    "        \n",
    "        self.phrasalGenerator.deptree_generate(\n",
    "            annotation['polarized_tree'], \n",
    "            annotation['annotated'], \n",
    "            annotation['original'])\n",
    "        for gen_tree in self.phrasalGenerator.tree_log:\n",
    "            leaves = gen_tree.sorted_leaves().popkeys()\n",
    "            sentence = ' '.join([x[0] for x in leaves])\n",
    "            print(sentence)\n",
    "            self.entailments.add(sentence)\n",
    "            #print(\"\\nNext Premise: \" + ' '.join(annotated))\n",
    "        for gen_sent in self.phrasalGenerator.sent_log:\n",
    "            #print(gen_sent)\n",
    "            self.entailments.add(gen_sent)\n",
    "            #print(\"\\nNext Premise: \" + ' '.join(gen_sent.popkeys()))\n",
    "        #toc = time.perf_counter()\n",
    "        #print(f\"Phrasla Generate 1 Premise: {toc - tic:0.4f} seconds\")\n",
    "\n",
    "    def word_similarity(self, s1, s2):\n",
    "        num_sim = 0\n",
    "        seq1 = s1.split(\" \")\n",
    "        for w in seq1:\n",
    "            if w in s2:\n",
    "                num_sim += 1\n",
    "        return num_sim / len(seq1)\n",
    "\n",
    "    def inference_sts(self, seqs1, seqs2):\n",
    "        embeddings1 = self.sbert.encode(seqs1, convert_to_tensor=True)\n",
    "        embeddings2 = self.sbert.encode(seqs2, convert_to_tensor=True)\n",
    "        cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "        for i in range(len(seqs1)):\n",
    "            cost1 = cosine_scores[i][i].data.cpu().numpy()\n",
    "            cost2 = self.word_similarity(seqs1[i], seqs2[i])\n",
    "            cost = cost1 * cost2\n",
    "            return cost\n",
    "\n",
    "    def generate_motion(self, starts, opened):\n",
    "        for start in starts:\n",
    "            #tic = time.perf_counter()\n",
    "            self.generate_premises(start)\n",
    "            #toc = time.perf_counter()\n",
    "            #print(f\"Generate Premises: {toc - tic:0.4f} seconds\")\n",
    "\n",
    "            for premise in self.entailments:\n",
    "                #print(premise)\n",
    "                if premise in self.closed_forward:\n",
    "                    continue\n",
    "                cost = self.inference_sts([premise], [self.hypothesis])\n",
    "                if premise not in opened:\n",
    "                    opened[premise] = 1 - cost\n",
    "                if (1-cost) < opened[premise]:\n",
    "                    opened[premise] = 1-cost\n",
    "\n",
    "            #toc = time.perf_counter()\n",
    "            #print(f\"Handled Premises: {toc - tic:0.4f} seconds\")\n",
    "\n",
    "    def query(self, premises, hypothesis):\n",
    "        self.closed_forward.clear()\n",
    "        self.hypothesis = hypothesis.lower()\n",
    "\n",
    "        kb = {\"ADJ\": [\"beautiful\", \"red\", \"fragret\"], \n",
    "              \"ADV\": [\"ergently\", \"clearly\", \"neccesaraly\"],\n",
    "              \"RCL\": [\"which is beautiful\", \"which opens at night\"]}\n",
    "        self.phrasalGenerator.kb = kb\n",
    "        self.lexicalGenerator.hypothesis = self.hypothesis\n",
    "\n",
    "        open_lists = pqdict({})\n",
    "        open_lists[premises] = 1 - self.inference_sts([premises], [hypothesis])\n",
    "\n",
    "        while open_lists:\n",
    "            top_k = 5\n",
    "            optimals = []\n",
    "            for _ in range(5):\n",
    "                if len(open_lists) > 0:\n",
    "                    optimals.append(open_lists.popitem())\n",
    "            print(\"\\nOptimals: \", optimals)\n",
    "            for optimal in optimals:\n",
    "                if optimal[1] < 9.0e-07:\n",
    "                    self.closed_forward.add((self.hypothesis, 0.0000))\n",
    "                    return True\n",
    "            #tic = time.perf_counter()\n",
    "            self.generate_motion([x[0] for x in optimals], open_lists)\n",
    "            #toc = time.perf_counter()\n",
    "            #print(f\"Handle New Premises: {toc - tic:0.4f} seconds\")\n",
    "            self.closed_forward.add(optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = AStarSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Optimals:  [('A brown dog is attacking another animal in front of the tall man in pants', 0.2218152602513631)]\n",
      "a dog is attacking another animal in front of the tall man in pants\n",
      "a brown dog is attacking another animal in front of the man in pants\n",
      "\n",
      "Optimals:  [('a dog is attacking another animal in front of the tall man in pants', 0.12686695371355328), ('a brown dog is attacking another animal in front of the man in pants', 0.1375848778656551)]\n",
      "a dog is attacking another animal in front of the man in pants\n",
      "a dog is attacking another animal in front of the man in pants\n",
      "\n",
      "Optimals:  [('a dog is attacking another animal in front of the man in pants', 2.384185791015625e-07)]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "search.query(\"A brown dog is attacking another animal in front of the tall man in pants\", \"A dog is attacking another animal in front of the man in pants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{('A brown dog is attacking another animal in front of the tall man in pants',\n",
       "  0.2218152602513631),\n",
       " ('a brown dog is attacking another animal in front of the man in pants',\n",
       "  0.1375848778656551),\n",
       " ('a dog is attacking another animal in front of the man in pants', 0.0)}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "search.closed_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "94aab336a04f5c3925a1bec1af7c83ad27d94843d0f31b9ada3336f189da4289"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}