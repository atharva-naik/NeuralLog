{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-03-11 07:14:59 INFO: Loading these models for language: en (English):\n",
      "========================================\n",
      "| Processor | Package                  |\n",
      "----------------------------------------\n",
      "| tokenize  | ../model/e...ize/gum.pt  |\n",
      "| pos       | ../model/en/pos/ewt.pt   |\n",
      "| lemma     | ../model/en/lemma/gum.pt |\n",
      "| depparse  | ../model/e...rse/gum.pt  |\n",
      "========================================\n",
      "\n",
      "2021-03-11 07:14:59 INFO: Use device: gpu\n",
      "2021-03-11 07:14:59 INFO: Loading: tokenize\n",
      "2021-03-11 07:15:01 INFO: Loading: pos\n",
      "2021-03-11 07:15:01 INFO: Loading: lemma\n",
      "2021-03-11 07:15:01 INFO: Loading: depparse\n",
      "2021-03-11 07:15:02 INFO: Done loading processors!\n",
      "2021-03-11 07:15:02 INFO: Loading these models for language: en (English):\n",
      "========================================\n",
      "| Processor | Package                  |\n",
      "----------------------------------------\n",
      "| tokenize  | ../model/e...ize/gum.pt  |\n",
      "| pos       | ../model/en/pos/ewt.pt   |\n",
      "| lemma     | ../model/en/lemma/ewt.pt |\n",
      "| depparse  | ../model/e...rse/ewt.pt  |\n",
      "========================================\n",
      "\n",
      "2021-03-11 07:15:02 INFO: Use device: gpu\n",
      "2021-03-11 07:15:02 INFO: Loading: tokenize\n",
      "2021-03-11 07:15:02 INFO: Loading: pos\n",
      "2021-03-11 07:15:02 INFO: Loading: lemma\n",
      "2021-03-11 07:15:03 INFO: Loading: depparse\n",
      "2021-03-11 07:15:03 INFO: Done loading processors!\n",
      "2021-03-11 07:15:03 INFO: Loading these models for language: en (English):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | ../model/e...ize/gum.pt |\n",
      "=======================================\n",
      "\n",
      "2021-03-11 07:15:03 INFO: Use device: gpu\n",
      "2021-03-11 07:15:03 INFO: Loading: tokenize\n",
      "2021-03-11 07:15:03 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import string\n",
    "import heapq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from word2number import w2n\n",
    "from nltk.tree import Tree\n",
    "from nltk.draw import TreeWidget\n",
    "from nltk.draw.util import CanvasFrame\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import stanza\n",
    "\n",
    "# FIRST TIME ADD:\n",
    "# stanza.download('en')\n",
    "\n",
    "pkg = \"ewt\"\n",
    "#pkg = \"gum\"\n",
    "\n",
    "depparse_gum_config = {\n",
    "    'lang': \"en\",\n",
    "    'processors': \"tokenize,pos,lemma,depparse\",\n",
    "    'tokenize_model_path': '../model/en/tokenize/gum.pt', \n",
    "\t'pos_model_path': '../model/en/pos/ewt.pt',\n",
    "    'depparse_model_path': '../model/en/depparse/gum.pt',\n",
    "    'lemma_model_path': '../model/en/lemma/gum.pt',\n",
    "    'use_gpu': True,\n",
    "    'pos_batch_size': 1000\n",
    "}\n",
    "\n",
    "depparse_ewt_config = {\n",
    "    'lang': \"en\",\n",
    "    'processors': \"tokenize,pos,lemma,depparse\",\n",
    "    'tokenize_model_path': '../model/en/tokenize/gum.pt', \n",
    "\t'pos_model_path': '../model/en/pos/ewt.pt',\n",
    "    'depparse_model_path': '../model/en/depparse/ewt.pt',\n",
    "    'lemma_model_path': '../model/en/lemma/ewt.pt',\n",
    "    'use_gpu': True,\n",
    "    'pos_batch_size': 1000\n",
    "}\n",
    "\n",
    "token_config = {\n",
    "    'lang': \"en\",\n",
    "    'processors': \"tokenize\",\n",
    "    'tokenize_model_path': '../model/en/tokenize/gum.pt', \n",
    "    'pos_batch_size': 3000\n",
    "}\n",
    "\n",
    "gum_depparse = stanza.Pipeline(**depparse_gum_config)\n",
    "ewt_depparse = stanza.Pipeline(**depparse_ewt_config)\n",
    "tokenizer = stanza.Pipeline(**token_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000\n",
    "\n",
    "replacement = {\n",
    "    \n",
    "    \"a few\": \"a-few\",\n",
    "    \"a lot of\": \"a-lot-of\",\n",
    "    \"lots of\": \"lots-of\",\n",
    "    \n",
    "    \"a few of the\": \"a-few-of-the\",\n",
    "    \"none of the\": \"none-of-the\",\n",
    "    \"all of the\": \"all-of-the\",\n",
    "    \"each of the\": \"each-of-the\",\n",
    "    \"some of the\": \"some-of-the\",\n",
    "    \"most of the\": \"most-of-the\",\n",
    "    \"many of the\": \"many-of-the\",\n",
    "    \"several of the\": \"several-of-the\",\n",
    "    \"some but not all\": \"some-but-not-all\",\n",
    "    \"at most\": \"at-most\",\n",
    "    \"at least\": \"at-least\",\n",
    "    \"more than\": \"more-than\",\n",
    "    \"less than\": \"less-than\",\n",
    "    \n",
    "    \"after all\": \"after-all\",\n",
    "    \"out of\": \"out-of\",\n",
    "    \"hardly ever\": \"hardly-ever\",\n",
    "    \"even if\": \"even-if\",\n",
    "    \"no longer\": \"no-longer\",\n",
    "\n",
    "    \"A few\": \"A-few\",\n",
    "    \"A few of the\": \"A-few-of-the\",\n",
    "    \"None of the\": \"None-of-the\",\n",
    "    \"All of the\": \"All-of-the\",\n",
    "    \"Some of the\": \"Some-of-the\",\n",
    "    \"Most of the\": \"Most-of-the\",\n",
    "    \"Many of the\": \"Many-of-the\",\n",
    "    \"Several of the\": \"Several-of-the\",\n",
    "    \"Some but not all\": \"Some-but-not-all\",\n",
    "    \"At most\": \"At-most\",\n",
    "    \"At least\": \"At-least\",\n",
    "    \"More than\": \"More-than\",\n",
    "    \"Less than\": \"Less-than\",\n",
    "    \"No longer\": \"No-longer\",\n",
    "    \"A lot of\": \"A-lot-of\",\n",
    "    \"Lots of\": \"Lots-of\",\n",
    "    \"Each of the\": \"Each-of-the\",\n",
    "    \"Even if\": \"Even-if\",\n",
    "\n",
    "    \"not every\": \"not-every\",\n",
    "    \"not some\": \"not-some\",\n",
    "    \"not all\": \"not-all\",\n",
    "    \"not each\": \"not-each\",\n",
    "    \"Not every\": \"Not-every\",\n",
    "    \"Not some\": \"Not-some\",\n",
    "    \"Not all\": \"Not-all\",\n",
    "    \"Not each\": \"Not-each\",\n",
    "}\n",
    "\n",
    "quantifier_replacement = {\n",
    "    \"a-few\": \"some\",\n",
    "    \"a-few of the\": \"some\",\n",
    "    \"none-of-the\": \"no\",\n",
    "    \"all-of-the\": \"all\",\n",
    "    \"some-of-the\": \"some\",\n",
    "    \"most-of-the\": \"most\",\n",
    "    \"many-of-the\": \"many\",\n",
    "    \"several-of-the\": \"several\",\n",
    "    \"some-but-not-all\": \"some\",\n",
    "    \"at-most\": \"no\",\n",
    "    \"at-least\": \"some\",\n",
    "    \"more-than\": \"some\",\n",
    "    \"less-than\": \"no\",\n",
    "    \"no-longer\": \"not\",\n",
    "    \"a-lot-of\": \"some\",\n",
    "    \"lots-of\": \"some\",\n",
    "    \"each of the\": \"each\",\n",
    "    \"A-few\": \"Some\",\n",
    "    \"A-few of the\": \"Some\",\n",
    "    \"None-of-the\": \"No\",\n",
    "    \"All-of-the\": \"All\",\n",
    "    \"Some-of-the\": \"Some\",\n",
    "    \"Most-of-the\": \"Most\",\n",
    "    \"Many-of-the\": \"Many\",\n",
    "    \"Several-of-the\": \"Several\",\n",
    "    \"Some-but-not-all\": \"Some\",\n",
    "    \"At-most\": \"No\",\n",
    "    \"At-least\": \"Some\",\n",
    "    \"More-than\": \"Some\",\n",
    "    \"Less-than\": \"No\",\n",
    "    \"No-longer\": \"Not\",\n",
    "    \"A-lot-of\": \"Some\",\n",
    "    \"Lots-of\": \"Some\",\n",
    "    \"Each of the\": \"Each\",\n",
    "    \"hardly-ever\": \"never\",\n",
    "    \"Even-if\": \"If\",\n",
    "    \"even-if\": \"if\",\n",
    "    \"not-every\": \"every\",\n",
    "    \"not-some\": \"some\",\n",
    "    \"not-all\": \"all\",\n",
    "    \"not-each\": \"each\",\n",
    "    \"Not-every\": \"every\",\n",
    "    \"Not-some\": \"some\",\n",
    "    \"Not-all\": \"all\",\n",
    "    \"Not-each\": \"each\",\n",
    "\n",
    "    \"after-all\": \"after-all\",\n",
    "    \"out-of\": \"out-of\",\n",
    "    \"hardly-ever\": \"never\",\n",
    "    \"no-longer\": \"no-longer\",\n",
    "}\n",
    "\n",
    "def preprocess(sentence):\n",
    "    replaced = {}\n",
    "    processed = sentence\n",
    "    for orig in replacement:\n",
    "        if orig in processed:\n",
    "            processed = processed.replace(orig, replacement[orig])\n",
    "            \n",
    "    tokens = tokenizer(processed).sentences[0].words\n",
    "    for tok in tokens:\n",
    "        if tok.text in quantifier_replacement:\n",
    "            processed = processed.replace(tok.text, quantifier_replacement[tok.text])\n",
    "            replaced[str((quantifier_replacement[tok.text], tok.id))] = tok.text \n",
    "    \n",
    "    return processed, replaced\n",
    "\n",
    "def dependency_parse(sentence, parser=\"gum\"):\n",
    "    processed, replaced = preprocess(sentence)\n",
    "    return stanza_parse(processed, parser=parser), replaced\n",
    "\n",
    "def stanza_parse(sentence, parser=\"gum\"):\n",
    "    postags = {}\n",
    "    words = {}\n",
    "    parse_tree = []\n",
    "    head_log = {}\n",
    "    depdent_log = {}\n",
    "\n",
    "    if parser == \"gum\":\n",
    "        parsed = gum_depparse(sentence)\n",
    "    elif parser == \"ewt\":\n",
    "        parsed = ewt_depparse(sentence)\n",
    "\n",
    "    for sent in parsed.sentences:\n",
    "        for word in sent.words:\n",
    "            tree_node = post_process(sent, word, postags, words)\n",
    "\n",
    "            if len(tree_node) == 0:\n",
    "                continue\n",
    "\n",
    "            if tree_node[2] in head_log:\n",
    "                head_log[tree_node[2]].append(tree_node[0])\n",
    "            else:\n",
    "                head_log[tree_node[2]] = [tree_node[0]]\n",
    "\n",
    "            if tree_node[1] in depdent_log:\n",
    "                depdent_log[tree_node[1]].append(tree_node[0])\n",
    "            else:\n",
    "                depdent_log[tree_node[1]] = [tree_node[0]]\n",
    "\n",
    "            parse_tree.append(tree_node)\n",
    "\n",
    "        enhance_parse(parse_tree, head_log, depdent_log, words)\n",
    "    return parse_tree, postags, words\n",
    "\n",
    "def enhance_parse(tree, heads, deps, words):\n",
    "    for node in tree:\n",
    "        if node[0] == \"conj\":\n",
    "            if \"nsubj\" in heads[node[1]] and \"nsubj\" in heads[node[2]]:\n",
    "                node[0] = \"conj-sent\"\n",
    "            elif words[node[1]][1] == \"JJ\" and words[node[2]][1] == \"JJ\":\n",
    "                node[0] = \"conj-adj\"\n",
    "            elif \"NN\" in words[node[1]][1] and \"NN\" in words[node[2]][1]:\n",
    "                node[0] = \"conj-n\"\n",
    "                vp_rel = set([\"amod\", \"compound\", \"compound\",  \"compound:prt\", \"det\",\n",
    "                              \"nummod\", \"appos\", \"advmod\", \"nmod\", \"nmod:poss\"])\n",
    "                vp_left = set(heads[node[1]]) & vp_rel\n",
    "                vp_right = set(heads[node[2]]) & vp_rel\n",
    "                if len(vp_left) and len(vp_right):\n",
    "                    node[0] = \"conj-np\"\n",
    "            elif \"VB\" in words[node[1]][1] and \"VB\" in words[node[2]][1]:\n",
    "                node[0] = \"conj-vb\"\n",
    "                vp_rel = set([\"obj\", \"xcomp\", \"obl\"])\n",
    "                vp_left = set(heads[node[1]]) & vp_rel\n",
    "                vp_right = set(heads[node[2]]) & vp_rel\n",
    "\n",
    "                if len(vp_left):\n",
    "                    if len(vp_right):\n",
    "                        node[0] = \"conj-vp\"\n",
    "                    # else:\n",
    "\n",
    "        if node[0] == \"advcl\":\n",
    "            if words[1][0] == \"if\":\n",
    "                node[0] = \"advcl-sent\"\n",
    "        if node[0] == \"advmod\":\n",
    "            if words[node[1]][0] == \"not\" and node[1] == 1:\n",
    "                node[0] = \"advmod-sent\"\n",
    "        if node[0] == \"case\" and node[1] - node[2] > 0:\n",
    "            node[0] = \"case-after\"\n",
    "        if words[node[1]][0] in [\"at-most\", \"at-least\", \"more-than\", \"less-than\"]:\n",
    "            node[0] = \"det\"\n",
    "\n",
    "\n",
    "def post_process(sent, word, postag, words):\n",
    "    wordID = int(word.id)\n",
    "    if wordID not in words:\n",
    "        postag[word.text] = (wordID, word.xpos)\n",
    "        words[wordID] = (word.text, word.xpos)\n",
    "    if word.deprel != \"punct\":\n",
    "        tree_node = [word.deprel, wordID,\n",
    "                     word.head if word.head > 0 else \"root\"]\n",
    "        return tree_node\n",
    "    return []\n",
    "\n",
    "\n",
    "def printTree(tree, tag, word):\n",
    "    if tree[0] != \"root\":\n",
    "        print(f\"word: {word[tree[1]][0]}\\thead: {word[tree[2]][0]}\\tdeprel: {tree[0]}\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnifiedCounter:\n",
    "    def __init__(self, initial_val = 0):\n",
    "        self.addi_negates = initial_val\n",
    "        self.unifies = initial_val\n",
    "        self.nsubjLeft = False\n",
    "        self.nsubjDetExist = False\n",
    "        self.expl = False\n",
    "        self.willing_verb = False\n",
    "        self.ability_verb = False\n",
    "        self.allBut = False\n",
    "        self.atLeastVerb = False\n",
    "        self.originals = {\n",
    "                        \"nsubjLeft\": [False],\n",
    "                        \"nsubjDetExist\": [False],\n",
    "                        \"expl\": [False],\n",
    "                        \"willing_verb\": [False],\n",
    "                        \"ability_verb\": [False],\n",
    "                        \"allBut\": [False],\n",
    "                        \"atLeastVerb\": [False]\n",
    "        }\n",
    "    def add_negates(self):\n",
    "        self.addi_negates += 1 \n",
    "    def add_unifies(self):\n",
    "        self.unifies += 1\n",
    "    def is_unified_clause_subj(self):\n",
    "        return self.unifies %2 == 1 and self.nsubjLeft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pqdict import pqdict\n",
    "\n",
    "class BinaryDependencyTree:\n",
    "    def __init__(self, val, left, right, key, counter, id=None, pos=None):\n",
    "        self.val = val\n",
    "        self.parent = None\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.mark = \"0\"\n",
    "        self.id = id\n",
    "        self.pos = pos\n",
    "        self.key = key\n",
    "        self.is_root = False\n",
    "        self.is_tree = True\n",
    "        self.length = 0\n",
    "        self.leaves = pqdict({})\n",
    "        self.counter = counter\n",
    "        self.replaced = {}\n",
    "\n",
    "    def sorted_leaves(self):\n",
    "        self.traverse(self)\n",
    "        return self.leaves\n",
    "\n",
    "    def traverse(self, tree):\n",
    "        if not tree.is_tree:\n",
    "            replacement = False\n",
    "            if str((tree.val, tree.id)) in self.replaced:\n",
    "                tree.val = self.replaced[str((tree.val, tree.id))]\n",
    "                replacement = True\n",
    "            if \"-\" in tree.val and replacement:\n",
    "                words = tree.val.split('-')\n",
    "                words.reverse()\n",
    "                for i in range(len(words)):\n",
    "                    word_id = tree.id - i * 0.1\n",
    "                    key = (words[i], tree.pos, tree.mark, word_id)\n",
    "                    if words[i].lower() == \"not\" and len(words) == 2:\n",
    "                        key = (words[i], tree.pos, negate_mark[tree.mark], word_id)\n",
    "                    self.leaves[key] = (word_id)\n",
    "            else:\n",
    "                item = (tree.id)\n",
    "                key = (tree.val, tree.pos, tree.mark, tree.id)\n",
    "                self.leaves[key] = item\n",
    "        else:\n",
    "            self.traverse(tree.left)\n",
    "            self.traverse(tree.right)\n",
    "            \n",
    "    def copy(self):\n",
    "        left = None\n",
    "        if self.left is not None:\n",
    "            left = self.left.copy()\n",
    "        right = None\n",
    "        if self.right is not None:\n",
    "            right = self.right.copy()\n",
    "        new_tree = BinaryDependencyTree(\n",
    "            self.val, left, right, self.key, self.counter, self.id, self.pos)\n",
    "        new_tree.mark = self.mark\n",
    "        new_tree.parent = self.parent\n",
    "        new_tree.is_tree = self.is_tree\n",
    "        new_tree.is_root = self.is_root\n",
    "        new_tree.leaves = pqdict({})\n",
    "        return new_tree\n",
    "\n",
    "    def set_length(self, lth):\n",
    "        self.length = lth\n",
    "\n",
    "    def set_root(self):\n",
    "        self.is_root = True\n",
    "\n",
    "    def set_not_tree(self):\n",
    "        self.is_tree = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy = {\n",
    "    \"conj-sent\": 0,\n",
    "    \"advcl-sent\": 1,\n",
    "    \"advmod-sent\": 2,\n",
    "    \"case\": 10,\n",
    "    \"case-after\": 75,\n",
    "    \"mark\": 10,\n",
    "    \"expl\": 10,\n",
    "    \"discourse\": 10,\n",
    "    \"nsubj\": 20,\n",
    "    \"csubj\": 20,\n",
    "    \"nsubj:pass\": 20,\n",
    "    \"conj-vp\": 25,\n",
    "    \"ccomp\": 30,\n",
    "    \"advcl\": 30,\n",
    "    \"advmod\": 30,\n",
    "    \"nmod\": 30,\n",
    "    \"nmod:tmod\": 30,\n",
    "    \"nmod:npmod\": 30,\n",
    "    \"nmod:poss\": 30,\n",
    "    \"xcomp\": 40,\n",
    "    \"aux\": 40,\n",
    "    \"aux:pass\": 40,\n",
    "    \"obj\": 60,\n",
    "    \"iobj\": 60,\n",
    "    \"obl\": 50,\n",
    "    \"obl:tmod\": 50,\n",
    "    \"obl:npmod\": 50,\n",
    "    \"cop\": 50,\n",
    "    \"acl\": 60,\n",
    "    \"acl:relcl\": 60,\n",
    "    \"appos\": 60,\n",
    "    \"conj\": 60,\n",
    "    \"conj-np\": 60,\n",
    "    \"conj-adj\": 60,\n",
    "    \"det\": 55,\n",
    "    \"det:predet\": 55,\n",
    "    \"cc\": 70,\n",
    "    \"nummod\": 75,\n",
    "    \"fixed\": 80,\n",
    "    \"compound\": 80,\n",
    "    \"compound:prt\": 80,\n",
    "    \"fixed\": 80,\n",
    "    \"amod\": 75,\n",
    "    \"conj-n\": 90,\n",
    "    \"conj-vb\": 90,\n",
    "    \"flat\": 100,\n",
    "    \"goeswith\": 100,\n",
    "    \"parataxis\": 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Binarizer:\n",
    "    def __init__(self, parse_table=None, postag=None, words=None):\n",
    "        self.postag = postag\n",
    "        self.parse_table = parse_table\n",
    "        self.words = words\n",
    "        self.id = 0\n",
    "        self.counter = UnifiedCounter(0)\n",
    "        self.replaced = {}\n",
    "\n",
    "    def process_not(self, children):\n",
    "        if len(children) > 1:\n",
    "            if children[0][0] == \"advmod\":\n",
    "                if self.words[children[1][1]][0] == \"not\":\n",
    "                    return [children[1]]\n",
    "        return children\n",
    "\n",
    "    def compose(self, head):\n",
    "        children = list(filter(lambda x: x[2] == head, self.parse_table))\n",
    "        children.sort(key=(lambda x: hierarchy[x[0]]))\n",
    "        children = self.process_not(children)\n",
    "\n",
    "        if len(children) == 0:\n",
    "            word = self.words[head][0]\n",
    "            tag = self.words[head][1]\n",
    "            binary_tree = BinaryDependencyTree(\n",
    "                word, None, None, self.id, self.counter, head, tag)\n",
    "            binary_tree.replaced = self.replaced\n",
    "            self.id += 1\n",
    "            binary_tree.set_not_tree()\n",
    "            return binary_tree, [binary_tree.key]\n",
    "        else:\n",
    "            top_dep = children[0]\n",
    "        self.parse_table.remove(top_dep)\n",
    "\n",
    "        left, left_rel = self.compose(top_dep[1])\n",
    "        right, right_rel = self.compose(top_dep[2])\n",
    "        if \"conj\" in top_dep[0]:\n",
    "            dep_rel = \"conj\"\n",
    "        elif \"case\" in top_dep[0]:\n",
    "            dep_rel = \"case\"\n",
    "        elif \"advcl\" in top_dep[0]:\n",
    "            dep_rel = \"advcl\"\n",
    "        elif \"advmod\" in top_dep[0]:\n",
    "            dep_rel = \"advmod\"\n",
    "        else:\n",
    "            dep_rel = top_dep[0]\n",
    "\n",
    "        binary_tree = BinaryDependencyTree(dep_rel, left, right, self.id, self.counter)\n",
    "        binary_tree.left.parent = binary_tree\n",
    "        binary_tree.right.parent = binary_tree\n",
    "        binary_tree.replaced = self.replaced\n",
    "\n",
    "        left_rel.append(binary_tree.key)\n",
    "        self.id += 1\n",
    "        return binary_tree, left_rel + right_rel\n",
    "\n",
    "    def binarization(self):\n",
    "        self.id = 0\n",
    "        self.relation = []\n",
    "        root = list(filter(lambda x: x[0] == \"root\", self.parse_table))[0][1]\n",
    "        self.counter = UnifiedCounter(0)\n",
    "        binary_tree, relation = self.compose(root)\n",
    "        binary_tree.set_root()\n",
    "        binary_tree.length = len(self.words)\n",
    "        return binary_tree, relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import conjugate\n",
    "import numpy as np\n",
    "\n",
    "negate_mark = {\n",
    "    \"+\": \"-\",\n",
    "    \"-\": \"+\",\n",
    "    \"=\": \"=\"\n",
    "}\n",
    "\n",
    "det_mark = {\n",
    "    \"det:univ\": \"-\",\n",
    "    \"det:exist\": \"+\",\n",
    "    \"det:limit\": \"=\",\n",
    "    \"det:negation\": \"-\"\n",
    "}\n",
    "\n",
    "det_type_words = {\n",
    "    \"det:univ\": [\"all\", \"every\", \"each\", \"any\", \"all-of-the\"],\n",
    "    \"det:exist\": [\"a\", \"an\", \"some\", \"double\", \"triple\", \"some-of-the\", \"al-least\", \"more-than\"],\n",
    "    \"det:limit\": [\"such\", \"both\", \"the\", \"this\", \"that\",\n",
    "                  \"those\", \"these\", \"my\", \"his\", \"her\",\n",
    "                  \"its\", \"either\", \"both\", \"another\"],\n",
    "    \"det:negation\": [\"no\", \"neither\", \"never\", \"none\", \"none-of-the\", \"less-than\", \"at-most\", \"few\"]\n",
    "}\n",
    "\n",
    "negtive_implicative = [\"refuse\", \"reject\", \"oppose\", \"forget\",\n",
    "                       \"hesitate\", \"without\", \"disapprove\", \"disagree\",\n",
    "                       \"eradicate\", \"erase\", \"dicline\", \"eliminate\",\n",
    "                       \"decline\", \"resist\", \"block\", \"stop\", \"hault\",\n",
    "                       \"disable\", \"disinfect\", \"disapear\", \"disgard\",\n",
    "                       \"disarm\", \"disarrange\", \"disallow\", \"discharge\",\n",
    "                       \"disbelieve\", \"disclaim\", \"disclose\", \"disconnect\",\n",
    "                       \"disconnect\", \"discourage\", \"discredit\", \"discorporate\",\n",
    "                       \"disengage\", \"disentangle\", \"dismiss\", \"disobeye\",\n",
    "                       \"distrust\", \"disrupt\", \"suspen\", \"suspend \",\n",
    "                       \"freeze\"\n",
    "                      ]\n",
    "\n",
    "\n",
    "at_least_implicative = [\"for\", \"buy\", \"drink\", \"take\", \"hold\", \"receive\",\n",
    "                        \"get\", \"catch\", \"smoke\", \"have\",\"give\",\"eat\",\"see\"]\n",
    "\n",
    "exactly_implicative = [\"like\", \"love\", \"admires\", \"marry\"]\n",
    "\n",
    "if_verbs = [\"see\", \"understand\", \"know\", \"hear\", \"care\"]\n",
    "\n",
    "willing_verbs = [\"want\", \"ask\", \"told\", \"tell\", \"assign\", \"force\"]\n",
    "ability_words = [\"can\", \"could\",\"may\",\"might\"]\n",
    "\n",
    "def build_implicative_dict():\n",
    "    verbs = list(df['Verb'])\n",
    "    signs = list(df['Signature'])\n",
    "    implicatives = {}\n",
    "    for i in range(len(verbs)):\n",
    "        implicatives[verbs[i]] = signs[i]\n",
    "    return implicatives\n",
    "\n",
    "implicatives = {} #build_implicative_dict()\n",
    "imp_types = {\n",
    "    '-': negtive_implicative,\n",
    "    'at_least': at_least_implicative,\n",
    "    '=': exactly_implicative\n",
    "}\n",
    "\n",
    "def is_implicative(word, imp_type):\n",
    "    verb = conjugate(word, tense=\"present\", person=1, number=\"singular\")\n",
    "    if imp_type in ['+', '-']:\n",
    "        if verb in implicatives:\n",
    "            return implicatives\n",
    "    return verb in imp_types[imp_type] \n",
    "\n",
    "def det_type(word):\n",
    "    for det in det_type_words:\n",
    "        if word.lower() in det_type_words[det]:\n",
    "            return det\n",
    "\n",
    "arrows = {\n",
    "    \"+\": \"\\u2191\",\n",
    "    \"-\": \"\\u2193\",\n",
    "    \"=\": \"=\",\n",
    "    \"0\": \"\"\n",
    "}\n",
    "\n",
    "arrow2int = {\n",
    "    \"\\u2191\": 1,\n",
    "    \"\\u2193\": -1,\n",
    "    \"=\": 0\n",
    "}\n",
    "\n",
    "def btree2list(binaryDepdency, verbose=0):\n",
    "    def to_list(tree):\n",
    "        treelist = []\n",
    "        if tree.is_tree:\n",
    "            word = tree.val + arrows[tree.mark]\n",
    "            if verbose == 2:\n",
    "                word += str(tree.key)\n",
    "            treelist.append(word)\n",
    "        else:\n",
    "            treelist.append(tree.pos)\n",
    "            word = tree.val.replace('-', ' ') + arrows[tree.mark]\n",
    "            if verbose == 2:\n",
    "                word += str(tree.key)\n",
    "            treelist.append(word)\n",
    "\n",
    "        if tree.left is not None:\n",
    "            treelist.append(to_list(tree.left))\n",
    "\n",
    "        if tree.right is not None:\n",
    "            treelist.append(to_list(tree.right))\n",
    "\n",
    "        return treelist\n",
    "    return to_list(binaryDepdency)\n",
    "\n",
    "def annotation2string(annotation):\n",
    "    annotated = list(annotation['annotated'].popkeys())\n",
    "    def compose_token(word):\n",
    "        if '-' in word[0]:\n",
    "            orig = word[0].split('-')\n",
    "            return ' '.join([x + arrows[word[2]] for x in orig])\n",
    "        else:\n",
    "            return word[0] + arrows[word[2]]\n",
    "    annotated_sent = ' '.join([compose_token(x) for x in annotated])\n",
    "    return annotated_sent\n",
    "\n",
    "\n",
    "def arrow2int(word):\n",
    "    if arrows['+'] in word:\n",
    "       return \"+\"\n",
    "    elif arrows['-'] in word:\n",
    "        return \"-\"\n",
    "    elif arrows['='] in word:\n",
    "        return \"=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_comparative = {\n",
    "    \"taller\": [\"+\", \"-\"],\n",
    "    \"lower\": [\"-\", \"+\"],\n",
    "    \"higher\": [\"-\", \"+\"],\n",
    "    \"faster\": [\"+\", \"-\"],\n",
    "    \"slower\": [\"-\", \"+\"],\n",
    "    \"longer\": [\"+\", \"-\"],\n",
    "    \"shorter\": [\"-\", \"+\"],\n",
    "    \"heavier\": [\"+\", \"-\"],\n",
    "    \"lighter\": [\"-\", \"+\"],\n",
    "    \"deeper\": [\"+\", \"-\"],\n",
    "    \"shawlloer\": [\"-\", \"+\"],\n",
    "    \"brighter\": [\"+\", \"-\"],\n",
    "    \"darker\": [\"-\", \"+\"],\n",
    "    \"hotter\": [\"+\", \"-\"],\n",
    "    \"colder\": [\"-\", \"+\"],\n",
    "    \"warmer\": [\"+\", \"-\"],\n",
    "    \"cooler\": [\"-\", \"+\"],\n",
    "    \"bigger\": [\"+\", \"-\"],\n",
    "    \"larger\": [\"+\", \"-\"], \n",
    "    \"smaller\": [\"-\", \"+\"],\n",
    "    \"more\": [\"+\", \"-\"],\n",
    "    \"less\": [\"-\", \"+\"],\n",
    "    \"fewer\": [\"-\", \"+\"],\n",
    "    \"greater\": [\"+\", \"-\"],\n",
    "    \"stronger\": [\"+\", \"-\"],\n",
    "    \"weaker\": [\"-\", \"+\"],\n",
    "    \"dryer\": [\"-\", \"+\"],\n",
    "    \"wetter\": [\"+\", \"-\"],\n",
    "    \"tigher\": [\"+\", \"-\"],\n",
    "    \"loose\": [\"-\", \"+\"],\n",
    "    \"farther\": [\"+\", \"-\"],\n",
    "    \"closer\": [\"-\", \"+\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jupyter_draw_nltk_tree(tree):\n",
    "    cf = CanvasFrame()\n",
    "    tc = TreeWidget(cf.canvas(), tree)\n",
    "    tc['node_font'] = 'arial 14 bold'\n",
    "    tc['leaf_font'] = 'arial 14'\n",
    "    tc['node_color'] = '#005990'\n",
    "    tc['leaf_color'] = '#3F8F57'\n",
    "    tc['line_color'] = '#175252'\n",
    "    cf.add_widget(tc, 20, 20)\n",
    "    cf.print_to_file('../data/tree.ps')\n",
    "    cf.destroy()\n",
    "    os.system('convert ../data/tree.ps ../data/tree.png')\n",
    "    display(Image(filename='../data/tree.png'))\n",
    "    \n",
    "def jupyter_draw_rsyntax_tree(tree):\n",
    "    font_size = '8'\n",
    "    command = 'rsyntaxtree -s {} \"{}\"'.format(font_size, tree)\n",
    "    os.system(command)\n",
    "    display(Image(filename='./syntree.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Polarizer:\n",
    "    def __init__(self, dependtree=None, relation=None):\n",
    "        self.dependtree = dependtree\n",
    "        self.sentence_head = []\n",
    "        self.relation = relation\n",
    "        self.polarize_function = {\n",
    "            \"acl\": self.polarize_acl_relcl,\n",
    "            \"acl:relcl\": self.polarize_acl_relcl,\n",
    "            \"advcl\": self.polarize_acl_relcl,\n",
    "            \"advmod\": self.polarize_advmod,\n",
    "            \"advmod:count\": self.polarize_advmod,\n",
    "            \"amod\": self.polarize_amod,\n",
    "            \"appos\": self.polarize_inherite,\n",
    "            \"aux\": self.polarize_aux,\n",
    "            \"aux:pass\": self.polarize_aux,\n",
    "            \"case\": self.polarize_case,\n",
    "            \"cc\": self.polarize_cc,\n",
    "            \"cc:preconj\": self.polarize_det,\n",
    "            \"ccomp\": self.polarize_ccomp,\n",
    "            \"compound\": self.polarize_inherite,\n",
    "            \"compound:prt\": self.polarize_inherite,\n",
    "            \"conj\": self.polarize_inherite,\n",
    "            \"cop\": self.polarize_inherite,\n",
    "            \"csubj\": self.polarize_nsubj,\n",
    "            \"csubj:pass\": self.polarize_nsubj,\n",
    "            \"dep\": self.polarize_dep,\n",
    "            \"det\": self.polarize_det,\n",
    "            \"det:predet\": self.polarize_det,\n",
    "            \"discourse\": self.polarize_inherite,\n",
    "            \"expl\": self.polarize_expl,\n",
    "            \"fixed\": self.polarize_inherite,\n",
    "            \"flat\": self.polarize_inherite,\n",
    "            \"goeswith\": self.polarize_inherite,\n",
    "            \"iobj\": self.polarize_iobj,\n",
    "            \"mark\": self.polarize_inherite,\n",
    "            \"nmod\": self.polarize_nmod,\n",
    "            \"nmod:npmod\": self.polarize_nmod,\n",
    "            \"nmod:tmod\": self.polarize_nmod,\n",
    "            \"nmod:poss\": self.polarize_nmod_poss,\n",
    "            \"nsubj\": self.polarize_nsubj,\n",
    "            \"nsubj:pass\": self.polarize_nsubj,\n",
    "            \"nummod\": self.polarize_nummod,\n",
    "            \"obj\": self.polarize_obj,\n",
    "            \"obl\": self.polarize_obl,\n",
    "            \"obl:npmod\": self.polarize_oblnpmod,\n",
    "            \"obl:tmod\": self.polarize_inherite,\n",
    "            \"parataxis\": self.polarize_inherite,\n",
    "            \"xcomp\": self.polarize_obj,\n",
    "        }\n",
    "        self.tree_log = []\n",
    "        self.polar_log = []\n",
    "        self.replaced = None\n",
    "\n",
    "        self.DETEXIST = \"det:exist\"\n",
    "        self.DETNEGATE = \"det:negation\"\n",
    "\n",
    "        self.nsubj_right_equal = False\n",
    "\n",
    "    def polarize_deptree(self):\n",
    "        self.polarize(self.dependtree)\n",
    "\n",
    "    def polarize(self, tree):\n",
    "        if tree.is_tree:\n",
    "            self.polarize_function[tree.val](tree)\n",
    "\n",
    "    def polarize_acl_relcl(self, tree):\n",
    "        self.sentence_head.append(tree)\n",
    "        self.right_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "        \n",
    "        verb = self.down_right(tree)\n",
    "        original_verbState = tree.counter.willing_verb\n",
    "        if(verb.val.lower() in willing_verbs and left.val == \"mark\" and left.left.val.lower() == \"to\"):\n",
    "            tree.counter.willing_verb = True\n",
    "    \n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "        \n",
    "        tree.counter.willing_verb = original_verbState\n",
    "        \n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "        \n",
    "        if right.id == 1:\n",
    "            right.mark = \"-\"\n",
    "\n",
    "        tree.mark = right.mark\n",
    "\n",
    "        if right.mark == \"-\" and left.pos != \"VBD\":\n",
    "            self.negate(left, -1)\n",
    "        elif right.mark == \"=\" and left.pos != \"VBD\":\n",
    "            self.equalize(left)\n",
    "        elif right.val == \"impossible\":\n",
    "            self.negate(left, -1)\n",
    "\n",
    "        self.sentence_head.pop()\n",
    "\n",
    "    def polarize_advmod(self, tree):\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "        self.polarize_inherite(tree)\n",
    "        root_mark = tree.mark\n",
    "\n",
    "        if left.val.lower() in [\"many\", \"most\"]:\n",
    "            right.mark = \"=\"\n",
    "            if isinstance(tree.parent, BinaryDependencyTree) and tree.parent.val == \"amod\":\n",
    "                self.equalize(tree.parent.right)\n",
    "        elif left.val.lower() in [\"not\", \"no\", \"n't\", \"never\", \"rarely\", \"barely\", \"seldom\"]:\n",
    "            self.negate(right, -1)\n",
    "        elif left.val.lower() in [\"exactly\"]:\n",
    "            self.equalize(tree.right)\n",
    "            left.mark = root_mark\n",
    "            tree.mark = right.mark\n",
    "\n",
    "        if left.val.lower() == \"when\":\n",
    "            self.equalize(self.dependtree)\n",
    "\n",
    "    def polarize_amod(self, tree):\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "        self.polarize_inherite(tree)\n",
    "        \n",
    "        \n",
    "        if left.val.lower() in [\"many\", \"most\"]:\n",
    "            self.equalize(right)\n",
    "            tree.mark = right.mark\n",
    "        elif left.val.lower() == \"few\":\n",
    "            self.top_down_negate(\n",
    "                    tree, \"amod\", self.relation.index(tree.key))\n",
    "            right.mark = \"-\"\n",
    "            self.polarize(right)\n",
    "        elif self.down_left(tree).val.lower() in [\"fewer\", \"less\"]:\n",
    "            self.noun_mark_replace(right, \"-\")\n",
    "            left.mark = \"+\"\n",
    "            if(tree.parent.val == \"acl:relcl\"):\n",
    "                self.equalize(tree.parent.left)\n",
    "        elif self.down_left(tree).val.lower() in [\"more\"]:\n",
    "            if(tree.parent.val == \"acl:relcl\"):\n",
    "                self.equalize(tree.parent.left)\n",
    "        elif left.val == \"advmod\":\n",
    "            if left.right.val == \"many\":\n",
    "                self.equalize(right)\n",
    "                tree.mark = right.mark\n",
    "            if left.left.val.lower() == \"not\":\n",
    "                self.top_down_negate(\n",
    "                    tree, \"amod\", self.relation.index(tree.key))\n",
    "        elif left.val == \"out-of\":\n",
    "            if(tree.parent is not None and tree.parent.val == \"nummod\" and right.val == \"nummod\"):\n",
    "                left.mark = \"-\"\n",
    "                right.mark =  \"+\"\n",
    "                right.right.mark = \"+\"\n",
    "                right.left.mark = \"=\"\n",
    "            self.polarize(right.right)\n",
    "    \n",
    "    def polarize_aux(self, tree):\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "        tree.counter.originals[\"ability_verb\"].append(tree.counter.ability_verb)\n",
    "        if left.val in ability_words:\n",
    "            tree.counter.ability_verb = True\n",
    "        self.polarize_inherite(tree)\n",
    "        tree.counter.ability_verb = tree.counter.originals[\"ability_verb\"].pop()\n",
    "        \n",
    "    def polarize_case(self, tree):\n",
    "        self.polarize_inherite(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if left.val == \"without\":\n",
    "            if right.is_tree:\n",
    "                self.polarize(right)\n",
    "            self.negate(tree, self.relation.index(left.key))\n",
    "        elif right.pos == \"CD\":\n",
    "            right.mark = \"=\"\n",
    "            if left.is_tree:\n",
    "                self.polarize(left)\n",
    "        elif right.val == \"nmod:poss\":\n",
    "            left.mark = \"=\"\n",
    "            if right.is_tree:\n",
    "                self.polarize(right)\n",
    "        elif left.val == \"except\":\n",
    "            right.mark = \"=\"\n",
    "            if right.is_tree and right.left.val == \"for\":\n",
    "                self.nsubj_right_equal = True\n",
    "        \n",
    "        ## duration case \"for\"\n",
    "        elif left.val.lower() == \"for\" and right.val == \"nummod\":\n",
    "            right.mark = \"-\"\n",
    "            self.polarize(right)\n",
    "        elif left.val == \"than\":\n",
    "            temp, changes = self.find_comparative(tree)\n",
    "            if(temp is not None and changes is not None):\n",
    "                if(changes[0] != \"+\"):\n",
    "                    temp.parent.mark = changes[0]\n",
    "                    self.polarize(temp.parent)\n",
    "\n",
    "                if(changes[1] != \"+\"):\n",
    "                    right.mark = changes[1]      \n",
    "                    self.polarize(right)\n",
    "    def polarize_cc(self, tree):\n",
    "        self.full_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if right.val != \"expl\" and right.val != \"det\":\n",
    "            right.mark = tree.mark\n",
    "\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "\n",
    "        if left.val == \"but\" and not tree.counter.allBut:\n",
    "            right.mark = \"-\"\n",
    "            tree.mark = \"-\"\n",
    "\n",
    "        if left.id == 1:\n",
    "            self.equalize(right)\n",
    "\n",
    "    def polarize_ccomp(self, tree):\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if tree.mark != \"0\":\n",
    "            right.mark = tree.mark\n",
    "\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "\n",
    "        left.mark = right.mark\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "\n",
    "    def polarize_dep(self, tree):\n",
    "        self.full_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "\n",
    "    def polarize_det(self, tree):\n",
    "        self.full_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "        \n",
    "        \n",
    "        if(tree.counter.willing_verb):\n",
    "            tree.mark = \"=\"\n",
    "            left.mark = \"=\"\n",
    "            self.polarize(left)\n",
    "            right.mark = \"=\"\n",
    "            self.polarize(right)\n",
    "            return\n",
    "         \n",
    "        dettype = det_type(left.val)\n",
    "        if dettype is None:\n",
    "            dettype = self.DETEXIST\n",
    "\n",
    "        if left.val.lower() == \"any\":\n",
    "            has_roots = isinstance(tree.parent, BinaryDependencyTree)\n",
    "            has_roots = has_roots and isinstance(tree.parent.parent, BinaryDependencyTree)\n",
    "            if  has_roots:\n",
    "                negate_signal = tree.parent.parent.left\n",
    "                if negate_signal.val == \"not\":\n",
    "                    dettype = self.DETEXIST\n",
    "                if negate_signal.val == \"det\" and negate_signal.left.val.lower() == \"no\":\n",
    "                    dettype = self.DETEXIST\n",
    "                if tree.counter.addi_negates%2 == 1 :\n",
    "                    dettype = self.DETEXIST\n",
    "\n",
    "        detmark = det_mark[dettype]\n",
    "        right.mark = detmark\n",
    "        tree.mark = detmark\n",
    "        \n",
    "        if(left.val.lower() in det_type_words[\"det:univ\"] and \n",
    "           (right.val == \"cc\" and right.left.val.lower() == \"but\") and (right.right.val == \"nummod\")):\n",
    "            left.mark = \"+\"\n",
    "            right.mark = \"+\"\n",
    "            right.left.mark = \"+\"\n",
    "            right.right.mark = \"=\"\n",
    "            self.polarize(right.right)\n",
    "            return\n",
    "        \n",
    "        det = str((left.val, left.id))\n",
    "        at_least = self.replaced.get(det, \"det\").lower() in [\"at-least\", \"more-than\"]\n",
    "        at_most = self.replaced.get(det, \"det\").lower() in [\"at-most\", \"less-than\"]\n",
    "\n",
    "        if right.is_tree:\n",
    "            if right.val == \"nummod\":\n",
    "                right.mark = [detmark]\n",
    "            self.polarize(right)\n",
    "            if right.val == \"nummod\":\n",
    "                if at_least:\n",
    "                    right.left.mark = \"-\"\n",
    "                elif at_most:\n",
    "                    right.left.mark = \"+\"\n",
    "        elif right.pos == 'CD':\n",
    "            if at_least:\n",
    "                right.mark = \"-\"\n",
    "            elif at_most:\n",
    "                right.mark = \"+\"\n",
    "\n",
    "        if dettype == self.DETNEGATE:\n",
    "            if(at_most and tree.parent != None and tree.parent.val == \"case\"):\n",
    "                self.negate(tree, self.relation.index(tree.key))\n",
    "            else:\n",
    "                self.top_down_negate(tree, \"det\", self.relation.index(tree.key))\n",
    "\n",
    "        if \"not-\" in self.replaced.get(det, \"det\").lower() and len(self.replaced.get(det, \"det\").lower().split('-')) == 2:\n",
    "            self.negate(tree.parent, -1)\n",
    "\n",
    "    def polarize_expl(self, tree):\n",
    "        self.full_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "        \n",
    "        tree.counter.expl = True\n",
    "        \n",
    "        if self.dependtree.left.mark == \"-\":\n",
    "            right.mark = \"-\"\n",
    "\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "    def polarize_iobj(self, tree):\n",
    "        self.full_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "        \n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "        \n",
    "        tree.counter.originals[\"atLeastVerb\"].append(tree.counter.atLeastVerb)\n",
    "        vb = self.down_right(tree)\n",
    "        \n",
    "        if is_implicative(vb.val.lower(), 'at_least'):\n",
    "            tree.counter.atLeastVerb = True\n",
    "        \n",
    "        \n",
    "        if left.val.lower() == \"there\":\n",
    "            left.mark = \"+\"\n",
    "\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "        elif left.val.lower() == \"if\":\n",
    "            if(not(tree.parent != None and self.down_right(tree.parent).val in if_verbs)):\n",
    "                self.negate(right, -1)\n",
    "        tree.counter.atLeastVerb = tree.counter.originals[\"atLeastVerb\"].pop()\n",
    "        \n",
    "    def polarize_nmod(self, tree):\n",
    "        self.right_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if right.pos == \"DT\" or right.pos == \"CC\":\n",
    "            detType = det_type(right.val)\n",
    "            if detType == None:\n",
    "                detType = self.DETEXIST\n",
    "            left.mark = det_mark[detType][1]\n",
    "            if detType == \"det:negation\":\n",
    "                self.top_down_negate(\n",
    "                    tree, \"nmod\", self.relation.index(tree.key))\n",
    "        elif right.val.lower() in [\"many\", \"most\"]:\n",
    "            left.mark = \"=\"\n",
    "\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "\n",
    "        if left.val == \"case\":\n",
    "            if isinstance(tree.parent, BinaryDependencyTree):\n",
    "                if tree.parent.left.val.lower() == \"more\":\n",
    "                    left.right.mark = \"-\"\n",
    "\n",
    "        tree.mark = right.mark\n",
    "        if right.mark == \"-\":\n",
    "            if(self.down_left(left).val != \"than\"):\n",
    "                self.negate(left, -1)\n",
    "        elif right.mark == \"=\":\n",
    "            if right.left.val != \"the\":\n",
    "                self.equalize(left)\n",
    "            elif right.left.mark == \"-\":\n",
    "                self.negate(left, -1)\n",
    "\n",
    "    def polarize_nmod_poss(self, tree):\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        left.mark = tree.mark\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "        else:\n",
    "            left.mark = \"+\"\n",
    "\n",
    "        right.mark = tree.mark\n",
    "        if self.search_dependency(\"det\", tree.left):\n",
    "            right.mark = left.mark\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "        else:\n",
    "            right.mark = \"+\"\n",
    "\n",
    "    def polarize_nsubj(self, tree):\n",
    "        self.full_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "        self.nsubj_right_equal = False\n",
    "\n",
    "        if self.search_dependency(\"expl\", right):\n",
    "            self.polarize(left)\n",
    "            self.polarize(right)\n",
    "            return\n",
    "        \n",
    "        original_DetExist = tree.counter.nsubjDetExist\n",
    "        all_equal = False\n",
    "        \n",
    "        #increment counter\n",
    "        self.checkNot(tree.right, tree.counter)\n",
    "        if(self.findDet(tree.left, tree.counter)):\n",
    "            tree.counter.nsubjDetExist = True\n",
    "        else:\n",
    "            subj = self.down_right(tree.left)\n",
    "            if(subj.pos.lower() == \"nns\" or subj.pos.lower() == \"prp\") and self.numNotExist(tree.left):\n",
    "                tree.counter.nsubjDetExist = True\n",
    "        \n",
    "        vb = self.down_right(tree)\n",
    "        \n",
    "        if((left.val == \"det\" and left.left.val.lower() in det_type_words[\"det:univ\"]) \n",
    "           and (vb.parent.val == \"cc\" and vb.parent.left.val.lower() == \"but\")\n",
    "           and (left.right.val == \"nummod\")):\n",
    "            right.mark = \"=\"\n",
    "            tree.counter.originals[\"allBut\"].append(tree.counter.allBut)\n",
    "            tree.counter.allBut = True\n",
    "            self.polarize(right)\n",
    "            left.mark = \"+\"\n",
    "            left.left.mark = \"+\"\n",
    "            left.right.mark = \"=\"\n",
    "            self.polarize(left.right)\n",
    "            vb.parent.left.mark = \"+\"\n",
    "            tree.counter.allBut = tree.counter.originals[\"allBut\"].pop()\n",
    "            return\n",
    "            \n",
    "        \n",
    "        \n",
    "        self.polarize(right)\n",
    "        tree.counter.nsubjLeft = True\n",
    "        \n",
    "        if left.val.lower() == \"that\":\n",
    "            self.equalize(right)\n",
    "        if not tree.is_root:\n",
    "            if tree.parent.left.val.lower() == \"that\" and tree.parent.left.mark == \"=\":\n",
    "                self.equalize(left)\n",
    "\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "        else:\n",
    "            if left.val.lower() in [\"nobody\"]:\n",
    "                self.negate(tree, self.relation.index(tree.key))\n",
    "\n",
    "        if tree.mark == \"0\":\n",
    "            tree.mark = right.mark\n",
    "\n",
    "        if left.pos == \"NN\":\n",
    "            left.mark = tree.mark\n",
    "\n",
    "        if is_implicative(right.val.lower(), \"-\"):\n",
    "            tree.mark = \"-\"\n",
    "\n",
    "        if self.nsubj_right_equal:\n",
    "            self.equalize(right)\n",
    "        \n",
    "        tree.counter.nsubjDetExist = original_DetExist\n",
    "\n",
    "    def polarize_nummod(self, tree):\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "        \n",
    "        left.mark = \"=\"\n",
    "        if tree.mark != \"0\":\n",
    "            right.mark = tree.mark\n",
    "            if tree.mark == \"-\":\n",
    "                left.mark = \"-\"\n",
    "                right.mark = \"-\"\n",
    "            elif type(tree.mark) is list:\n",
    "                right.mark = tree.mark[0]\n",
    "                tree.mark = right.mark\n",
    "            elif tree.mark == \"--\":\n",
    "                left.mark = \"-\"\n",
    "                tree.mark = \"+\"\n",
    "            elif not(tree.counter.nsubjDetExist):\n",
    "                left.mark = \"=\"\n",
    "                right.mark = \"=\"\n",
    "            if tree.counter.atLeastVerb or tree.counter.ability_verb:\n",
    "                if(not(tree.counter.atLeastVerb and tree.counter.ability_verb)):\n",
    "                    left.mark = negate_mark[tree.mark]\n",
    "                right.mark = tree.mark\n",
    "      \n",
    "                \n",
    "        else:\n",
    "            right.mark = \"=\"\n",
    "        if left.val == \"det\":\n",
    "            left.mark = \"+\"\n",
    "\n",
    "        if tree.parent == \"compound\":\n",
    "            right.mark = left.mark\n",
    "\n",
    "        if left.is_tree:\n",
    "            if left.val == \"advmod\":\n",
    "                left.mark = \"+\"\n",
    "            self.polarize(left)\n",
    "            if left.mark == \"=\":\n",
    "                right.mark = left.mark\n",
    "                tree.mark = left.mark\n",
    "        elif left.id == 1:\n",
    "            left.mark = \"=\"\n",
    "            \"\"\"right.mark = \"=\"\n",
    "            self.nsubj_right_equal = True\"\"\"\n",
    "\n",
    "        if not tree.is_tree:\n",
    "            if is_implicative(tree.parent.right.val, \"-\"):\n",
    "                left.mark = \"-\"\n",
    "            elif is_implicative(tree.parent.right.val, \"=\"):\n",
    "                left.mark = \"=\"\n",
    "                \n",
    "        if(tree.counter.willing_verb):\n",
    "            left.mark = \"=\"\n",
    "            right.mark = \"=\"\n",
    "            tree.mark = \"=\"\n",
    "        \n",
    "       # if (tree.counter.is_unified_clause_subj() and tree.parent\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "    \n",
    "    def polarize_obj(self, tree):\n",
    "        self.right_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left        \n",
    "        \n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "        \n",
    "        tree.counter.originals[\"atLeastVerb\"].append(tree.counter.atLeastVerb)\n",
    "        vb = self.down_right(tree)\n",
    "        \n",
    "        if is_implicative(vb.val.lower(), 'at_least'):\n",
    "            tree.counter.atLeastVerb = True\n",
    "        \n",
    "        if tree.counter.atLeastVerb and tree.counter.ability_verb:\n",
    "                left.mark = \"-\"\n",
    "                \n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "\n",
    "        tree.counter.atLeastVerb = tree.counter.originals[\"atLeastVerb\"].pop()\n",
    "      \n",
    "        if is_implicative(right.val.lower(), \"-\"):\n",
    "            tree.mark = \"-\"\n",
    "            self.negate(left, -1)\n",
    "        \n",
    "            \n",
    "        \n",
    "        if left.val == \"mark\" and left.left.val == \"to\":\n",
    "            left.left.mark = right.mark\n",
    "\n",
    "    def polarize_obl(self, tree):\n",
    "        self.right_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        scalar_arrow = \"+\"\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "            try:\n",
    "                scalar_arrow = scalar_comparative[right.left.val][1]\n",
    "            except KeyError:\n",
    "                 pass\n",
    "        else:\n",
    "            try:\n",
    "                scalar_arrow = scalar_comparative[right.val][1]\n",
    "            except KeyError:\n",
    "                 pass\n",
    "\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "            if left.right.val == \"nummod\":\n",
    "                if(left.right.left.mark != \"-\"):\n",
    "                    left.right.left.mark = scalar_arrow\n",
    "            elif left.right.pos == \"CD\":\n",
    "                left.right.mark = scalar_arrow\n",
    "\n",
    "        if right.mark == \"-\":\n",
    "            self.negate(left, -1)\n",
    "\n",
    "    def polarize_oblnpmod(self, tree):\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "        right.mark = left.mark\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "\n",
    "    def polarize_inherite(self, tree):\n",
    "        self.full_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "\n",
    "        if left.val.lower() == \"there\":\n",
    "            left.mark = \"+\"\n",
    "\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "        elif left.val.lower() == \"if\":\n",
    "            if(not(tree.parent != None and self.down_right(tree.parent).val in if_verbs)):\n",
    "                self.negate(right, -1)\n",
    "\n",
    "    def search_dependency(self, deprel, tree):\n",
    "        if tree.val == deprel:\n",
    "            return True\n",
    "        else:\n",
    "            right = tree.right\n",
    "            left = tree.left\n",
    "\n",
    "            left_found = False\n",
    "            right_found = False\n",
    "\n",
    "            if right is not None and right.is_tree:\n",
    "                right_found = self.search_dependency(deprel, right)\n",
    "\n",
    "            if left is not None and left.is_tree:\n",
    "                left_found = self.search_dependency(deprel, left)\n",
    "\n",
    "            return left_found or right_found\n",
    "        \n",
    "    def checkNot(self, tree, counter):\n",
    "        if(tree.right == None or tree.val != \"advmod\"):\n",
    "            return\n",
    "        else:\n",
    "            if(tree.val == \"advmod\" and tree.left.val in [\"not\", \"n't\"]):\n",
    "                tree.counter.add_negates()\n",
    "            return self.checkNot(tree.right, counter)\n",
    "            \n",
    "    def findDet(self, tree, counter):\n",
    "        if(tree.right == None):\n",
    "            return False\n",
    "        else:\n",
    "            if(tree.val in [\"det\", \"amod\"] and tree.left.val.lower() in det_type_words[\"det:negation\"]):\n",
    "                counter.add_negates()\n",
    "                self.findDet(tree.right, counter)\n",
    "                return True\n",
    "            elif(tree.val in [\"det\"] and tree.left.val.lower() in det_type_words[\"det:univ\"]):\n",
    "                counter.add_unifies()\n",
    "                self.findDet(tree.right, counter)\n",
    "                return True\n",
    "            elif(tree.val in [\"det\"] and tree.left.val.lower() in det_type_words[\"det:exist\"]):\n",
    "                self.findDet(tree.right, counter)\n",
    "                return True\n",
    "            else:\n",
    "                return self.findDet(tree.right, counter)\n",
    "\n",
    "    def numNotExist(self, tree):\n",
    "        if(tree.right == None):\n",
    "            return True\n",
    "        else:\n",
    "            if(tree.val == \"nummod\"):\n",
    "                return False\n",
    "            return self.numNotExist(tree.right)\n",
    "        \n",
    "    def down_left(self,tree):\n",
    "        if(tree.left == None):\n",
    "            return tree\n",
    "        return self.down_left(tree.left)\n",
    "               \n",
    "    def down_right(self, tree):\n",
    "        if(tree.right == None):\n",
    "            return tree\n",
    "        return self.down_right(tree.right)\n",
    "               \n",
    "    def find_comparative(self, tree):\n",
    "        parent = tree.parent\n",
    "        \n",
    "      \n",
    "        #if(parent.val == \"nmod\"):\n",
    "        #    target = parent.right\n",
    "        #elif(parent.val == \"obl\"):\n",
    "        #    target = parent.right\n",
    "        modified, comp = self.find_right(parent, \"amod\")\n",
    "        if(modified is None):\n",
    "            return None, None\n",
    "        return modified, scalar_comparative[comp.val.lower()] \n",
    "    \n",
    "    def find_right(self, tree, val):\n",
    "        if(tree.right is None):\n",
    "            return None, None\n",
    "        if(tree.val == val):\n",
    "            comp = self.down_left(tree)\n",
    "            if comp.val.lower() in scalar_comparative:\n",
    "                return tree, comp\n",
    "            return self.find_right(tree.right, val)\n",
    "        return self.find_right(tree.right, val)\n",
    "\n",
    "    def find_comp_modifying(self, tree):\n",
    "        if(tree.val == \"amod\"):\n",
    "            return tree.right\n",
    "        if(tree.is_root):\n",
    "            return None\n",
    "        return self.find_comp_modifying(tree.parent)\n",
    "    \n",
    "    def noun_mark_replace(self, tree, mark):\n",
    "        if isinstance(tree, str):\n",
    "            return False\n",
    "        if tree.pos is not None and \"NN\" in tree.pos:\n",
    "            tree.mark = mark\n",
    "            return True\n",
    "        right = self.noun_mark_replace(tree.right, mark)\n",
    "        if not right:\n",
    "            self.noun_mark_replace(tree.left, mark)\n",
    "\n",
    "    def right_inheritance(self, tree):\n",
    "        if tree.mark != \"0\":\n",
    "            tree.right.mark = tree.mark\n",
    "        else:\n",
    "            tree.right.mark = \"+\"\n",
    "            tree.mark = \"+\"\n",
    "        tree.left.mark = \"+\"\n",
    "\n",
    "    def full_inheritance(self, tree):\n",
    "        if tree.mark != \"0\":\n",
    "            tree.right.mark = tree.mark\n",
    "            tree.left.mark = tree.mark\n",
    "        else:\n",
    "            tree.right.mark = \"+\"\n",
    "            tree.left.mark = \"+\"\n",
    "            tree.mark = \"+\"\n",
    "\n",
    "    def equalize(self, tree):\n",
    "        if tree.is_tree:\n",
    "            self.equalize(tree.right)\n",
    "            self.equalize(tree.left)\n",
    "            if tree.mark != \"0\":\n",
    "                tree.mark = \"=\"\n",
    "        else:\n",
    "            if tree.pos != \"CC\" and tree.val.lower() != \"when\":\n",
    "                tree.mark = \"=\"\n",
    "\n",
    "    def negate_condition(self, tree, anchor):\n",
    "        not_truth_connection = not tree.val in [\"and\", \"or\"]\n",
    "        not_empty_mark = tree.mark != \"0\"\n",
    "        return not_empty_mark and not_truth_connection\n",
    "\n",
    "    def top_down_negate(self, tree, deprel, anchor):\n",
    "        if not isinstance(tree.parent, BinaryDependencyTree):\n",
    "            return\n",
    "        if tree.parent.left.val == deprel:\n",
    "            self.negate(tree.parent.left, anchor)\n",
    "            self.negate(tree.parent.right, -1)\n",
    "        elif tree.parent.right.val == deprel:\n",
    "            self.negate(tree.parent.right, anchor)\n",
    "            self.negate(tree.parent.left, -1)\n",
    "\n",
    "    def negate(self, tree, anchor):\n",
    "        if isinstance(tree, str):\n",
    "            return\n",
    "        if tree.val == \"cc\" and tree.right.val in [\"expl\", \"nsubj\", \"det\"]:\n",
    "            return\n",
    "        if tree.val == \"mark\" and tree.left.val.lower() == \"if\" and tree.left.id < 3:\n",
    "            return\n",
    "        if tree.is_tree:\n",
    "            # print(tree.val)\n",
    "            if self.relation.index(tree.key) > anchor or \"nsubj\" in tree.val:\n",
    "                # print(tree.val)\n",
    "                self.negate(tree.right, anchor)\n",
    "                self.negate(tree.left, anchor)\n",
    "                if self.negate_condition(tree, anchor):\n",
    "                    tree.mark = negate_mark[tree.mark]\n",
    "        else:\n",
    "            if self.relation.index(tree.key) > anchor and self.negate_condition(tree, anchor):\n",
    "                if tree.pos != \"EX\":\n",
    "                    # print(tree.val)\n",
    "                    tree.mark = negate_mark[tree.mark]\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import svgling\n",
    "\n",
    "class PolarizationPipeline:\n",
    "    def __init__(self, sentences=None, verbose=0, parser=\"gum\"):\n",
    "        self.binarizer = Binarizer()\n",
    "        self.polarizer = Polarizer()\n",
    "        self.annotations = []\n",
    "        self.annotated_sentences = []\n",
    "        self.exceptioned = []\n",
    "        self.incorrect = []\n",
    "        self.verbose = verbose\n",
    "        self.parser = parser\n",
    "        self.sentences = sentences\n",
    "        self.num_sent = 0 if sentences is None else len(sentences)\n",
    "\n",
    "    def run_binarization(self, parsed, replaced, sentence):\n",
    "        self.binarizer.parse_table = parsed[0]\n",
    "        self.binarizer.postag = parsed[1]\n",
    "        self.binarizer.words = parsed[2]\n",
    "\n",
    "        if self.verbose == 2:\n",
    "            print()\n",
    "            print(parsed[0])\n",
    "            print()\n",
    "            print(parsed[1])\n",
    "            print()\n",
    "            print(replaced)\n",
    "\n",
    "        self.binarizer.replaced = replaced\n",
    "        binary_dep, relation = self.binarizer.binarization()\n",
    "        if self.verbose == 2:\n",
    "            self.postprocess(binary_dep)\n",
    "        return binary_dep, relation\n",
    "\n",
    "    def postprocess(self, tree, svg=False):\n",
    "        sexpression = btree2list(tree, 0)\n",
    "        if not svg:\n",
    "            sexpression = '[%s]' % ', '.join(\n",
    "                map(str, sexpression)).replace(\",\", \" \").replace(\"'\", \"\")\n",
    "        #print(sexpression)\n",
    "        return sexpression\n",
    "\n",
    "    def run_polarization(self, binary_dep, relation, replaced, sentence):\n",
    "        self.polarizer.dependtree = binary_dep\n",
    "        self.polarizer.relation = relation\n",
    "        self.polarizer.replaced = replaced\n",
    "\n",
    "        self.polarizer.polarize_deptree()\n",
    "        if self.verbose == 2:\n",
    "            self.postprocess(binary_dep)\n",
    "        elif self.verbose == 1:\n",
    "            polarized = self.postprocess(binary_dep)\n",
    "            svgling.draw_tree(polarized)\n",
    "            #jupyter_draw_rsyntax_tree(polarized)\n",
    "            #btreeViz = Tree.fromstring(polarized.replace('[', '(').replace(']', ')'))\n",
    "            #jupyter_draw_nltk_tree(btreeViz) \n",
    "    \n",
    "    def modify_replacement(self, tree, replace):\n",
    "        if str((tree.val,tree.id)) in replace:\n",
    "            tree.val = replace[str((tree.val,tree.id))]\n",
    "        \n",
    "        if tree.is_tree:\n",
    "            self.modify_replacement(tree.left, replace)\n",
    "            self.modify_replacement(tree.right, replace)\n",
    "\n",
    "    def single_polarization(self, sentence):\n",
    "        parsed, replaced = dependency_parse(sentence, self.parser)\n",
    "        #print(parsed)\n",
    "        binary_dep, relation = self.run_binarization(\n",
    "            parsed, replaced, sentence)\n",
    "        #print(parsed)\n",
    "        self.run_polarization(binary_dep, relation, replaced, sentence)\n",
    "        annotated = self.polarizer.dependtree.sorted_leaves()\n",
    "\n",
    "        if self.verbose == 2:\n",
    "            annotated_sent = ' '.join([word[0] for word in annotated.keys()])\n",
    "            self.annotated_sentences.append(annotated_sent)\n",
    "\n",
    "        self.modify_replacement(self.polarizer.dependtree, replaced)\n",
    "\n",
    "        return {\n",
    "            'original': sentence,\n",
    "            'annotated': annotated,\n",
    "            'polarized_tree': self.polarizer.dependtree,\n",
    "        }\n",
    "\n",
    "    def batch_polarization(self, sentences):\n",
    "        for i in tqdm(range(self.num_sent)):\n",
    "            sent = sentences[i]\n",
    "            try:\n",
    "                annotation = self.single_polarization(sent)\n",
    "                self.annotations.append(annotation)\n",
    "            except Exception as e:\n",
    "                if self.verbose == 2:\n",
    "                    print(str(e))\n",
    "                self.exceptioned.append(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('+', '+', '+', '+', '+', '-', '-')\n('+', '+', '+', '+', '+', '+', '-')\n('+', '=', '+', '+', '+', '+', '=')\n('+', '+', '+', '+', '+', '+', '-')\n('+', '+', '+', '+', '+', '+', '+', '+')\n"
     ]
    }
   ],
   "source": [
    "from svgling.figure import Caption, SideBySide, RowByRow\n",
    "\n",
    "# test comparative numerical inference              \n",
    "sentences = [\"John is less than 2 years older\",\n",
    "             \"A Number 5 is greater than 4\", \n",
    "             \"The exam is shorter than 5 hours\",\n",
    "             \"New York has more buildings than Dallas\",\n",
    "             \"There are some amazing hikes around Mt Fuji\"]\n",
    "\n",
    "pipeline = PolarizationPipeline(verbose=0)\n",
    "\n",
    "tree_visuals = []\n",
    "for sentence in sentences:\n",
    "    annotation = pipeline.single_polarization(sentence)\n",
    "    print(list(zip(*annotation['annotated'].popkeys()))[2])\n",
    "    #tree = pipeline.postprocess(annotation[\"polarized_tree\"])\n",
    "    #btree = Tree.fromstring(tree.replace('[', '(').replace(']', ')'))\n",
    "    #tree_visuals.append(svgling.draw_tree(tree1))\n",
    "    #jupyter_draw_nltk_tree(btree)\n",
    "#RowByRow(tree_visuals[0], tree_visuals[1], tree_visuals[2], tree_visuals[3], tree_visuals[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n[['nsubj', 1, 7], ['cc', 2, 3], ['conj-n', 3, 1], ['aux', 5, 7], ['advmod', 6, 7], ['root', 7, 'root'], ['amod', 8, 9], ['obj', 9, 7], ['advmod', 10, 7]]\n\n{'Tom': (1, 'NNP'), 'and': (2, 'CC'), 'John': (3, 'NNP'), ',': (4, ','), 'do': (5, 'VBP'), 'not': (6, 'RB'), 'eat': (7, 'VB'), 'fresh': (8, 'JJ'), 'meat': (9, 'NN'), 'anymore': (10, 'RB')}\n\n{}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('+', '+', '+', '-', '+', '-', '-', '-', '-')\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"Tom and John, do not eat fresh meat anymore\"]\n",
    "pipeline = PolarizationPipeline(verbose=2)\n",
    "for sentence in sentences:\n",
    "    annotation = pipeline.single_polarization(sentence)\n",
    "    tree = pipeline.postprocess(annotation[\"polarized_tree\"])\n",
    "    btree = Tree.fromstring(tree.replace('[', '(').replace(']', ')'))\n",
    "    jupyter_draw_nltk_tree(btree)\n",
    "    print(list(zip(*annotation['annotated'].popkeys()))[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There is a dog in the house who wants to eat three biscuits\n",
      "Udep2Mono: \n",
      "['There+', 'is+', 'a+', 'dog+', 'in+', 'the+', 'house=', 'who=', 'wants=', 'to=', 'eat=', 'three=', 'biscuits=']\n",
      "Suggested Solution: \n",
      "['There+', 'is+', 'a+', 'dog+', 'in+', 'the+', 'house=', 'who+', 'wants+', 'to+', 'eat+', 'three=', 'biscuits=']\n",
      "Five dogs see at least six cats\n",
      "Udep2Mono: \n",
      "['Five=', 'dogs=', 'see+', 'at+', 'least+', 'six-', 'cats+']\n",
      "Suggested Solution: \n",
      "['Five+', 'dogs=', 'see=', 'at=', 'least=', 'six=', 'cats=']\n",
      "No dentist who recommends that their patients brush their teeth at least four times a day gave five patients a toothbrush\n",
      "Udep2Mono: \n",
      "['No+', 'dentist-', 'who-', 'recommends-', 'that-', 'their-', 'patients-', 'brush-', 'their-', 'teeth-', 'at-', 'least-', 'four+', 'times-', 'a-', 'day-', 'gave-', 'five+', 'patients-', 'a-', 'toothbrush-']\n",
      "Suggested Solution: \n",
      "['No+', 'dentist-', 'who-', 'recommends-', 'that-', 'their-', 'patients-', 'brush-', 'their-', 'teeth-', 'at-', 'least-', 'four-', 'times-', 'a-', 'day-', 'gave-', 'five-', 'patients-', 'a-', 'toothbrush-']\n",
      "My parents said I could have three candies\n",
      "Udep2Mono: \n",
      "['My+', 'parents+', 'said+', 'I+', 'could+', 'have+', 'three-', 'candies-']\n",
      "Suggested Solution: \n",
      "['My+', 'parents+', 'said+', 'I+', 'could+', 'have+', 'three=', 'candies+']\n",
      "Every person who smokes two cigarettes in one hour runs a risk of cancer\n",
      "Udep2Mono: \n",
      "['Every+', 'person-', 'who-', 'smokes-', 'two+', 'cigarettes-', 'in-', 'one-', 'hour-', 'runs+', 'a+', 'risk+', 'of+', 'cancer+']\n",
      "Suggested Solution: \n",
      "['Every+', 'person-', 'who-', 'smokes-', 'two+', 'cigarettes-', 'in+', 'one-', 'hour-', 'runs+', 'a+', 'risk+', 'of+', 'cancer+']\n",
      "A dog who ate two rotten biscuits was sick for three days\n",
      "Udep2Mono: \n",
      "['A+', 'dog+', 'who+', 'ate+', 'two-', 'rotten+', 'biscuits+', 'was+', 'sick+', 'for+', 'three-', 'days-']\n",
      "Suggested Solution: \n",
      "['A+', 'dog+', 'who+', 'ate+', 'two=', 'rotten+', 'biscuits+', 'was+', 'sick+', 'for+', 'three-', 'days-']\n",
      "A dog ate 2 rotten biscuits\n",
      "Udep2Mono: \n",
      "['A+', 'dog+', 'ate+', '2-', 'rotten+', 'biscuits+']\n",
      "Suggested Solution: \n",
      "['A+', 'dog+', 'ate+', '2=', 'rotten+', 'biscuits+']\n",
      "Sentence Accuracy:  87.5\n",
      "Number of tokens:  481\n",
      "All-token Accuracy:  96.46569646569647\n",
      "Number of key tokens:  385\n",
      "Key-token Accuracy:  96.36363636363636\n"
     ]
    }
   ],
   "source": [
    "arrow_num = {\n",
    "    \"+\": 1,\n",
    "    \"-\": -1,\n",
    "    \"=\": 0\n",
    "}\n",
    "\n",
    "polarity_gold = pd.read_csv(\"Udep2Mono/polarity_gold.csv\")\n",
    "gold = zip(polarity_gold['Sentence'].tolist(), polarity_gold['Polarity'].tolist())\n",
    "\n",
    "num_tok = 0\n",
    "num_key_tok = 0\n",
    "num_correct = 0\n",
    "num_correct_tok = 0\n",
    "num_correct_key_tok = 0\n",
    "y_pred = []\n",
    "y_true = []\n",
    "y_pred_key = []\n",
    "y_true_key = []\n",
    "postags = []\n",
    "pipeline = PolarizationPipeline(verbose=0, parser=\"gum\")\n",
    "for sentence in gold:\n",
    "    annotation = pipeline.single_polarization(sentence[0])\n",
    "    #tree = pipeline.postprocess(annotation[\"polarized_tree\"],[])\n",
    "    #btree = Tree.fromstring(tree.replace('[', '(').replace(']', ')'))\n",
    "    #jupyter_draw_nltk_tree(btree)\n",
    "    annotate_info = list(zip(*annotation['annotated'].popkeys()))\n",
    "    pred_arrows = annotate_info[2]\n",
    "    label_arrows = sentence[1].split(' ')\n",
    "    predicted = [arrow_num[x] for x in pred_arrows]\n",
    "    label = [arrow_num[x] for x in label_arrows]\n",
    "    x = np.array(predicted)\n",
    "    y = np.array(label)\n",
    "    y_pred += list(x)\n",
    "    y_true += list(y)\n",
    "    num_tok += len(y)\n",
    "    pos = annotate_info[1]\n",
    "    postags.append(pos)\n",
    "    for i in range(len(pos)):\n",
    "        if 'NN' in pos[i] or 'VB' in pos[i] or 'JJ' in pos[i] or 'DT' in pos[i] or 'CD' in pos[i]:\n",
    "            y_pred_key.append(x[i])\n",
    "            y_true_key.append(y[i])\n",
    "            if x[i] == y[i]:\n",
    "                num_correct_key_tok += 1\n",
    "            num_key_tok += 1\n",
    "    if np.array_equal(x, y):\n",
    "        num_correct += 1\n",
    "        num_correct_tok += len(y)\n",
    "    else:\n",
    "        for i in range(len(predicted)):\n",
    "            if predicted[i] == label[i]:\n",
    "                num_correct_tok += 1\n",
    "        print(sentence[0])\n",
    "        list_pred = list(pred_arrows)\n",
    "        sent_list = sentence[0].split(\" \")\n",
    "        for i in range(len(sent_list)):\n",
    "            list_pred[i] = sent_list[i] + list_pred[i]\n",
    "            label_arrows[i] = sent_list[i] + label_arrows[i] \n",
    "        print(\"Udep2Mono: \")\n",
    "        print(list_pred)\n",
    "        print(\"Suggested Solution: \")\n",
    "        print(label_arrows)\n",
    "\n",
    "print(\"Sentence Accuracy: \", num_correct*100/56)\n",
    "print(\"Number of tokens: \", num_tok)\n",
    "print(\"All-token Accuracy: \", num_correct_tok*100/num_tok)\n",
    "print(\"Number of key tokens: \", num_key_tok)\n",
    "print(\"Key-token Accuracy: \", num_correct_key_tok*100/num_key_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[164   0   2]\n [  4  55   4]\n [  2   5 245]]\n              precision    recall  f1-score   support\n\n          -1      0.965     0.988     0.976       166\n           0      0.917     0.873     0.894        63\n           1      0.976     0.972     0.974       252\n\n    accuracy                          0.965       481\n   macro avg      0.952     0.944     0.948       481\nweighted avg      0.964     0.965     0.964       481\n\n[[133   0   2]\n [  4  49   4]\n [  1   3 189]]\n              precision    recall  f1-score   support\n\n          -1      0.964     0.985     0.974       135\n           0      0.942     0.860     0.899        57\n           1      0.969     0.979     0.974       193\n\n    accuracy                          0.964       385\n   macro avg      0.958     0.941     0.949       385\nweighted avg      0.963     0.964     0.963       385\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_true, y_pred))\n",
    "print(metrics.classification_report(y_true, y_pred, digits=3))\n",
    "print(metrics.confusion_matrix(y_true_key, y_pred_key))\n",
    "print(metrics.classification_report(y_true_key, y_pred_key, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sentence Accuracy:  50.0\nNumber of tokens:  481\nAll-token Accuracy:  77.54677754677755\nNumber of key tokens:  385\nKey-token Accuracy:  78.96103896103897\n"
     ]
    }
   ],
   "source": [
    "with open('gold.polarized.txt', 'r', encoding='utf-8') as ccg2mono:\n",
    "    output = ccg2mono.readlines()\n",
    "    num_tok = 0\n",
    "    num_key_tok = 0\n",
    "    num_correct = 0\n",
    "    num_correct_tok = 0\n",
    "    num_correct_key_tok = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    y_pred_key = []\n",
    "    y_true_key = []\n",
    "    \n",
    "    gold_labels = list(zip(polarity_gold['Sentence'].tolist(), polarity_gold['Polarity'].tolist()))\n",
    "    for j in range(len(output)):\n",
    "\n",
    "        pred_arrows = []\n",
    "        for token in output[j]:\n",
    "            if \"\\u2191\" in token:\n",
    "                pred_arrows.append('+')\n",
    "            elif \"\\u2193\" in token:\n",
    "                pred_arrows.append('-')\n",
    "            elif \"=\" in token:\n",
    "                pred_arrows.append('=')\n",
    "        label_arrows = gold_labels[j][1].split(' ')\n",
    "        predicted = [arrow_num[x] for x in pred_arrows]\n",
    "        label = [arrow_num[x] for x in label_arrows]\n",
    "        x = np.array(predicted)\n",
    "        y = np.array(label)\n",
    "\n",
    "        y_pred += list(x)\n",
    "        y_true += list(y)\n",
    "        \n",
    "        num_tok += len(y)\n",
    "        pos = postags[j]\n",
    "        for i in range(len(pos)):\n",
    "            if 'NN' in pos[i] or 'VB' in pos[i] or 'JJ' in pos[i] or 'DT' in pos[i] or 'CD' in pos[i]:\n",
    "                y_pred_key.append(x[i])\n",
    "                y_true_key.append(y[i])\n",
    "                if x[i] == y[i]:\n",
    "                    num_correct_key_tok += 1\n",
    "                num_key_tok += 1\n",
    "        if np.array_equal(x, y):\n",
    "            num_correct += 1\n",
    "            num_correct_tok += len(y)\n",
    "        else:\n",
    "            for i in range(len(predicted)):\n",
    "                if predicted[i] == label[i]:\n",
    "                    num_correct_tok += 1\n",
    "\n",
    "print(\"Sentence Accuracy: \", num_correct*100/56)\n",
    "print(\"Number of tokens: \", num_tok)\n",
    "print(\"All-token Accuracy: \", num_correct_tok*100/num_tok)\n",
    "print(\"Number of key tokens: \", num_key_tok)\n",
    "print(\"Key-token Accuracy: \", num_correct_key_tok*100/num_key_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[130  13  23]\n [  7  47   9]\n [ 35  21 196]]\n              precision    recall  f1-score   support\n\n          -1      0.756     0.783     0.769       166\n           0      0.580     0.746     0.653        63\n           1      0.860     0.778     0.817       252\n\n    accuracy                          0.775       481\n   macro avg      0.732     0.769     0.746       481\nweighted avg      0.787     0.775     0.779       481\n\n[[107   9  19]\n [  7  42   8]\n [ 22  16 155]]\n              precision    recall  f1-score   support\n\n          -1      0.787     0.793     0.790       135\n           0      0.627     0.737     0.677        57\n           1      0.852     0.803     0.827       193\n\n    accuracy                          0.790       385\n   macro avg      0.755     0.778     0.765       385\nweighted avg      0.796     0.790     0.792       385\n\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_true, y_pred))\n",
    "print(metrics.classification_report(y_true, y_pred, digits=3))\n",
    "print(metrics.confusion_matrix(y_true_key, y_pred_key))\n",
    "print(metrics.classification_report(y_true_key, y_pred_key, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sentence Accuracy:  28.571428571428573\nNumber of tokens:  481\nAll-token Accuracy:  69.85446985446985\nNumber of key tokens:  385\nKey-token Accuracy:  68.05194805194805\n"
     ]
    }
   ],
   "source": [
    "arrow_num = {\n",
    "    \"+\": 1,\n",
    "    \"-\": -1,\n",
    "    \"=\": 0\n",
    "}\n",
    "with open('natlog.txt', 'r', encoding='utf-8') as natlog:\n",
    "    output = natlog.readlines()\n",
    "    num_tok = 0\n",
    "    num_key_tok = 0\n",
    "    num_correct = 0\n",
    "    num_correct_tok = 0\n",
    "    num_correct_key_tok = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    y_pred_key = []\n",
    "    y_true_key = []\n",
    "    \n",
    "    gold_labels = list(zip(polarity_gold['Sentence'].tolist(), polarity_gold['Polarity'].tolist()))\n",
    "    for j in range(len(output)):\n",
    "        pred_arrows = output[j].replace('[','').replace(']','').replace('\\n','').replace(' ','').split(',')\n",
    "        label_arrows = gold_labels[j][1].split(' ')\n",
    "        predicted = [arrow_num[x] for x in pred_arrows]\n",
    "        label = [arrow_num[x] for x in label_arrows]\n",
    "        x = np.array(predicted)\n",
    "        y = np.array(label)\n",
    "\n",
    "        y_pred += list(x)\n",
    "        y_true += list(y)\n",
    "        \n",
    "        num_tok += len(y)\n",
    "        pos = postags[j]\n",
    "        for i in range(len(pos)):\n",
    "            if 'NN' in pos[i] or 'VB' in pos[i] or 'JJ' in pos[i] or 'DT' in pos[i] or 'CD' in pos[i]:\n",
    "                y_pred_key.append(x[i])\n",
    "                y_true_key.append(y[i])\n",
    "                if x[i] == y[i]:\n",
    "                    num_correct_key_tok += 1\n",
    "                num_key_tok += 1\n",
    "        if np.array_equal(x, y):\n",
    "            num_correct += 1\n",
    "            num_correct_tok += len(y)\n",
    "        else:\n",
    "            for i in range(len(predicted)):\n",
    "                if predicted[i] == label[i]:\n",
    "                    num_correct_tok += 1\n",
    "\n",
    "print(\"Sentence Accuracy: \", num_correct*100/56)\n",
    "print(\"Number of tokens: \", num_tok)\n",
    "print(\"All-token Accuracy: \", num_correct_tok*100/num_tok)\n",
    "print(\"Number of key tokens: \", num_key_tok)\n",
    "print(\"Key-token Accuracy: \", num_correct_key_tok*100/num_key_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[106   6  54]\n [ 19  10  34]\n [ 25   7 220]]\n              precision    recall  f1-score   support\n\n          -1      0.707     0.639     0.671       166\n           0      0.435     0.159     0.233        63\n           1      0.714     0.873     0.786       252\n\n    accuracy                          0.699       481\n   macro avg      0.619     0.557     0.563       481\nweighted avg      0.675     0.699     0.674       481\n\n[[ 83   6  46]\n [ 17   8  32]\n [ 17   5 171]]\n              precision    recall  f1-score   support\n\n          -1      0.709     0.615     0.659       135\n           0      0.421     0.140     0.211        57\n           1      0.687     0.886     0.774       193\n\n    accuracy                          0.681       385\n   macro avg      0.606     0.547     0.548       385\nweighted avg      0.655     0.681     0.650       385\n\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_true, y_pred))\n",
    "print(metrics.classification_report(y_true, y_pred, digits=3))\n",
    "print(metrics.confusion_matrix(y_true_key, y_pred_key))\n",
    "print(metrics.classification_report(y_true_key, y_pred_key, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There is a dog in the house who wants to eat three biscuits\n('+', '+', '+', '+', '+', '+', '=', '+', '+', '+', '+', '-', '+')\n['+', '+', '+', '+', '+', '+', '=', '+', '+', '+', '+', '=', '=']\n"
     ]
    }
   ],
   "source": [
    "sentences = [[\"There is a dog in the house who wants to eat three biscuits\", \n",
    "              ['+', '+', '+', '+', '+', '+', '=', '+', '+', '+', '+', '=', '=']]]\n",
    "pipeline = PolarizationPipeline(verbose=0, parser=\"ewt\")\n",
    "for sentence in sentences:\n",
    "    print(sentence[0])\n",
    "    annotation = pipeline.single_polarization(sentence[0])\n",
    "    #tree = pipeline.postprocess(annotation[\"polarized_tree\"])\n",
    "    #btree = Tree.fromstring(tree.replace('[', '(').replace(']', ')'))\n",
    "    #jupyter_draw_nltk_tree(btree)\n",
    "    print(list(zip(*annotation['annotated'].popkeys()))[2])\n",
    "    print(sentence[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sentences = [\"All the cats, except for at most two, eat chocolate\",\n",
    "             \"All the cats except for two, love to run\",\n",
    "             \"All students except engineers must take a class in Organic Chemistry\",\n",
    "             \"At most 6 dogs are hungry\",\n",
    "             \"At least 5 people ran\",\n",
    "             \"Less than 5 people ran\",\n",
    "             \"More than 6 dogs are hungry\",\n",
    "             \"Exactly 8 cats are sleeping\", \n",
    "             \"A dog ate 2 rotten biscuits\",\n",
    "             \"Some but not all students cheated in this class\",\n",
    "             \"More than three students cheated in this class\",\n",
    "             \"Less than five students got A in the class\",\n",
    "             \"Every dog who likes most cats was chased by at least two of them\",\n",
    "             \"Some person in the White House doesn't know if any dog in Ohio ate bananas yesterday\",\n",
    "             \"No dentist who recommends that their patients brush their teeth at least four times a day gave five patients a toothbrush\"]\n",
    "pipeline = PolarizationPipeline(verbose=0)\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    annotation = pipeline.single_polarization(sentence)\n",
    "    tree = pipeline.postprocess(annotation[\"polarized_tree\"])\n",
    "    btree = Tree.fromstring(tree.replace('[', '(').replace(']', ')'))\n",
    "    jupyter_draw_nltk_tree(btree)\n",
    "    print(list(zip(*annotation['annotated'].popkeys()))[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = [\"All dogs run\", \"Some dogs run\", \"No dog runs\", \n",
    "            \"All dogs eat apples\", \"Some dogs eat apples\", \"No dog eats apples\", \"That dog eats apples\",\n",
    "            \"Many dogs sleep at night. \", \"Most dogs sleep at night. \", \"A few dogs sleep at night. \",\n",
    "            \"At least 5 dogs sleep at night. \", \"At most five dogs eat dinner.\",\"Five dogs are chasing cats\",\n",
    "            \"All beautiful dogs eat apples\", \n",
    "            \"Some beautiful dogs eat apples\", \n",
    "            \"No beautiful dogs eat apples\", \n",
    "            \"All beautiful and smart dogs eat apples\", \n",
    "            \"No beautiful and smart dogs eat apples\",\n",
    "            \"Some beautiful and smart dogs eat apples\",\n",
    "            \"A smart and healthy person sleeps at night\",\n",
    "            \"Every smart and healthy people sleep at night\",\n",
    "            \"That tall and beautiful flower opens at night\",\n",
    "            \"A man is playing the piano happily\",\n",
    "            \"Every dog is excitedly chasing some cats\",\n",
    "            \"No dog is excitedly chasing some cats\",\n",
    "            \"All books here are beautifully printed and absolutely immaculate\"]\n",
    "            \n",
    "Conservativity = [\"No really great tenors are modest\", \"Some Italian tenors are great\", \n",
    "                  \"The really ambitious tenors are Italian\", \"Each Italian tenors wants to be great\",\n",
    "     ho wants to eat three biscuit\", ['+', '+', '+', '+', '+', '+', '=', '+', '+', '+', '+', '=', '=']],\n",
    "    [\"Few math students love any subject in linguistics\", ['+', '-', '-', '-', '-', '-', '-', '-']],\n",
    "    [\"Five dogs see at least six cats\", ['+', '=', '=', '=', '=', '=', '=']],\n",
    "    [\"Every cat who no dog chases, rests\", ['+', '-', '+', '-', '+', '+', '+']],\n",
    "    [\"Every dog who likes most cats was chased by at least two of them\", ['+', '-', '-', '-', '-', '=', '+', '+', '+', '+', '+', '-', '+', '+']],\n",
    "    [\"More dogs than cats sit\", ['+', '+', '+', '-', '=']],\n",
    "    [\"Fewer dogs than cats sit\", ['+', '-', '+', '+', '=']],\n",
    "    [\"Every student's favorite class was French\", ['+', '-', '-', '-', '-', '+', '+']],\n",
    "    [\"No students liked any class in Chemistry\", ['+', '-', '-', '-', '-', '-', '-']],\n",
    "    [\"All but five dogs died\", ['+', '+', '=', '=', '=']],\n",
    "    [\"Three out of five dentists recommend that their patients brush their teeth at least four times a day\", ['=', '-', '-', '=', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+', '-', '+', '+', '+']],\n",
    "    [\"No dentist who recommends that their patients brush their teeth at least four times a day gave five patients a toothbrush\", ['+', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']],\n",
    "    [\"Every doctor who told her patients to take three pills a day was afraid that taking four or more would kill them\", ['+', '-', '-', '-', '-', '-', '-', '-', '=', '=', '=', '=', '+', '+', '+', '+', '+', '+', '+', '+', '+', '+']],\n",
    "    [\"My parents said I could have three candies\", ['+', '+', '+', '+', '+', '+', '=', '+']],\n",
    "    [\"If you are addicted to cigarettes, you can smoke two a day\", ['+', '-', '-', '-', '-', '-', '+', '+', '+', '-', '+', '+']],\n",
    "    [\"Even if you are addicted to cigarettes, you can smoke two a day\", ['+', '+', '-', '-', '-', '-', '-', '+', '+', '+', '-', '+', '+']],\n",
    "    [\"Every person who smokes two cigarettes in one hour runs a risk of cancer\", ['+', '-', '-', '-', '+', '-', '+', '-', '-', '+', '+', '+', '+', '+']],\n",
    "    [\"If every cat runs, some dog runs also\", ['+', '-', '+', '-', '+', '+', '+', '+']],\n",
    "    [\"If some dog runs, no cat sits\", ['+', '-', '-', '-', '+', '-', '-']],\n",
    "    [\"A dog who ate two rotten biscuits was sick for three days\", ['+', '+', '+', '+', '=', '+', '+', '+', '+', '+', '-', '-']],\n",
    "    [\"John is dancing without clothes\", ['+', '+', '+', '+', '-']],\n",
    "    [\"Ursula refused to sing or dance\", ['+', '+', '+', '-', '+', '-']],\n",
    "    [\"A dog ate 2 rotten biscuits\", ['+', '+', '+', '=', '+', '+']],\n",
    "    [\"Any dog in Michigan would prefer to live in Indiana\", ['+', '-', '-', '-', '+', '+', '+', '+', '+', '+']],\n",
    "    [\"All the cats, except for at most two, eat chocolate\", ['+', '-', '=', '-', '-', '-', '-', '-', '=', '=']],\n",
    "    [\"All the cats except for two, love to run\", ['+', '-', '=', '-', '-', '=', '=', '=', '=']],\n",
    "    [\"All students except engineers must take a class in Organic Chemistry\", ['+', '-', '-', '=', '+', '+', '+', '+', '+', '+', '+']],\n",
    "    [\"At least seven fish died yesterday in Morocco\", ['+', '+', '-', '+', '+', '+', '+', '+']],\n",
    "    [\"At most 6 dogs are hungry\", ['+', '+', '+', '-', '-', '-']],\n",
    "    [\"At least 5 people ran\", ['+', '+', '-', '+', '+']],\n",
    "    [\"Less than 5 people ran\", ['+', '+', '+', '-', '-']],\n",
    "    [\"More than 6 dogs are hungry\", ['+', '+', '-', '+', '+', '+']],\n",
    "    [\"Exactly 8 cats are sleeping\", ['+', '=', '=', '=', '=']],\n",
    "    [\"Some but not all students cheated in this class\", ['+', '+', '+', '+', '+', '+', '+', '+', '=']],\n",
    "    [\"More than three students cheated in this class\", ['+', '+', '-', '+', '+', '+', '+', '=']],\n",
    "    [\"Less than five students got A in the class\", ['+', '+', '+', '-', '-', '-', '-', '-', '=']]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[g[0], ' '.join(g[1])] for g in gold]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Sentence', 'Polarity'])\n",
    "df.to_csv(\"Udep2Mono/polarity_gold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monotonicity_up_first = [\n",
    "    \"A Swede won a Nobel prize.\",\n",
    "    \"Every Swede is a Scandinavian.\",\n",
    "    \"A Scandinavian won a Nobel prize.\",\n",
    "    \"Every Canadian resident can travel freely within Europe.\",\n",
    "    \"Every Canadian resident is a resident of the North American continent.\",\n",
    "    \"Every resident of the North American continent can travel freely within Europe.\",\n",
    "    \"All Canadian residents can travel freely within Europe.\",\n",
    "    \"Every Canadian resident is a resident of the North American continent.\",\n",
    "    \"All residents of the North American continent can travel freely within Europe.\",\n",
    "    \"Each Canadian resident can travel freely within Europe.\",\n",
    "    \"Every Canadian resident is a resident of the North American continent.\",\n",
    "    \"Each resident of the North American continent can travel freely within Europe.\",\n",
    "    \"The residents of major western countries can travel freely within Europe.\",\n",
    "    \"All residents of major western countries are residents of western countries.\",\n",
    "    \"The residents of western countries have the right to live in Europe.\",\n",
    "    \"No Scandinavian delegate finished the report on time.\",\n",
    "    \"Some delegate finished the report on time.\",\n",
    "    \"Some Irish delegates finished the survey on time.\",\n",
    "    \"Some delegates finished the survey on time.\",\n",
    "    \"Many British delegates obtained interesting results from the survey.\",\n",
    "    \"Many delegates obtained interesting results from the survey.\",\n",
    "    \"Several Portuguese delegates got the results published in major national newspapers.\",\n",
    "    \"Several delegates got the results published in major national newspapers.\",\n",
    "    \"Most Europeans who are resident in Europe can travel freely within Europe.\",\n",
    "    \"Most Europeans can travel freely within Europe.\",\n",
    "    \"A few female committee members are from Scandinavia.\",\n",
    "    \"At least a few committee members are from Scandinavia.\",\n",
    "    \"Few female committee members are from southern Europe.\",\n",
    "    \"Few committee members are from southern Europe.\",\n",
    "    \"Both female commissioners used to be in business.\",\n",
    "    \"Neither female commissioner spends a lot of time at home.\",\n",
    "    \"One of the commissioners spends a lot of time at home.\",\n",
    "    \"At least three female commissioners spend time at home.\",\n",
    "    \"At least three commissioners spend time at home.\",\n",
    "    \"At most ten female commissioners spend time at home.\",\n",
    "    \"At most ten commissioners spend time at home.\"\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}