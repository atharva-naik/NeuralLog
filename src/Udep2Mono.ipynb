{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-04 00:20:59 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | gum       |\n",
      "| pos       | gum       |\n",
      "| lemma     | gum       |\n",
      "| depparse  | gum       |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-01-04 00:20:59 INFO: Use device: cpu\n",
      "2021-01-04 00:20:59 INFO: Loading: tokenize\n",
      "2021-01-04 00:20:59 INFO: Loading: pos\n",
      "2021-01-04 00:21:00 INFO: Loading: lemma\n",
      "2021-01-04 00:21:00 INFO: Loading: depparse\n",
      "2021-01-04 00:21:01 INFO: Loading: sentiment\n",
      "2021-01-04 00:21:02 INFO: Loading: ner\n",
      "2021-01-04 00:21:03 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import string\n",
    "import heapq\n",
    "import numpy as np\n",
    "from word2number import w2n\n",
    "from nltk.tree import Tree\n",
    "from nltk.draw import TreeWidget\n",
    "from nltk.draw.util import CanvasFrame\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# cd ./Desktop/Udep2Mono/NaturalLanguagePipeline/lib/stanford-corenlp-4.1.0\n",
    "# java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000\n",
    "\n",
    "import stanza\n",
    "from nltk.parse import CoreNLPParser\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "\n",
    "parser = CoreNLPParser(url='http://localhost:9000')\n",
    "dep_parser = CoreNLPDependencyParser(url='http://localhost:9000')\n",
    "\n",
    "nlp = stanza.Pipeline(\n",
    "    \"en\",\n",
    "    processors={\"tokenize\": \"gum\", \"pos\": \"gum\",\n",
    "                \"lemma\": \"gum\", \"depparse\": \"gum\"},\n",
    "    use_gpu=True,\n",
    "    pos_batch_size=2000\n",
    ")\n",
    "\n",
    "relations = [\n",
    "    \"acl\",\n",
    "    \"acl:relcl\",\n",
    "    \"advcl\",\n",
    "    \"advmod\",\n",
    "    \"advmod:count\",\n",
    "    \"amod\",\n",
    "    \"appos\",\n",
    "    \"aux\",\n",
    "    \"aux:pass\",\n",
    "    \"case\",\n",
    "    \"cc\",\n",
    "    \"cc:preconj\",\n",
    "    \"ccomp\",\n",
    "    \"clf\",\n",
    "    \"compound\",\n",
    "    \"compound:prt\",\n",
    "    \"conj\",\n",
    "    \"cop\",\n",
    "    \"csubj\",\n",
    "    \"csubj:pass\",\n",
    "    \"dep\",\n",
    "    \"det\",\n",
    "    \"det:predet\",\n",
    "    \"discourse\",\n",
    "    \"dislocated\",\n",
    "    \"expl\",\n",
    "    \"fixed\",\n",
    "    \"flat\",\n",
    "    \"goeswith\",\n",
    "    \"iobj\",\n",
    "    \"list\",\n",
    "    \"mark\",\n",
    "    \"nmod\",\n",
    "    \"nmod:poss\",\n",
    "    \"nmod:npmod\",\n",
    "    \"nmod:tmod\",\n",
    "    \"nmod:count\",\n",
    "    \"nsubj\",\n",
    "    \"nsubj:pass\",\n",
    "    \"nummod\",\n",
    "    \"obj\",\n",
    "    \"obl\",\n",
    "    \"obl:npmod\",\n",
    "    \"obl:tmod\",\n",
    "    \"orphan\",\n",
    "    \"parataxis\",\n",
    "    \"punct\",\n",
    "    \"reparandum\",\n",
    "    \"root\",\n",
    "    \"vocative\",\n",
    "    \"xcomp\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000\n",
    "\n",
    "replacement = {\n",
    "    \"out of\": \"out-of\",\n",
    "    \"none of the\": \"no\",\n",
    "    \"all of the\": \"all\",\n",
    "    \"some of the\": \"some\",\n",
    "    \"most of the\": \"most\",\n",
    "    \"many of the\": \"many\",\n",
    "    \"several of the\": \"several\",\n",
    "    \"some but not all\": \"some\",\n",
    "    \"at most\": \"at-most\",\n",
    "    \"at least\": \"at-least\",\n",
    "    \"more than\": \"more-than\",\n",
    "    \"less than\": \"less-than\",\n",
    "}\n",
    "\n",
    "def preprocess(sentence):\n",
    "    replaced = {}\n",
    "    processed = sentence.lower()\n",
    "    for orig in replacement:\n",
    "        if orig in processed:\n",
    "            processed = processed.replace(orig, replacement[orig])\n",
    "            replaced[replacement[orig]] = orig\n",
    "    return processed, replaced\n",
    "\n",
    "def dependency_parse(sentence, parser=\"stanford\"):\n",
    "    processed, replaced = preprocess(sentence)\n",
    "    if parser == \"stanford\":\n",
    "        return stanfordParse(processed), replaced\n",
    "    elif parser == \"stanza\":\n",
    "        return stanza_parse(processed), replaced\n",
    "\n",
    "def stanza_parse(sentence):\n",
    "    postags = {}\n",
    "    words = {}\n",
    "    parse_tree = []\n",
    "    head_log = {}\n",
    "    depdent_log = {}\n",
    "    parsed = nlp(sentence)\n",
    "\n",
    "    for sent in parsed.sentences:\n",
    "        for word in sent.words:\n",
    "            tree_node = post_process(sent, word, postags, words)\n",
    "\n",
    "            if len(tree_node) == 0:\n",
    "                continue\n",
    "\n",
    "            if tree_node[2] in head_log:\n",
    "                head_log[tree_node[2]].append(tree_node[0])\n",
    "            else:\n",
    "                head_log[tree_node[2]] = [tree_node[0]]\n",
    "\n",
    "            if tree_node[1] in depdent_log:\n",
    "                depdent_log[tree_node[1]].append(tree_node[0])\n",
    "            else:\n",
    "                depdent_log[tree_node[1]] = [tree_node[0]]\n",
    "\n",
    "            parse_tree.append(tree_node)\n",
    "\n",
    "        enhance_parse(parse_tree, head_log, depdent_log, words)\n",
    "    return parse_tree, postags, words\n",
    "\n",
    "def enhance_parse(tree, heads, deps, words):\n",
    "    for node in tree:\n",
    "        if node[0] == \"conj\":\n",
    "            if \"nsubj\" in heads[node[1]] and \"nsubj\" in heads[node[2]]:\n",
    "                node[0] = \"conj-sent\"\n",
    "            elif words[node[1]][1] == \"JJ\" and words[node[2]][1] == \"JJ\":\n",
    "                node[0] = \"conj-adj\"\n",
    "            elif \"NN\" in words[node[1]][1] and \"NN\" in words[node[2]][1]:\n",
    "                node[0] = \"conj-np\"\n",
    "            elif \"VB\" in words[node[1]][1] and \"VB\" in words[node[2]][1]:\n",
    "                node[0] = \"conj-vp\"\n",
    "                if not node[1] in deps and not node[2] in deps:\n",
    "                    node[0] = \"conj-vb\"\n",
    "        if node[0] == \"advcl\":\n",
    "            if words[1][0] == \"if\":\n",
    "                node[0] = \"advcl-sent\"\n",
    "        if node[0] == \"advmod\":\n",
    "            if words[node[1]][0] == \"not\" and node[1] == 1:\n",
    "                node[0] = \"advmod-sent\"\n",
    "        if node[0] == \"case\" and node[1] - node[2] > 0:\n",
    "            node[0] = \"case-after\"\n",
    "        if words[node[1]][0] in [\"at-most\", \"at-least\", \"more-than\", \"less-than\"]:\n",
    "            node[0] = \"det\"\n",
    "\n",
    "\n",
    "def post_process(sent, word, postag, words):\n",
    "    wordID = int(word.id)\n",
    "    if wordID not in words:\n",
    "        postag[word.text] = (wordID, word.xpos)\n",
    "        words[wordID] = (word.text, word.xpos)\n",
    "    if word.deprel != \"punct\":\n",
    "        tree_node = [word.deprel, wordID,\n",
    "                     word.head if word.head > 0 else \"root\"]\n",
    "        return tree_node\n",
    "    return []\n",
    "\n",
    "\n",
    "def printTree(tree, tag, word):\n",
    "    if tree[0] != \"root\":\n",
    "        print(\n",
    "            f\"word: {word[tree[1]][0]}\\thead: {word[tree[2]][0]}\\tdeprel: {tree[0]}\", sep=\"\\n\")\n",
    "\n",
    "\n",
    "def stanfordParse(sentence):\n",
    "    postag = {}\n",
    "    wordids = {}\n",
    "    tokens = {}\n",
    "    parse_tree = []\n",
    "    \n",
    "    tokenized = list(parser.tokenize(sentence))\n",
    "    for i in range(len(tokenized)):\n",
    "        tokens[tokenized[i]] = i+1\n",
    "        \n",
    "    parsed = list(dep_parser.raw_parse(sentence))[0]\n",
    "    dep_rels = parsed.to_conll(4).split('\\n')\n",
    "    for dep_rel in dep_rels:\n",
    "        rel = dep_rel.split('\\t')\n",
    "        if len(rel) == 4:\n",
    "            dependent = tokens[rel[0]]\n",
    "            govenor = int(rel[2])\n",
    "            relation = rel[3].lower()\n",
    "            postag[rel[0]] = (dependent, rel[1])\n",
    "            wordids[dependent] = (rel[0], rel[1])\n",
    "            if relation != \"punct\":\n",
    "                parse_tree.append([relation, dependent, govenor])\n",
    "    return parse_tree, postag, wordids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pqdict import pqdict\n",
    "\n",
    "\n",
    "class BinaryDependencyTree:\n",
    "    def __init__(self, val, left, right, key, id=None, pos=None):\n",
    "        self.val = val\n",
    "        self.parent = None\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.mark = \"0\"\n",
    "        self.id = id\n",
    "        self.pos = pos\n",
    "        self.key = key\n",
    "        self.is_root = False\n",
    "        self.is_tree = True\n",
    "        self.length = 0\n",
    "        self.leaves = pqdict({})\n",
    "\n",
    "    def sorted_leaves(self):\n",
    "        self.traverse(self)\n",
    "        return self.leaves\n",
    "\n",
    "    def traverse(self, tree):\n",
    "        if not tree.is_tree:\n",
    "            item = (tree.id)\n",
    "            key = (tree.val, tree.pos, tree.mark, tree.id)\n",
    "            self.leaves[key] = item\n",
    "        else:\n",
    "            self.traverse(tree.left)\n",
    "            self.traverse(tree.right)\n",
    "\n",
    "    def copy(self):\n",
    "        left = None\n",
    "        if self.left is not None:\n",
    "            left = self.left.copy()\n",
    "        right = None\n",
    "        if self.right is not None:\n",
    "            right = self.right.copy()\n",
    "        new_tree = BinaryDependencyTree(\n",
    "            self.val, left, right, self.key, self.id, self.pos)\n",
    "        new_tree.mark = self.mark\n",
    "        new_tree.parent = self.parent\n",
    "        new_tree.is_tree = self.is_tree\n",
    "        new_tree.is_root = self.is_root\n",
    "        new_tree.leaves = pqdict({})\n",
    "        return new_tree\n",
    "\n",
    "    def set_length(self, lth):\n",
    "        self.length = lth\n",
    "\n",
    "    def set_root(self):\n",
    "        self.is_root = True\n",
    "\n",
    "    def set_not_tree(self):\n",
    "        self.is_tree = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy = {\n",
    "    \"conj-sent\": 0,\n",
    "    \"advcl-sent\": 1,\n",
    "    \"advmod-sent\":2,\n",
    "    \"case\": 10,\n",
    "    \"case-after\": 75,\n",
    "    \"mark\": 10,\n",
    "    \"expl\": 10,\n",
    "    \"discourse\": 10,\n",
    "    \"nsubj\": 20,\n",
    "    \"csubj\": 20,\n",
    "    \"nsubj:pass\": 20,\n",
    "    \"conj-vp\": 25,\n",
    "    \"ccomp\": 30,\n",
    "    \"advcl\": 30,\n",
    "    \"advmod\": 30,\n",
    "    \"nmod\": 30,\n",
    "    \"nmod:tmod\": 30,\n",
    "    \"nmod:npmod\": 30,\n",
    "    \"nmod:poss\": 30,\n",
    "    \"xcomp\": 40,\n",
    "    \"aux\": 40,\n",
    "    \"aux:pass\": 40,\n",
    "    \"obj\": 60,\n",
    "    \"obl\": 50,\n",
    "    \"obl:tmod\": 50,\n",
    "    \"cop\": 50,\n",
    "    \"acl\": 60,\n",
    "    \"acl:relcl\": 60,\n",
    "    \"appos\": 60,\n",
    "    \"conj\": 60,\n",
    "    \"conj-np\": 60,\n",
    "    \"conj-adj\": 60,\n",
    "    \"det\": 70,\n",
    "    \"det:predet\": 70,\n",
    "    \"cc\": 70,\n",
    "    \"nummod\": 75,\n",
    "    \"compound\": 80,\n",
    "    \"amod\": 75,\n",
    "    \"conj-vb\": 90,\n",
    "    \"flat\": 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Binarizer:\n",
    "    def __init__(self, parse_table=None, postag=None, words=None):\n",
    "        self.postag = postag\n",
    "        self.parse_table = parse_table\n",
    "        self.words = words\n",
    "        self.id = 0\n",
    "\n",
    "    def process_not(self, children):\n",
    "        if len(children) > 1:\n",
    "            if children[0][0] == \"advmod\":\n",
    "                if self.words[children[1][1]][0] == \"not\":\n",
    "                    return [children[1]]\n",
    "        return children\n",
    "\n",
    "    def compose(self, head):\n",
    "        children = list(filter(lambda x: x[2] == head, self.parse_table))\n",
    "        children.sort(key=(lambda x: hierarchy[x[0]]))\n",
    "        children = self.process_not(children)\n",
    "\n",
    "        if len(children) == 0:\n",
    "            word = self.words[head][0]\n",
    "            tag = self.words[head][1]\n",
    "            binary_tree = BinaryDependencyTree(\n",
    "                word, None, None, self.id, head, tag)\n",
    "            self.id += 1\n",
    "            binary_tree.set_not_tree()\n",
    "            return binary_tree, [binary_tree.key]\n",
    "        else:\n",
    "            top_dep = children[0]\n",
    "        self.parse_table.remove(top_dep)\n",
    "\n",
    "        left, left_rel = self.compose(top_dep[1])\n",
    "        right, right_rel = self.compose(top_dep[2])\n",
    "        if \"conj\" in top_dep[0]:\n",
    "            dep_rel = \"conj\"\n",
    "        elif \"case\" in top_dep[0]:\n",
    "            dep_rel = \"case\"\n",
    "        elif \"advcl\" in top_dep[0]:\n",
    "            dep_rel = \"advcl\"\n",
    "        elif \"advmod\" in top_dep[0]:\n",
    "            dep_rel = \"advmod\"\n",
    "        else:\n",
    "            dep_rel = top_dep[0]\n",
    "\n",
    "        binary_tree = BinaryDependencyTree(dep_rel, left, right, self.id)\n",
    "        binary_tree.left.parent = binary_tree\n",
    "        binary_tree.right.parent = binary_tree\n",
    "\n",
    "        left_rel.append(binary_tree.key)\n",
    "        self.id += 1\n",
    "        return binary_tree, left_rel + right_rel\n",
    "\n",
    "    def binarization(self):\n",
    "        self.id = 0\n",
    "        self.relation = []\n",
    "        root = list(filter(lambda x: x[0] == \"root\", self.parse_table))[0][1]\n",
    "        binary_tree, relation = self.compose(root)\n",
    "        binary_tree.set_root()\n",
    "        binary_tree.length = len(self.words)\n",
    "        return binary_tree, relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import conjugate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "negate_mark = {\n",
    "    \"+\": \"-\",\n",
    "    \"-\": \"+\",\n",
    "    \"=\": \"=\"\n",
    "}\n",
    "\n",
    "det_mark = {\n",
    "    \"det:univ\": \"-\",\n",
    "    \"det:exist\": \"+\",\n",
    "    \"det:limit\": \"=\",\n",
    "    \"det:negation\": \"-\"\n",
    "}\n",
    "\n",
    "det_type_words = {\n",
    "    \"det:univ\": [\"all\", \"every\", \"each\", \"any\", \"all-of-the\"],\n",
    "    \"det:exist\": [\"a\", \"an\", \"some\", \"double\", \"triple\", \"some-of-the\", \"al-least\", \"more-than\"],\n",
    "    \"det:limit\": [\"such\", \"both\", \"the\", \"this\", \"that\",\n",
    "                  \"those\", \"these\", \"my\", \"his\", \"her\",\n",
    "                  \"its\", \"either\", \"both\", \"another\"],\n",
    "    \"det:negation\": [\"no\", \"neither\", \"never\", \"none\", \"none-of-the\", \"less-than\", \"at-most\"]\n",
    "}\n",
    "\n",
    "negtive_implicative = [\"refuse\", \"reject\", \"oppose\", \"forget\",\n",
    "                       \"hesitate\", \"without\", \"disapprove\", \"disagree\",\n",
    "                       \"eradicate\", \"erase\", \"dicline\", \"eliminate\",\n",
    "                       \"decline\", \"resist\", \"block\", \"stop\", \"hault\",\n",
    "                       \"disable\", \"disinfect\", \"disapear\", \"disgard\",\n",
    "                       \"disarm\", \"disarrange\", \"disallow\", \"discharge\",\n",
    "                       \"disbelieve\", \"disclaim\", \"disclose\", \"disconnect\",\n",
    "                       \"disconnect\", \"discourage\", \"discredit\", \"discorporate\",\n",
    "                       \"disengage\", \"disentangle\", \"dismiss\", \"disobeye\",\n",
    "                       \"distrust\", \"disrupt\", \"suspen\", \"suspend \",\n",
    "                       \"freeze\", \n",
    "                      ]\n",
    "\n",
    "at_least_implicative = [\"for\", \"buy\", \"drink\", \"take\", \"hold\", \"receive\",\n",
    "                        \"get\", \"catch\"]\n",
    "\n",
    "exactly_implicative = [\"like\", \"love\", \"admires\", \"marry\"]\n",
    "\n",
    "def build_implicative_dict():\n",
    "    verbs = list(df['Verb'])\n",
    "    signs = list(df['Signature'])\n",
    "    implicatives = {}\n",
    "    for i in range(len(verbs)):\n",
    "        implicatives[verbs[i]] = signs[i]\n",
    "    return implicatives\n",
    "\n",
    "implicatives = {} #build_implicative_dict()\n",
    "imp_types = {\n",
    "    '-': negtive_implicative,\n",
    "    'at_least': at_least_implicative,\n",
    "    '=': exactly_implicative\n",
    "}\n",
    "\n",
    "def is_implicative(word, imp_type):\n",
    "    verb = conjugate(word, tense=\"present\", person=1, number=\"singular\")\n",
    "    if imp_type in ['+', '-']:\n",
    "        if verb in implicatives:\n",
    "            return implicatives\n",
    "    return verb in imp_types[imp_type] \n",
    "\n",
    "def det_type(word):\n",
    "    for det in det_type_words:\n",
    "        if word.lower() in det_type_words[det]:\n",
    "            return det\n",
    "\n",
    "arrows = {\n",
    "    \"+\": \"\\u2191\",\n",
    "    \"-\": \"\\u2193\",\n",
    "    \"=\": \"=\",\n",
    "    \"0\": \"\"\n",
    "}\n",
    "\n",
    "arrow2int = {\n",
    "    \"\\u2191\": 1,\n",
    "    \"\\u2193\": -1,\n",
    "    \"=\": 0\n",
    "}\n",
    "\n",
    "def btree2list(binaryDepdency, replaced, verbose=2):\n",
    "    def to_list(tree):\n",
    "        treelist = []\n",
    "        if tree.is_tree:\n",
    "            word = tree.val + arrows[tree.mark]\n",
    "            if verbose == 2:\n",
    "                word += str(tree.key)\n",
    "            treelist.append(word)\n",
    "        else:\n",
    "            treelist.append(tree.pos)\n",
    "            word = tree.val.replace('-', ' ') + arrows[tree.mark]\n",
    "            if verbose == 2:\n",
    "                word += str(tree.key)\n",
    "            treelist.append(word)\n",
    "\n",
    "        if tree.left is not None:\n",
    "            treelist.append(to_list(tree.left))\n",
    "\n",
    "        if tree.right is not None:\n",
    "            treelist.append(to_list(tree.right))\n",
    "\n",
    "        return treelist\n",
    "    return to_list(binaryDepdency)\n",
    "\n",
    "def annotation2string(annotation):\n",
    "    annotated = list(annotation['annotated'].popkeys())\n",
    "    def compose_token(word):\n",
    "        if '-' in word[0]:\n",
    "            orig = word[0].split('-')\n",
    "            return ' '.join([x + arrows[word[2]] for x in orig])\n",
    "        else:\n",
    "            return word[0] + arrows[word[2]]\n",
    "    annotated_sent = ' '.join([compose_token(x) for x in annotated])\n",
    "    return annotated_sent\n",
    "\n",
    "\n",
    "def arrow2int(word):\n",
    "    if arrows['+'] in word:\n",
    "       return 1\n",
    "    elif arrows['-'] in word:\n",
    "        return -1\n",
    "    elif arrows['='] in word:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jupyter_draw_nltk_tree(tree):\n",
    "    cf = CanvasFrame()\n",
    "    tc = TreeWidget(cf.canvas(), tree)\n",
    "    tc['node_font'] = 'arial 14 bold'\n",
    "    tc['leaf_font'] = 'arial 14'\n",
    "    tc['node_color'] = '#005990'\n",
    "    tc['leaf_color'] = '#3F8F57'\n",
    "    tc['line_color'] = '#175252'\n",
    "    cf.add_widget(tc, 20, 20)\n",
    "    cf.print_to_file('../data/tree.ps')\n",
    "    cf.destroy()\n",
    "    os.system('magick convert ../data/tree.ps ../data/tree.png')\n",
    "    display(Image(filename='../data/tree.png'))\n",
    "    \n",
    "def jupyter_draw_rsyntax_tree(tree):\n",
    "    font_size = '8'\n",
    "    command = 'rsyntaxtree -s {} \"{}\"'.format(font_size, tree)\n",
    "    os.system(command)\n",
    "    display(Image(filename='./syntree.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Polarizer:\n",
    "    def __init__(self, dependtree=None, relation=None):\n",
    "        self.dependtree = dependtree\n",
    "        self.sentence_head = []\n",
    "        self.relation = relation\n",
    "        self.polarize_function = {\n",
    "            \"acl\": self.polarize_acl_relcl,\n",
    "            \"acl:relcl\": self.polarize_acl_relcl,\n",
    "            \"advcl\": self.polarize_acl_relcl,\n",
    "            \"advmod\": self.polarize_advmod,\n",
    "            \"advmod:count\": self.polarize_advmod,\n",
    "            \"amod\": self.polarize_amod,\n",
    "            \"appos\": self.polarize_inherite,\n",
    "            \"aux\": self.polarize_inherite,\n",
    "            \"aux:pass\": self.polarize_inherite,\n",
    "            \"case\": self.polarize_case,\n",
    "            \"cc\": self.polarize_cc,\n",
    "            \"cc:preconj\": self.polarize_det,\n",
    "            \"ccomp\": self.polarize_ccomp,\n",
    "            \"compound\": self.polarize_inherite,\n",
    "            \"compound:prt\": self.polarize_inherite,\n",
    "            \"conj\": self.polarize_inherite,\n",
    "            \"cop\": self.polarize_inherite,\n",
    "            \"csubj\": self.polarize_nsubj,\n",
    "            \"csubj:pass\": self.polarize_nsubj,\n",
    "            \"dep\": self.polarize_dep,\n",
    "            \"det\": self.polarize_det,\n",
    "            \"det:predet\": self.polarize_det,\n",
    "            \"discourse\": self.polarize_inherite,\n",
    "            \"expl\": self.polarize_expl,\n",
    "            \"fixed\": self.polarize_inherite,\n",
    "            \"flat\": self.polarize_inherite,\n",
    "            \"goeswith\": self.polarize_inherite,\n",
    "            \"iobj\": self.polarize_inherite,\n",
    "            \"mark\": self.polarize_inherite,\n",
    "            \"nmod\": self.polarize_nmod,\n",
    "            \"nmod:npmod\": self.polarize_nmod,\n",
    "            \"nmod:tmod\": self.polarize_nmod,\n",
    "            \"nmod:poss\": self.polarize_nmod_poss,\n",
    "            \"nsubj\": self.polarize_nsubj,\n",
    "            \"nsubj:pass\": self.polarize_nsubj,\n",
    "            \"nummod\": self.polarize_nummod,\n",
    "            \"obj\": self.polarize_obj,\n",
    "            \"obl\": self.polarize_obj,\n",
    "            \"obl:npmod\": self.polarize_oblnpmod,\n",
    "            \"obl:tmod\": self.polarize_inherite,\n",
    "            \"parataxis\": self.polarize_inherite,\n",
    "            \"xcomp\": self.polarize_obj,\n",
    "        }\n",
    "        self.tree_log = []\n",
    "        self.polar_log = []\n",
    "\n",
    "        self.DETEXIST = \"det:exist\"\n",
    "        self.DETNEGATE = \"det:negation\"\n",
    "\n",
    "    def polarize_deptree(self):\n",
    "        self.polarize(self.dependtree)\n",
    "\n",
    "    def polarize(self, tree):\n",
    "        if tree.is_tree:\n",
    "            self.polarize_function[tree.val](tree)\n",
    "\n",
    "    def polarize_acl_relcl(self, tree):\n",
    "        self.sentence_head.append(tree)\n",
    "        self.right_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "        \n",
    "        if right.id == 1:\n",
    "            right.mark = \"-\"\n",
    "\n",
    "        tree.mark = right.mark\n",
    "\n",
    "        if right.mark == \"-\" and left.pos != \"VBD\":\n",
    "            self.negate(left, -1)\n",
    "        elif right.mark == \"=\" and left.pos != \"VBD\":\n",
    "            self.equalize(left)\n",
    "        elif right.val == \"impossible\":\n",
    "            self.negate(left, -1)\n",
    "\n",
    "        self.sentence_head.pop()\n",
    "\n",
    "    def polarize_advmod(self, tree):\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "        self.polarize_inherite(tree)\n",
    "        root_mark = tree.mark\n",
    "\n",
    "        if left.val.lower() in [\"many\", \"most\"]:\n",
    "            right.mark = \"=\"\n",
    "            if isinstance(tree.parent, BinaryDependencyTree) and tree.parent.val == \"amod\":\n",
    "                self.equalize(tree.parent.right)\n",
    "        elif left.val.lower() in [\"not\", \"no\", \"n't\", \"never\"]:\n",
    "            self.negate(right, -1)\n",
    "        elif left.val.lower() in [\"exactly\"]:\n",
    "            self.equalize(tree.parent.parent)\n",
    "            left.mark = root_mark\n",
    "            tree.mark = right.mark\n",
    "\n",
    "        if left.val.lower() == \"when\":\n",
    "            self.equalize(self.dependtree)\n",
    "\n",
    "    def polarize_amod(self, tree):\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "        self.polarize_inherite(tree)\n",
    "\n",
    "        if left.val.lower() in [\"many\", \"most\"]:\n",
    "            self.equalize(right)\n",
    "            tree.mark = right.mark\n",
    "        elif left.val.lower() == \"fewer\":\n",
    "            self.noun_mark_replace(right, \"-\")\n",
    "        elif left.val == \"advmod\":\n",
    "            if left.right.val == \"many\":\n",
    "                self.equalize(right)\n",
    "                tree.mark = right.mark\n",
    "            if left.left.val.lower() == \"not\":\n",
    "                self.top_down_negate(\n",
    "                    tree, \"amod\", self.relation.index(tree.key))\n",
    "\n",
    "    def polarize_case(self, tree):\n",
    "        self.polarize_inherite(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if left.val == \"without\":\n",
    "            if right.is_tree:\n",
    "                self.polarize(right)\n",
    "            self.negate(tree, self.relation.index(left.key))\n",
    "        elif right.pos == \"CD\":\n",
    "            right.mark = \"=\"\n",
    "            if left.is_tree:\n",
    "                self.polarize(left)\n",
    "        elif right.val == \"nmod:poss\":\n",
    "            left.mark = \"=\"\n",
    "            if right.is_tree:\n",
    "                self.polarize(right)\n",
    "        elif left.val == \"except\":\n",
    "            right.mark = \"=\"\n",
    "            self.polarize(right)\n",
    "\n",
    "    def polarize_cc(self, tree):\n",
    "        self.full_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if right.val != \"expl\" and right.val != \"det\":\n",
    "            right.mark = tree.mark\n",
    "\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "\n",
    "        if left.id == 1:\n",
    "            self.equalize(right)\n",
    "\n",
    "    def polarize_ccomp(self, tree):\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if tree.mark != \"0\":\n",
    "            right.mark = tree.mark\n",
    "\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "\n",
    "        left.mark = right.mark\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "\n",
    "    def polarize_dep(self, tree):\n",
    "        self.full_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "\n",
    "    def polarize_det(self, tree):\n",
    "        self.full_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        dettype = det_type(left.val)\n",
    "        if dettype is None:\n",
    "            dettype = self.DETEXIST\n",
    "\n",
    "        if left.val.lower() == \"any\":\n",
    "            if isinstance(tree.parent, BinaryDependencyTree) and isinstance(tree.parent.parent, BinaryDependencyTree):\n",
    "                negate_signal = tree.parent.parent.left\n",
    "                if negate_signal.val == \"not\":\n",
    "                    dettype = self.DETEXIST\n",
    "                if negate_signal.val == \"det\" and negate_signal.left.val.lower() == \"no\":\n",
    "                    dettype = self.DETEXIST\n",
    "        \n",
    "        detmark = det_mark[dettype]\n",
    "        right.mark = detmark\n",
    "        tree.mark = detmark\n",
    "\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "\n",
    "        if dettype == self.DETNEGATE:\n",
    "            self.top_down_negate(tree, \"det\", self.relation.index(tree.key))\n",
    "\n",
    "        if right.val == \"nummod\":\n",
    "            if dettype == self.DETEXIST:\n",
    "                right.left.mark = \"-\"\n",
    "            elif dettype == self.DETNEGATE:\n",
    "                right.left.mark = \"+\"\n",
    "        if right.pos == 'CD':\n",
    "            if left.val == \"more-than\" or left.val == \"at-least\":\n",
    "                right.mark = \"-\"\n",
    "            if left.val == \"less-than\" or left.val == \"at-most\":\n",
    "                right.mark = \"+\"\n",
    "\n",
    "    def polarize_expl(self, tree):\n",
    "        self.full_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if self.dependtree.left.mark == \"-\":\n",
    "            right.mark = \"-\"\n",
    "\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "\n",
    "    def polarize_nmod(self, tree):\n",
    "        self.right_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if right.pos == \"DT\" or right.pos == \"CC\":\n",
    "            detType = det_type(right.val)\n",
    "            if detType == None:\n",
    "                detType = self.DETEXIST\n",
    "            left.mark = det_mark[detType][1]\n",
    "            if detType == \"det:negation\":\n",
    "                self.top_down_negate(\n",
    "                    tree, \"nmod\", self.relation.index(tree.key))\n",
    "        elif right.val.lower() in [\"many\", \"most\"]:\n",
    "            left.mark = \"=\"\n",
    "\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "\n",
    "        if left.val == \"case\":\n",
    "            if isinstance(tree.parent, BinaryDependencyTree):\n",
    "                if tree.parent.left.val.lower() == \"more\":\n",
    "                    left.right.mark = \"-\"\n",
    "\n",
    "        tree.mark = right.mark\n",
    "        if right.mark == \"-\":\n",
    "            self.negate(left, -1)\n",
    "        elif right.mark == \"=\":\n",
    "            self.equalize(left)\n",
    "\n",
    "    def polarize_nmod_poss(self, tree):\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        left.mark = tree.mark\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "        else:\n",
    "            left.mark = \"+\"\n",
    "\n",
    "        right.mark = tree.mark\n",
    "        if self.search_dependency(\"det\", tree.left):\n",
    "            right.mark = left.mark\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "        else:\n",
    "            right.mark = \"+\"\n",
    "\n",
    "    def polarize_nsubj(self, tree):\n",
    "        self.full_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if self.search_dependency(\"expl\", right):\n",
    "            self.polarize(left)\n",
    "            self.polarize(right)\n",
    "            return\n",
    "\n",
    "        self.polarize(right)\n",
    "\n",
    "        if left.val.lower() == \"that\":\n",
    "            self.equalize(right)\n",
    "        if not tree.is_root:\n",
    "            if tree.parent.left.val.lower() == \"that\":\n",
    "                self.equalize(left)\n",
    "\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "        else:\n",
    "            if left.val.lower() in [\"nobody\"]:\n",
    "                self.negate(tree, self.relation.index(tree.key))\n",
    "\n",
    "        if tree.mark == \"0\":\n",
    "            tree.mark = right.mark\n",
    "\n",
    "        if left.pos == \"NN\":\n",
    "            left.mark = tree.mark\n",
    "\n",
    "        if is_implicative(right.val.lower(), \"-\"):\n",
    "            tree.mark = \"-\"\n",
    "\n",
    "    def polarize_nummod(self, tree):\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        left.mark = \"=\"\n",
    "        if tree.mark != \"0\":\n",
    "            right.mark = tree.mark\n",
    "        else:\n",
    "            right.mark = \"+\"\n",
    "        \n",
    "        if left.val == \"det\":\n",
    "            left.mark = \"+\"\n",
    "\n",
    "        if tree.parent == \"compound\":\n",
    "            right.mark = left.mark\n",
    "\n",
    "        if left.is_tree:\n",
    "            if left.val == \"advmod\":\n",
    "                left.mark = \"+\"\n",
    "            self.polarize(left)\n",
    "            if left.mark == \"=\":\n",
    "                right.mark = left.mark\n",
    "                tree.mark = left.mark\n",
    "        elif left.id == 1:\n",
    "            left.mark = \"=\"\n",
    "\n",
    "        if not tree.is_tree:\n",
    "            if is_implicative(tree.parent.right.val, \"-\"):\n",
    "                left.mark = \"-\"\n",
    "            elif is_implicative(tree.parent.right.val, \"=\"):\n",
    "                left.mark = \"=\"\n",
    "\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "\n",
    "    def polarize_obj(self, tree):\n",
    "        self.right_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left        \n",
    "\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "\n",
    "        if is_implicative(right.val.lower(), \"-\"):\n",
    "            tree.mark = \"-\"\n",
    "            self.negate(left, -1)\n",
    "\n",
    "        if left.val == \"mark\" and left.left.val == \"to\":\n",
    "            left.left.mark = right.mark\n",
    "\n",
    "    def polarize_obl(self, tree):\n",
    "        self.right_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "\n",
    "        if right.mark == \"-\":\n",
    "            self.negate(left, -1)\n",
    "\n",
    "    def polarize_oblnpmod(self, tree):\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "        right.mark = left.mark\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "\n",
    "    def polarize_inherite(self, tree):\n",
    "        self.full_inheritance(tree)\n",
    "        right = tree.right\n",
    "        left = tree.left\n",
    "\n",
    "        if right.is_tree:\n",
    "            self.polarize(right)\n",
    "\n",
    "        if left.val.lower() == \"there\":\n",
    "            left.mark = \"+\"\n",
    "\n",
    "        if left.is_tree:\n",
    "            self.polarize(left)\n",
    "        elif left.val.lower() == \"if\":\n",
    "            self.negate(right, -1)\n",
    "\n",
    "    def search_dependency(self, deprel, tree):\n",
    "        if tree.val == deprel:\n",
    "            return True\n",
    "        else:\n",
    "            right = tree.right\n",
    "            left = tree.left\n",
    "\n",
    "            left_found = False\n",
    "            right_found = False\n",
    "\n",
    "            if right is not None and right.is_tree:\n",
    "                right_found = self.search_dependency(deprel, right)\n",
    "\n",
    "            if left is not None and left.is_tree:\n",
    "                left_found = self.search_dependency(deprel, left)\n",
    "\n",
    "            return left_found or right_found\n",
    "\n",
    "    def noun_mark_replace(self, tree, mark):\n",
    "        if isinstance(tree, str):\n",
    "            return False\n",
    "        if tree.pos is not None and \"NN\" in tree.pos:\n",
    "            tree.mark = mark\n",
    "            return True\n",
    "        right = self.noun_mark_replace(tree.right, mark)\n",
    "        if not right:\n",
    "            self.noun_mark_replace(tree.left, mark)\n",
    "\n",
    "    def right_inheritance(self, tree):\n",
    "        if tree.mark != \"0\":\n",
    "            tree.right.mark = tree.mark\n",
    "        else:\n",
    "            tree.right.mark = \"+\"\n",
    "            tree.mark = \"+\"\n",
    "        tree.left.mark = \"+\"\n",
    "\n",
    "    def full_inheritance(self, tree):\n",
    "        if tree.mark != \"0\":\n",
    "            tree.right.mark = tree.mark\n",
    "            tree.left.mark = tree.mark\n",
    "        else:\n",
    "            tree.right.mark = \"+\"\n",
    "            tree.left.mark = \"+\"\n",
    "            tree.mark = \"+\"\n",
    "\n",
    "    def equalize(self, tree):\n",
    "        if tree.is_tree:\n",
    "            self.equalize(tree.right)\n",
    "            self.equalize(tree.left)\n",
    "            if tree.mark != \"0\":\n",
    "                tree.mark = \"=\"\n",
    "        else:\n",
    "            if tree.pos != \"CC\" and tree.val.lower() != \"when\":\n",
    "                tree.mark = \"=\"\n",
    "\n",
    "    def negate_condition(self, tree, anchor):\n",
    "        not_truth_connection = not tree.val in [\"and\", \"or\"]\n",
    "        not_empty_mark = tree.mark != \"0\"\n",
    "        return not_empty_mark and not_truth_connection\n",
    "\n",
    "    def top_down_negate(self, tree, deprel, anchor):\n",
    "        if not isinstance(tree.parent, BinaryDependencyTree):\n",
    "            return\n",
    "        if tree.parent.left.val == deprel:\n",
    "            self.negate(tree.parent.left, anchor)\n",
    "            self.negate(tree.parent.right, -1)\n",
    "        elif tree.parent.right.val == deprel:\n",
    "            self.negate(tree.parent.right, anchor)\n",
    "            self.negate(tree.parent.left, -1)\n",
    "\n",
    "    def negate(self, tree, anchor):\n",
    "        if isinstance(tree, str):\n",
    "            return\n",
    "        if tree.val == \"cc\" and tree.right.val in [\"expl\", \"nsubj\", \"det\"]:\n",
    "            return\n",
    "        if tree.is_tree:\n",
    "            # print(tree.val)\n",
    "            if self.relation.index(tree.key) > anchor or \"nsubj\" in tree.val:\n",
    "                # print(tree.val)\n",
    "                self.negate(tree.right, anchor)\n",
    "                self.negate(tree.left, anchor)\n",
    "                if self.negate_condition(tree, anchor):\n",
    "                    tree.mark = negate_mark[tree.mark]\n",
    "        else:\n",
    "            if self.relation.index(tree.key) > anchor and self.negate_condition(tree, anchor):\n",
    "                if tree.pos != \"EX\":\n",
    "                    # print(tree.val)\n",
    "                    tree.mark = negate_mark[tree.mark]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class PolarizationPipeline:\n",
    "    def __init__(self, sentences=None, verbose=0, parser=\"stanza\"):\n",
    "        self.binarizer = Binarizer()\n",
    "        self.polarizer = Polarizer()\n",
    "        self.annotations = []\n",
    "        self.annotated_sentences = []\n",
    "        self.exceptioned = []\n",
    "        self.incorrect = []\n",
    "        self.verbose = verbose\n",
    "        self.parser = parser\n",
    "        self.sentences = sentences\n",
    "        self.num_sent = 0 if sentences is None else len(sentences)\n",
    "\n",
    "    def run_binarization(self, parsed, replaced, sentence):\n",
    "        self.binarizer.parse_table = parsed[0]\n",
    "        self.binarizer.postag = parsed[1]\n",
    "        self.binarizer.words = parsed[2]\n",
    "\n",
    "        if self.verbose == 2:\n",
    "            print()\n",
    "            print(parsed[0])\n",
    "            print()\n",
    "            print(parsed[1])\n",
    "\n",
    "        binary_dep, relation = self.binarizer.binarization()\n",
    "        if self.verbose == 2:\n",
    "            self.postprocess(binary_dep, replaced)\n",
    "        return binary_dep, relation\n",
    "\n",
    "    def postprocess(self, tree, replaced):\n",
    "        sexpression = btree2list(tree, replaced, 0)\n",
    "        sexpression = '[%s]' % ', '.join(\n",
    "            map(str, sexpression)).replace(\",\", \" \").replace(\"'\", \"\")\n",
    "        #print(sexpression)\n",
    "        return sexpression\n",
    "\n",
    "    def run_polarization(self, binary_dep, relation, replaced, sentence):\n",
    "        self.polarizer.dependtree = binary_dep\n",
    "        self.polarizer.relation = relation\n",
    "\n",
    "        self.polarizer.polarize_deptree()\n",
    "        if self.verbose == 2:\n",
    "            self.postprocess(binary_dep, replaced)\n",
    "        elif self.verbose == 1:\n",
    "            polarized = self.postprocess(binary_dep, replaced)\n",
    "            #jupyter_draw_rsyntax_tree(polarized)\n",
    "            btreeViz = Tree.fromstring(polarized.replace('[', '(').replace(']', ')'))\n",
    "            jupyter_draw_nltk_tree(btreeViz) \n",
    "\n",
    "    def single_polarization(self, sentence):\n",
    "        parsed, replaced = dependency_parse(sentence, self.parser)\n",
    "\n",
    "        binary_dep, relation = self.run_binarization(\n",
    "            parsed, replaced, sentence)\n",
    "        self.run_polarization(binary_dep, relation, replaced, sentence)\n",
    "        annotated = self.polarizer.dependtree.sorted_leaves()\n",
    "\n",
    "        if self.verbose == 2:\n",
    "            annotated_sent = ' '.join([word[0] for word in annotated.keys()])\n",
    "            self.annotated_sentences.append(annotated_sent)\n",
    "\n",
    "        return {\n",
    "            'original': sentence,\n",
    "            'annotated': annotated,\n",
    "            'polarized_tree': self.polarizer.dependtree,\n",
    "        }\n",
    "\n",
    "    def batch_polarization(self, sentences):\n",
    "        for i in tqdm(range(self.num_sent)):\n",
    "            sent = sentences[i]\n",
    "            try:\n",
    "                annotation = self.single_polarization(sent)\n",
    "                self.annotations.append(annotation)\n",
    "            except Exception as e:\n",
    "                if self.verbose == 2:\n",
    "                    print(str(e))\n",
    "                self.exceptioned.append(sent)\n",
    "\n",
    "    def polarize_eval(self, annotations_val=[]):\n",
    "        num_unmatched = 0\n",
    "        self.incorrect = []\n",
    "        self.annotations = []\n",
    "        self.verbose = 1\n",
    "\n",
    "        self.batch_polarization()\n",
    "\n",
    "        for i in tqdm(range(len(self.annotations))):\n",
    "            annotation = self.annotations[i]\n",
    "            annotated_sent = annotation2string(annotation)\n",
    "            \n",
    "            vec = [arrow2int(x) for x in annotated_sent.split(' ')]\n",
    "\n",
    "            if len(annotations_val) > 0:\n",
    "                annotation_val = annotations_val[i]\n",
    "                vec_val = convert2vector(annotation_val)\n",
    "                if len(vec) == len(vec_val):\n",
    "                    if not np.array_equal(vec, vec_val):\n",
    "                        num_unmatched += 1\n",
    "                        self.incorrect.append(\n",
    "                            (output[1], output[0], annotation_val, postags))\n",
    "                    if self.parser == \"stanford\":\n",
    "                        continue\n",
    "\n",
    "            validate = \"\"\n",
    "            if len(annotations_val) > 0:\n",
    "                validate = annotations_val[i]\n",
    "\n",
    "            self.annotations.append(\n",
    "                {\n",
    "                    \"annotated\": output[0],\n",
    "                    \"polarized\": output[2],\n",
    "                    \"validation\": validate,\n",
    "                    \"orig\": output[1],\n",
    "                    \"postag\": postags\n",
    "                }\n",
    "            )\n",
    "\n",
    "        print()\n",
    "        print(\"Number of unmatched sentences: \", num_unmatched)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:05<00:00,  9.60it/s]Correct annotation:  37\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Three dogs love four cats\\n',\n",
       " 'The dog that bark loudly, does not like any cat\\n',\n",
       " \"Some person in the White House doesn't know if any dog in Ohio ate bananas yesterday\\n\",\n",
       " 'There is a dog in the house, who wants to eat three biscuits\\n',\n",
       " 'Few math students love any subject in linguistics\\n',\n",
       " 'Five dogs see at least six cats\\n',\n",
       " 'More dogs than cats sit\\n',\n",
       " 'Fewer dogs than cats sit\\n',\n",
       " 'No students liked any class in Chemistry\\n',\n",
       " 'All but five dogs died\\n',\n",
       " 'All the cats except for two run\\n',\n",
       " 'All the cats except for at most two love chocolate\\n',\n",
       " 'Three out of five dentists recommend that their patients brush their teeth at least four times a day\\n',\n",
       " 'No dentist who recommends that their patients brush their teeth at least four times a day gave five patients a toothbrush\\n',\n",
       " 'Every doctor who told her patients to take three pills a day was afraid that taking four or more would kill them\\n',\n",
       " 'Even if you are addicted to cigarettes, you can smoke two a day\\n',\n",
       " 'Every person who smokes two cigarettes in one hour runs a risk of cancer\\n']"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "incorrect = []\n",
    "need_process = []\n",
    "num_correct = 0\n",
    "\n",
    "with open(\"Udep2Mono/gold.txt\", \"r\") as data:\n",
    "    with open(\"Udep2Mono/gold_label.txt\", \"r\") as label:\n",
    "        labels = label.readlines()\n",
    "        sentences = data.readlines()\n",
    "        pipeline = PolarizationPipeline(verbose=0)\n",
    "        \n",
    "        for i in tqdm(range(len(sentences))):\n",
    "            annotation = pipeline.single_polarization(sentences[i])\n",
    "            annotated_sent = annotation2string(annotation)\n",
    "            vec = [arrow2int(x) for x in annotated_sent.split(' ')]\n",
    "            label = [arrow2int(x) for x in labels[i].split(' ')]\n",
    "            \n",
    "            if len(vec) == len(label):\n",
    "                x = np.array(vec)\n",
    "                y = np.array(label)\n",
    "                if np.array_equal(x, y):\n",
    "                    num_correct += 1\n",
    "                else:\n",
    "                    incorrect.append(annotation['original'])\n",
    "            else:\n",
    "                need_process.append(annotation['original'])\n",
    "\n",
    "print(\"Correct annotation: \", num_correct)\n",
    "incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'all↑ but↑ five= dogs↑ died↑'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = PolarizationPipeline(verbose=1)\n",
    "annotate1 = pipeline.single_polarization(\"All but five dogs died\")\n",
    "#print(annotate1['annotated'])\n",
    "annotation2string(annotate1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A dog who ate two rotten biscuits was sick for three days \\n',\n",
       " 'Some but not all students cheated in this class\\n']"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"The dog that bark loudly, does not like any cat\", \n",
    "             \"Some person in the White House does not know if any dog in Ohio ate bananas yesterday\",\n",
    "             \"There is no person cutting a tomato\",\n",
    "             \"If every cat runs, some dogs run also\",\n",
    "             \"A dog who ate two rotten biscuits was sick for three days\"]\n",
    "pipeline = PolarizationPipeline(verbose=0)\n",
    "for sentence in sentences:\n",
    "    annotate1 = pipeline.single_polarization(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"More than 4 dogs ate food\", \n",
    "             \"Less than 5 dogs ate food\",\n",
    "             \"At least 5 dogs ate food\",\n",
    "             \"At most 5 dogs ate food\",\n",
    "             \"Exactly 5 dogs ate food\"]\n",
    "\n",
    "pipeline = PolarizationPipeline(verbose=0)\n",
    "for sentence in sentences1:\n",
    "    annotation = pipeline.single_polarization(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_polarize_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-179-1400159699a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m run_polarize_pipeline([\"Three out of five dentists recommend that their patients brush their teeth at least four times a day\", \n\u001b[0m\u001b[0;32m      2\u001b[0m                        \u001b[1;34m\"A dog who ate two rotten biscuits was sick for three days\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                        \u001b[1;34m\"No student refused to dance without shoes\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                        \u001b[1;34m\"Every member forgot to attend the meeting\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'run_polarize_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "run_polarize_pipeline([\"Three out of five dentists recommend that their patients brush their teeth at least four times a day\", \n",
    "                       \"A dog who ate two rotten biscuits was sick for three days\",\n",
    "            \n",
    "                       \"No student refused to dance without shoes\",\n",
    "                       \"Every member forgot to attend the meeting\", \n",
    "                       \"most young animals, who some beagle is afrid of, scratched most boxes\",\n",
    "                       \"The Police of the City of Baltimore sovled many crimes.\",\n",
    "                       \"The woman surrounded by fans wears a hat and glasses\"], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = [\"All dogs run\", \"Some dogs run\", \"No dog runs\", \n",
    "            \"All dogs eat apples\", \"Some dogs eat apples\", \"No dog eats apples\", \"That dog eats apples\",\n",
    "            \"Many dogs sleep at night. \", \"Most dogs sleep at night. \", \"A few dogs sleep at night. \",\n",
    "            \"At least 5 dogs sleep at night. \", \"At most five dogs eat dinner.\",\"Five dogs are chasing cats\",\n",
    "            \"All beautiful dogs eat apples\", \n",
    "            \"Some beautiful dogs eat apples\", \n",
    "            \"No beautiful dogs eat apples\", \n",
    "            \"All beautiful and smart dogs eat apples\", \n",
    "            \"No beautiful and smart dogs eat apples\",\n",
    "            \"Some beautiful and smart dogs eat apples\",\n",
    "            \"A smart and healthy person sleeps at night\",\n",
    "            \"Every smart and healthy people sleep at night\",\n",
    "            \"That tall and beautiful flower opens at night\",\n",
    "            \"A man is playing the piano happily\",\n",
    "            \"Every dog is excitedly chasing some cats\",\n",
    "            \"No dog is excitedly chasing some cats\",\n",
    "            \"All books here are beautifully printed and absolutely immaculate\"]\n",
    "run_polarize_pipeline([\"Todos los perros son agradables\", \n",
    "                       \"Ningún perro que muerda a la gente es agradable\"], verbose=2, parser=\"stanza\")\n",
    "\n",
    "Conservativity = [\"No really great tenors are modest\", \"Some Italian tenors are great\", \n",
    "              \"The really ambitious tenors are Italian\", \"Each Italian tenors wants to be great\",\n",
    "              \"Many great tenors are German\", \"Both leading tenors are excellent\",\n",
    "              \"Neither leading tenor comes cheap\",\n",
    "              \"At least three tenors will take part in the concert\", \n",
    "              \"At most two tenors will contribute their fees to charity\", \"One of the leading tenor is Pavarotti\"\n",
    "              \"Leading tenors who are excellent are indispensable\"]\n",
    "\n",
    "monotonicity = [\"An Irishman won the Nobel prize for literature.\", \"Every European has the right to live in Europe.\", \n",
    "                \"All Europeans have the right to live in Europe.\", \"Each European has the right to live in Europe.\",\n",
    "                \"Every European is a person.\",\n",
    "                \"Every person who has the right to live in Europe can travel freely within Europe.\", \n",
    "                \"An Italian became the world's greatest tenor\"]\n",
    "\n",
    "monotonicity_up_first = [\n",
    "    \"A Swede won a Nobel prize.\",\n",
    "    \"Every Swede is a Scandinavian.\",\n",
    "    \"A Scandinavian won a Nobel prize.\",\n",
    "    \"Every Canadian resident can travel freely within Europe.\",\n",
    "    \"Every Canadian resident is a resident of the North American continent.\",\n",
    "    \"Every resident of the North American continent can travel freely within Europe.\",\n",
    "    \"All Canadian residents can travel freely within Europe.\",\n",
    "    \"Every Canadian resident is a resident of the North American continent.\",\n",
    "    \"All residents of the North American continent can travel freely within Europe.\",\n",
    "    \"Each Canadian resident can travel freely within Europe.\",\n",
    "    \"Every Canadian resident is a resident of the North American continent.\",\n",
    "    \"Each resident of the North American continent can travel freely within Europe.\",\n",
    "    \"The residents of major western countries can travel freely within Europe.\",\n",
    "    \"All residents of major western countries are residents of western countries.\",\n",
    "    \"The residents of western countries have the right to live in Europe.\",\n",
    "    \"No Scandinavian delegate finished the report on time.\",\n",
    "    \"Some delegate finished the report on time.\",\n",
    "    \"Some Irish delegates finished the survey on time.\",\n",
    "    \"Some delegates finished the survey on time.\",\n",
    "    \"Many British delegates obtained interesting results from the survey.\",\n",
    "    \"Many delegates obtained interesting results from the survey.\",\n",
    "    \"Several Portuguese delegates got the results published in major national newspapers.\",\n",
    "    \"Several delegates got the results published in major national newspapers.\",\n",
    "    \"Most Europeans who are resident in Europe can travel freely within Europe.\",\n",
    "    \"Most Europeans can travel freely within Europe.\",\n",
    "    \"A few female committee members are from Scandinavia.\",\n",
    "    \"At least a few committee members are from Scandinavia.\",\n",
    "    \"Few female committee members are from southern Europe.\",\n",
    "    \"Few committee members are from southern Europe.\",\n",
    "    \"Both female commissioners used to be in business.\",\n",
    "    \"Neither female commissioner spends a lot of time at home.\",\n",
    "    \"One of the commissioners spends a lot of time at home.\",\n",
    "    \"At least three female commissioners spend time at home.\",\n",
    "    \"At least three commissioners spend time at home.\",\n",
    "    \"At most ten female commissioners spend time at home.\",\n",
    "    \"At most ten commissioners spend time at home.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polarization import run_polarize_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"SEG/quantifier\"\n",
    "filename = \"test/test.json\"\n",
    "path = os.path.join('../data', dataset)\n",
    "path = os.path.join(path, filename)\n",
    "out_path = os.path.join('../data', dataset)\n",
    "out_path = os.path.join(out_path, \"quantifier.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentence1', 'sentence2', 'gold_label', 'pairID', 'captionID'], dtype='object')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SICK_train = pd.read_json(path, lines=True)\n",
    "SICK_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "sentence_A = SICK_train['sentence1'].to_numpy()\n",
    "sentence_B = SICK_train['sentence2'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_path, 'w') as filehandle:\n",
    "    for listitem in sentence_A:\n",
    "        filehandle.write('%s\\n' % listitem)\n",
    "    for listitem in sentence_B:\n",
    "        filehandle.write('%s\\n' % listitem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
