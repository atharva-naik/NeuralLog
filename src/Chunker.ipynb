{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "npk143F1aOoA",
    "outputId": "f351c31c-8b3c-4102-bc6e-979840311d00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/eric11eca/NeuralLog/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bElyQ22XaXic",
    "outputId": "22760214-adb4-48c5-b4b5-e87b63b2c67c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is EE12-7525\n",
      "\n",
      " Directory of C:\\Users\\atnaik\\Downloads\\NeuralLog\\src\n",
      "\n",
      "20-07-2021  23:33    <DIR>          .\n",
      "20-07-2021  23:33    <DIR>          ..\n",
      "20-07-2021  23:31    <DIR>          .ipynb_checkpoints\n",
      "20-07-2021  23:30            81,798 Chunker.ipynb\n",
      "20-07-2021  23:28            20,112 Chunker.py\n",
      "20-07-2021  23:28            76,328 con_infer.ipynb\n",
      "20-07-2021  23:28            36,267 controller.py\n",
      "20-07-2021  23:31    <DIR>          DELETE\n",
      "20-07-2021  23:28             9,843 entail_imp.txt\n",
      "20-07-2021  23:28           197,157 generation_log.txt\n",
      "20-07-2021  23:28             6,819 generation_log_downward.txt\n",
      "20-07-2021  23:28            10,443 generation_log_downward_p.txt\n",
      "20-07-2021  23:28            19,414 generation_log_SICK.txt\n",
      "20-07-2021  23:28            41,926 generation_log_SICK_Improve.txt\n",
      "20-07-2021  23:28            21,070 generation_log_SICK_Neutral.txt\n",
      "20-07-2021  23:28             3,145 generation_log_upward.txt\n",
      "20-07-2021  23:28             7,920 generation_log_upward_p.txt\n",
      "20-07-2021  23:28             3,799 gold.polarized.txt\n",
      "20-07-2021  23:28         2,868,940 graph_matching_networks.ipynb\n",
      "20-07-2021  23:28            18,740 implicative_infer.ipynb\n",
      "20-07-2021  23:28            15,106 lexical_infer.ipynb\n",
      "20-07-2021  23:28             1,555 natlog.txt\n",
      "20-07-2021  23:28            57,356 phrasal_infer.ipynb\n",
      "20-07-2021  23:28             6,128 quantifier.json\n",
      "20-07-2021  23:28            19,069 SICK_entail_incorrect.txt\n",
      "20-07-2021  23:28            20,640 SICK_neutral_incorrect.txt\n",
      "20-07-2021  23:28           118,919 syntactic_variation.ipynb\n",
      "20-07-2021  23:28           365,080 theory_align.ipynb\n",
      "20-07-2021  23:28            14,847 transformers.ipynb\n",
      "20-07-2021  23:28    <DIR>          Udep2Mono\n",
      "20-07-2021  23:28           112,203 Udep2Mono.ipynb\n",
      "20-07-2021  23:28           172,520 UdepLog.ipynb\n",
      "20-07-2021  23:28             4,070 udify_parser.py\n",
      "20-07-2021  23:28             4,822 wordnet.py\n",
      "              29 File(s)      4,336,036 bytes\n",
      "               5 Dir(s)  109,440,495,616 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7cwe5mMxaZHc",
    "outputId": "5b4974bc-0464-4356-b3c1-e62eb078735d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LYV1nORBamL9",
    "outputId": "14ea3455-3310-499c-faeb-d5b76db16497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8TojU95a1xU",
    "outputId": "7d62e1df-a34d-4a41-8375-a80f92c93075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: binarytree in c:\\programdata\\anaconda3\\lib\\site-packages (6.3.0)\n",
      "Requirement already satisfied: setuptools>=42 in c:\\programdata\\anaconda3\\lib\\site-packages (from binarytree) (52.0.0.post20210125)\n",
      "Requirement already satisfied: graphviz in c:\\programdata\\anaconda3\\lib\\site-packages (from binarytree) (0.16)\n",
      "Requirement already satisfied: setuptools-scm[toml]>=3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from binarytree) (6.0.1)\n",
      "Requirement already satisfied: toml in c:\\users\\atnaik\\appdata\\roaming\\python\\python38\\site-packages (from setuptools-scm[toml]>=3.4->binarytree) (0.10.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install binarytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3jApjaeby5L",
    "outputId": "7f30a34c-6c18-4276-81fc-0b6f3defbcb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanza\n",
      "  Downloading stanza-1.2.2-py3-none-any.whl (337 kB)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-3.17.3-cp38-cp38-win_amd64.whl (909 kB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from stanza) (1.20.1)\n",
      "Collecting torch>=1.3.0\n",
      "  Downloading torch-1.9.0-cp38-cp38-win_amd64.whl (222.0 MB)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from stanza) (4.59.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from stanza) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n",
      "Requirement already satisfied: six>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from protobuf->stanza) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->stanza) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->stanza) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->stanza) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->stanza) (4.0.0)\n",
      "Installing collected packages: torch, protobuf, stanza\n",
      "Successfully installed protobuf-3.17.3 stanza-1.2.2 torch-1.9.0\n"
     ]
    }
   ],
   "source": [
    "# this is a stanfordNLP package for using Java CoreNLP parser etc. from python and other tools (https://github.com/stanfordnlp/stanza)\n",
    "!pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "4c5c7abb33fe44b4a8ecd12371f5194a",
      "894a549d042a45b19561238a4b0afe99",
      "291a4aaa8dd24e6fb12c3e8b8c8ec56b",
      "8ed74b1d3482486785f72546a4203efe",
      "1da6f1d7a5774dc4931b9c376b65411c",
      "f976781716b34693b9ab569fbf55649a",
      "7ae1130c699d4ae7bcbe28b027b9629b",
      "ac28f855322242258e947cafe0cdf46f",
      "7069310136b74f17883087c8ba9ea119",
      "dfab5adca25d4f399eb8789a1b48c3e7",
      "0a875081b61e401081ba106d0976cb3e",
      "9a552e7f9f864203a770cbd53600f9ed",
      "86dab5d84e9e47ee825aaabe39bcedc6",
      "8dddf754681d4e6ba209e9e705ccc1ad",
      "d36e06be25154c2fbd98c951dfa28460",
      "81840fd518154627aaed69b4dbc27a7d"
     ]
    },
    "id": "4K6Ah5u2cZa9",
    "outputId": "2f541504-cbed-47d8-950e-de8a7b29196a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24116436b34e49c391aaa68d5ee0347a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-20 23:37:10 INFO: Downloading default packages for language: en (English)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76eef3c02c85433082a534e2f56220e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading http://nlp.stanford.edu/software/stanza/1.2.2/en/default.zip:   0%|          | 0.00/412M [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import stanza # Download the stanza model or you will get this error: \n",
    "stanza.download('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rD_VNj-Ea8cD",
    "outputId": "c7f5f6bd-ead6-4df8-dfe3-1c96a377baa4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-20 06:00:13 INFO: Loading these models for language: en (English):\n",
      "========================================\n",
      "| Processor | Package                  |\n",
      "----------------------------------------\n",
      "| tokenize  | ../model/e...ize/gum.pt  |\n",
      "| pos       | ../model/en/pos/ewt.pt   |\n",
      "| lemma     | ../model/en/lemma/gum.pt |\n",
      "| depparse  | ../model/e...rse/gum.pt  |\n",
      "========================================\n",
      "\n",
      "2021-07-20 06:00:13 INFO: Use device: cpu\n",
      "2021-07-20 06:00:13 INFO: Loading: tokenize\n",
      "2021-07-20 06:00:13 ERROR: Cannot load model from ../model/en/tokenize/gum.pt\n"
     ]
    },
    {
     "ename": "LanguageNotDownloadedError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stanza/pipeline/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang, dir, package, processors, logging_level, verbose, use_gpu, model_dir, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m                                                                                           \u001b[0mpipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                                                                                           use_gpu=self.use_gpu)\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mProcessorRequirementsException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stanza/pipeline/processor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, pipeline, use_gpu)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_variant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_up_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stanza/pipeline/tokenize_processor.py\u001b[0m in \u001b[0;36m_set_up_model\u001b[0;34m(self, config, use_gpu)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stanza/models/tokenization/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, vocab, model_file, use_cuda)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m# load everything from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stanza/models/tokenization/trainer.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../model/en/tokenize/gum.pt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mLanguageNotDownloadedError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-54d7e710c563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwordnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_relation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_word_sets\u001b[0m \u001b[0;31m# internally defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mUdep2Mono\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPolarizationPipeline\u001b[0m \u001b[0;31m# internally defined Udep2Mono package.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/NeuralLog/src/Udep2Mono/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mUdep2Mono\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdependency_parse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUdep2Mono\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinarization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUdep2Mono\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUdep2Mono\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/NeuralLog/src/Udep2Mono/dependency_parse.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m }\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mgum_depparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstanza\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdepparse_gum_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;31m#ewt_depparse = stanza.Pipeline(**depparse_ewt_config)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstanza\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtoken_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stanza/pipeline/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang, dir, package, processors, logging_level, verbose, use_gpu, model_dir, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                         \u001b[0;31m# model files for this language can't be found in the expected directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mLanguageNotDownloadedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mprocessor_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresources\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                         \u001b[0;31m# user asked for a model which doesn't exist for this language?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLanguageNotDownloadedError\u001b[0m: Could not find the model file ../model/en/tokenize/gum.pt.  The expected model directory ../model/en is missing.  Perhaps you need to run stanza.download(\"en\")"
     ]
    }
   ],
   "source": [
    "import binarytree as bt # pip install binarytree\n",
    "from nltk.tree import Tree\n",
    "from nltk.draw import TreeWidget\n",
    "from PIL import Image, ImageDraw\n",
    "from nltk.draw.util import CanvasFrame\n",
    "from IPython.display import Image, display \n",
    "from wordnet import find_relation, get_word_sets # internally defined\n",
    "from Udep2Mono.polarization import PolarizationPipeline # internally defined Udep2Mono package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "wxA0lKCPZp5Q"
   },
   "outputs": [],
   "source": [
    "nounModifiers = {\"det\", \"nummod\", \"amod\", \"obl:tmod\",\n",
    "                 \"acl:relcl\", \"nmod\", \"case\", \"nmod:pass\",  \"acl\", \"Prime\",\"cc\"}\n",
    "verbModifiers = {\"advmod\", \"obl\",\"xcomp\",\"advcl\",\"mark\",\"aux\"}\n",
    "nounCategories = {\"compound\"}\n",
    "verbs = {\"VBZ\", \"VBP\", \"VBD\", \"VBG\"}\n",
    "modified = {\"NN\", \"PRP\", \"JJ\", \"VB\"}.union(verbs)\n",
    "modifiers = nounModifiers.union(verbModifiers)\n",
    "offFocus = {\"expl\"}\n",
    "contents = {\"nsubj\", \"obj\", \"cop\", \"compound\",\n",
    "            \"conj\", \"nsubj:pass\"}\n",
    "cont_npos = {\"nsubj\": 'nn', \"obj\": 'nn', \"cop\": 'vbz', \"verb\": 'vbz'}\n",
    "mark_toProp = {\"+\": {\"hyponym\", \"synonym\"},\n",
    "               \"-\": {\"hypernym\", \"synonym\"}, \"=\": {\"synonym\"}}\n",
    "clause_prop = {\"which\", \"that\", \"who\"}\n",
    "be_verbs = {\"is\", \"am\", \"are\", \"be\"}\n",
    "directions = {0: \"lexical\", 1: \"phrasal\",\n",
    "              2: \"syntatic_variation\", 3: \"implicative\"}\n",
    "arrows = {\n",
    "    \"+\": \"\\u2191\",\n",
    "    \"-\": \"\\u2193\",\n",
    "    \"=\": \"=\",\n",
    "    \"0\": \"\"\n",
    "}\n",
    "\n",
    "\n",
    "def annotation2string(annotation):\n",
    "    '''self contained function, no change needed.'''\n",
    "    annotated = list(annotation['annotated'].popkeys())\n",
    "\n",
    "    def compose_token(word):\n",
    "        if '-' in word[0]:\n",
    "            orig = word[0].split('-')\n",
    "            return ' '.join([x + arrows[word[2]] for x in orig])\n",
    "        else:\n",
    "            return word[0] + arrows[word[2]]\n",
    "    annotated_sent = ' '.join([compose_token(x) for x in annotated])\n",
    "    return annotated_sent\n",
    "\n",
    "\n",
    "class Unode:\n",
    "    def __init__(self, prop, word, npos, mark):\n",
    "        self.nexts = dict()\n",
    "        self.prop = prop\n",
    "        self.isRoot = False\n",
    "        self.nexts[\"all\"] = set()\n",
    "        self.word = word\n",
    "        self.npos = npos\n",
    "        self.mark = mark\n",
    "        self.phrases = set()\n",
    "        self.pair = -1\n",
    "        self.pairParts = dict()\n",
    "        self.start = -1\n",
    "        self.end = -1\n",
    "        self.nodes = set()\n",
    "        self.cc = None\n",
    "        \n",
    "    def add_Unode(self, node):\n",
    "        # print(node.prop)\n",
    "        if(self.isRoot):\n",
    "            self.nexts[node.prop].add(node)\n",
    "        else:\n",
    "            self.nexts[\"all\"].add(node)\n",
    "\n",
    "    def addNode(self, node):\n",
    "        self.nodes.add(node)\n",
    "\n",
    "    def getText(self):\n",
    "        if(self.isRoot):\n",
    "            output = \"\"\n",
    "            for cont in [\"nsubj\", \"verb\", \"obj\"]:\n",
    "                for ele in self.nexts[cont]:\n",
    "                    output += ele.getText()\n",
    "                    output += \" \"\n",
    "            return output.strip()\n",
    "        else:\n",
    "            if(self.nexts[\"all\"] == set()):\n",
    "                return self.word\n",
    "            output = self.word\n",
    "            for element in self.nexts[\"all\"]:\n",
    "                if(element.prop == \"amod\"):\n",
    "                    output = \" \" + output\n",
    "                    output = element.getText() + output\n",
    "                else:\n",
    "                    output += \" \"\n",
    "                    output += element.getText()\n",
    "\n",
    "            return output\n",
    "\n",
    "    def get_inText(self, index):\n",
    "        connected_info = \"\"\n",
    "        if(self.isRoot):\n",
    "            for key in self.nexts.keys():\n",
    "                if(key != \"all\"):\n",
    "                    print(key)\n",
    "                    for keyItem in self.nexts[key]:\n",
    "                        connected_info += (key + \": \" +\n",
    "                                           keyItem.get_inText(index + 1) + \" \")\n",
    "            return \"{ \" + connected_info + \"}\"\n",
    "        else:\n",
    "            for node in self.nexts[\"all\"]:\n",
    "                if(node != None):\n",
    "                    # print(\"111\")\n",
    "                    connected_info += node.get_inText(index + 1)\n",
    "            return \"{ The \" + str(index) + \" layer\" + \": \" + self.word + connected_info + \"}\"\n",
    "\n",
    "    def get_magicText(self):\n",
    "        connected_info = \"\"\n",
    "        if(self.isRoot):\n",
    "            for key in self.nexts.keys():\n",
    "                component = \"\"\n",
    "                if(key != \"all\"):\n",
    "                    print(key)\n",
    "                    for keyItem in self.nexts[key]:\n",
    "                        component += \" (\" + keyItem.get_magicText() + \")\"\n",
    "                    component = \"(\" + key + \" \" + component + \")\"\n",
    "                connected_info += component\n",
    "            return \"(\" + connected_info + \")\"\n",
    "        else:\n",
    "            for node in self.nexts[\"all\"]:\n",
    "                if(node != None):\n",
    "                    # print(\"111\")\n",
    "                    connected_info += \"(\" + node.get_magicText() + \")\"\n",
    "            if(self.nexts[\"all\"] == set()):\n",
    "                if(self.pair != -1):\n",
    "                    return self.word + str(self.pair)\n",
    "                return self.word\n",
    "            if(self.pair != -1):\n",
    "                return self.word + str(self.pair) + connected_info\n",
    "            return self.word + connected_info\n",
    "\n",
    "    def addNum(self, num):\n",
    "        self.pair = num\n",
    "\n",
    "    def addPart(self, newNode, type1):\n",
    "        if(type1 not in self.pairParts):\n",
    "            self.pairParts[type1] = set()\n",
    "        self.pairParts[type1].add(newNode)\n",
    "\n",
    "    def getParts(self):\n",
    "        # return verb-obj subParts now\n",
    "        return self.pairParts[\"obj\"]\n",
    "    def addCC(self,node):\n",
    "        self.cc = node\n",
    "\n",
    "class PairCounter:\n",
    "    def __init__(self, initial=0):\n",
    "        self.nsubj = initial\n",
    "        self.obj = initial\n",
    "\n",
    "    def incrementN(self):\n",
    "        self.nsubj += 1\n",
    "\n",
    "    def incrementO(self):\n",
    "        self.obj += 1\n",
    "\n",
    "\n",
    "class Ugraph:\n",
    "    def __init__(self, rootNode):\n",
    "        self.root = rootNode\n",
    "        self.root.isRoot = True\n",
    "        self.root.nexts.pop(\"all\", None)\n",
    "        for main in {\"nsubj\", \"obj\", \"verb\"}:\n",
    "            self.root.nexts[main] = set()\n",
    "        self.nodes = set()\n",
    "        self.contentSet = set()\n",
    "        self.chunks = set()\n",
    "        self.Pairs = dict()\n",
    "        self.Pairs[\"nsubj\"] = dict()\n",
    "        self.Pairs[\"obj\"] = dict()\n",
    "\n",
    "    def add_node(self, node):\n",
    "        self.nodes.add(node)\n",
    "        self.root.addNode(node)\n",
    "\n",
    "    def add_edge(self, node1, node2):\n",
    "        if(node1.isRoot):\n",
    "            self.contentSet.add(node2.word)\n",
    "        node1.add_Unode(node2)\n",
    "\n",
    "    def contains(self, word_assigned):\n",
    "        return word_assigned in self.contentSet\n",
    "\n",
    "    def get_magicText(self):\n",
    "        return self.root.get_magicText()\n",
    "\n",
    "    def addPair(self, newNode, num, type1):\n",
    "        newNode.addNum(num)\n",
    "        if(num not in self.Pairs[type1]):\n",
    "            self.Pairs[type1][num] = [None]\n",
    "        if(newNode.prop == \"verb\"):\n",
    "            self.Pairs[type1][num][0] = newNode\n",
    "        else:\n",
    "            self.Pairs[type1][num].append(newNode)\n",
    "        if(len(self.Pairs[type1][num]) > 1 and self.Pairs[type1][num][0] is not None):\n",
    "            if(newNode.prop == \"verb\"):\n",
    "                self.Pairs[type1][num][0].addPart(\n",
    "                    self.Pairs[type1][num][-1], \"obj\")\n",
    "            else:\n",
    "                self.Pairs[type1][num][0].addPart(newNode, \"obj\")\n",
    "\n",
    "    def jupyter_draw_nltk_tree(self, tree):\n",
    "        cf = CanvasFrame()\n",
    "        tc = TreeWidget(cf.canvas(), tree)\n",
    "        tc['node_font'] = 'arial 14 bold'\n",
    "        tc['leaf_font'] = 'arial 14'\n",
    "        tc['node_color'] = '#005990'\n",
    "        tc['leaf_color'] = '#3F8F57'\n",
    "        tc['line_color'] = '#175252'\n",
    "        cf.add_widget(tc, 20, 20)\n",
    "        cf.print_to_file('../data/tree_img/tree.ps')\n",
    "        cf.destroy()\n",
    "        os.system(\n",
    "            'magick convert ../data/tree_img/tree.ps ../data/tree_img/tree.png')\n",
    "        display(Image(filename='../data/tree_img/tree.png'))\n",
    "    \n",
    "    def visualize_tree(self, tree):\n",
    "        btree = Tree.fromstring(tree.replace('[', '(').replace(']', ')'))\n",
    "        self.jupyter_draw_nltk_tree(btree)\n",
    "\n",
    "    def printUgraph_inText(self, Ugraph):\n",
    "        print(Ugraph.root.get_inText(1))\n",
    "        \n",
    "    def combine_comp(self, tree, node):\n",
    "        if(tree.right == None):\n",
    "            node.word = node.word + \" \" + tree.val\n",
    "            node.end = tree.id\n",
    "            return\n",
    "        else:\n",
    "            node.word = node.word + \" \" + tree.left.val\n",
    "            return self.combine_comp(tree.right, node)\n",
    "    \n",
    "    def mono2Graph_recur(self, sent_tree, G, mods, pos=None, counter=-1):\n",
    "        if(sent_tree is None):\n",
    "            return\n",
    "        else:\n",
    "            if(any(list(map(lambda x: sent_tree.val is not None and x in sent_tree.val, list(modifiers))))):\n",
    "                if(\"acl\" in sent_tree.val):\n",
    "                    pipeTemp = GraphPipeline()\n",
    "                    G_prime = pipeTemp.mono2Graph(sent_tree.left)\n",
    "                    mods.add(G_prime.root)\n",
    "                else:\n",
    "                    left_result = self.mono2Graph_recur(\n",
    "                        sent_tree.left, G, set(), sent_tree.val, counter)\n",
    "                    if(left_result is not None):\n",
    "                        if(type(left_result) is set):\n",
    "                            for item_result in left_result:\n",
    "                                if(item_result is not None):\n",
    "                                    mods.add(item_result)\n",
    "                        else:\n",
    "                            mods.add(left_result)\n",
    "\n",
    "                return self.mono2Graph_recur(sent_tree.right, G, mods, pos, counter)\n",
    "            else:\n",
    "                if ((sent_tree.left is None and sent_tree.right is None) or sent_tree.val == \"compound\"):\n",
    "                    if(sent_tree.val == 'and'):\n",
    "                        return\n",
    "                    if(sent_tree.val == \"compound\"):\n",
    "                        newNode = Unode(pos, sent_tree.left.val,\n",
    "                                        sent_tree.pos, sent_tree.mark)\n",
    "                        newNode.start = sent_tree.left.id\n",
    "                        self.combine_comp(sent_tree.right, newNode)\n",
    "                        if(pos in contents or pos == \"verb\"):\n",
    "                            G.add_edge(G.root, newNode)\n",
    "                            if(pos != \"nsubj\"):\n",
    "                                G.addPair(newNode, counter.obj, \"obj\")\n",
    "                                if(pos == \"verb\"  and sent_tree.parent.val != \"cop\"):\n",
    "                                    counter.incrementO()\n",
    "                        for node in mods:\n",
    "                            if(node.npos == \"CC\"):\n",
    "                                newNode.addCC(node)\n",
    "                            else:\n",
    "                                G.add_edge(newNode, node)\n",
    "                        return newNode\n",
    "                    newNode = Unode(pos, sent_tree.val,\n",
    "                                    sent_tree.pos, sent_tree.mark)\n",
    "                    newNode.start = sent_tree.id\n",
    "                    newNode.end = sent_tree.id\n",
    "                    G.add_node(newNode)\n",
    "                    if (any(list(map(lambda x: sent_tree.pos is not None and x in sent_tree.pos, list(modified))))\n",
    "                        or any(list(map(lambda x: pos is not None and x in pos, list(contents))))\n",
    "                            or pos == \"verb\"):\n",
    "                        if(pos in contents or pos == \"verb\"):\n",
    "\n",
    "                            G.add_edge(G.root, newNode)\n",
    "                            if(pos != \"nsubj\"):\n",
    "                                G.addPair(newNode, counter.obj, \"obj\")\n",
    "                                if(pos == \"verb\"  and sent_tree.parent.val != \"cop\"):\n",
    "                                    counter.incrementO()\n",
    "                        for node in mods:\n",
    "                            if(node.npos == \"CC\"):\n",
    "                                newNode.addCC(node)\n",
    "                            else:\n",
    "                                G.add_edge(newNode, node)\n",
    "                        return newNode\n",
    "                    else:\n",
    "                        mods.add(newNode)\n",
    "                        return newNode\n",
    "                else:\n",
    "                    if(any(list(map(lambda x: sent_tree.val is not None and x in sent_tree.val, list(contents))))):\n",
    "                        pos_left = sent_tree.val\n",
    "                        pos_right = pos\n",
    "                        if(\"nsubj\" in sent_tree.val):\n",
    "                            pos_right = \"verb\"\n",
    "                            pos_left = sent_tree.val[0:5]\n",
    "                        if(\"cop\" in sent_tree.val):\n",
    "                            pos_left = \"verb\"\n",
    "                            pos_right = \"obj\"\n",
    "                            self.mono2Graph_recur(sent_tree.left, G,set(),pos_left,counter)\n",
    "                            output = self.mono2Graph_recur(sent_tree.right, G, mods, pos_right,counter)\n",
    "                            counter.incrementO()\n",
    "                            return output\n",
    "                        if('conj' in sent_tree.val):\n",
    "                            if (any(list(map(lambda x: pos is not None and x in pos, list(modifiers))))):\n",
    "                                results = set()\n",
    "                                results.add(self.mono2Graph_recur(sent_tree.left, G, set(), pos,counter))\n",
    "                                results.add(self.mono2Graph_recur(sent_tree.right, G, set(), pos,counter))\n",
    "                                return results\n",
    "                            else:\n",
    "                                self.mono2Graph_recur(sent_tree.left, G, set(), pos,counter)\n",
    "                            \n",
    "                                self.mono2Graph_recur(sent_tree.right, G, mods, pos,counter)\n",
    "                    \n",
    "                        elif(\"aux\" in sent_tree.val):\n",
    "                            self.mono2Graph_recur(\n",
    "                                sent_tree.right, G, mods, \"verb\", counter)\n",
    "                        elif(\"obj\" in sent_tree.val and pos != \"verb\"):\n",
    "                            right_result = self.mono2Graph_recur(\n",
    "                                sent_tree.right, G, set(), \"Prime\", counter)\n",
    "                            if(right_result is not None):\n",
    "                                mods.add(right_result)\n",
    "                            self.mono2Graph_recur(\n",
    "                                sent_tree.left, G, mods, pos_left, counter)\n",
    "                        else:\n",
    "                            self.mono2Graph_recur(\n",
    "                                sent_tree.left, G, set(), pos_left, counter)\n",
    "                            self.mono2Graph_recur(\n",
    "                                sent_tree.right, G, mods, pos_right, counter)\n",
    "                    elif(any(list(map(lambda x: sent_tree.val is not None and x in sent_tree.val, list(offFocus))))):\n",
    "                        self.mono2Graph_recur(\n",
    "                            sent_tree.right, G, mods, pos, counter)\n",
    "\n",
    "\n",
    "class GraphPipeline:\n",
    "    def __init__(self):\n",
    "        self.graph_logs = []\n",
    "\n",
    "    def mono2Graph(self, sent_info):\n",
    "        G = Ugraph(Unode(\"root\", \"Root\", \"r00t\", \"=\"))\n",
    "        self.graph_logs.append(G)\n",
    "        counter = PairCounter()\n",
    "        G.mono2Graph_recur(sent_info, G, set(), \"verb\", counter)\n",
    "        return G\n",
    "\n",
    "\n",
    "class Chunk:\n",
    "    def __init__(self, node, nodeList):\n",
    "        self.node = node\n",
    "        self.nodeList = nodeList\n",
    "        self.ifVP = False\n",
    "\n",
    "\n",
    "class Chunker:\n",
    "    def __init__(self):\n",
    "        self.ifGraph = False\n",
    "\n",
    "    def insert_byOrder(self, nodeList, totalList):\n",
    "        index = 0\n",
    "        for i in range(len(totalList)):\n",
    "            if(nodeList[-1].end < totalList[i][0].start):\n",
    "                break\n",
    "            index += 1\n",
    "        totalList.insert(index, nodeList)\n",
    "        return index\n",
    "\n",
    "    def check_nodesForChunk(self, nodeList, center, total):\n",
    "        size = len(nodeList)\n",
    "        splitpos = [0, size]\n",
    "        for j in range(size - 1):\n",
    "            if(nodeList[j][-1].end + 1 != nodeList[j+1][0].start):\n",
    "                if(j < center):\n",
    "                    if(j >= splitpos[0]):\n",
    "                        splitpos[0] = j\n",
    "                else:\n",
    "                    if((j+1) < splitpos[1]):\n",
    "                        splitpos[1] = j+1\n",
    "        outList = nodeList[splitpos[0]:splitpos[1]]\n",
    "        newList = []\n",
    "        for k in range(len(outList)):\n",
    "            for node in outList[k]:\n",
    "                newList.append(node)\n",
    "        newChunk = Chunk(nodeList[center][0], newList)\n",
    "        total.append(newChunk)\n",
    "        return newChunk\n",
    "\n",
    "    def construct_sentence(self, root):\n",
    "        listNodes = list(root.nodes)\n",
    "        output = []\n",
    "        for k in range(len(root.nodes)):\n",
    "            index = 0\n",
    "            for i in range(len(output)):\n",
    "                if(listNodes[k].end < output[i].start):\n",
    "                    break\n",
    "                index += 1\n",
    "            output.insert(index, listNodes[k])\n",
    "        newChunk = Chunk(None, output)\n",
    "        return newChunk\n",
    "\n",
    "    def chunk_from_nodes(self, node, results):\n",
    "        if(node.isRoot):\n",
    "            self.make_chunks(node, results)\n",
    "            # considering chunks from clause unrelated to main clause now\n",
    "            output = self.construct_sentence(node)\n",
    "            results.append(output)\n",
    "            return output\n",
    "        if(node.nexts[\"all\"] == set()):\n",
    "            return Chunk(node, [node])\n",
    "        # sorting goes:\n",
    "        tempList = []\n",
    "        for nodeItem in node.nexts[\"all\"]:\n",
    "            result = self.chunk_from_nodes(nodeItem, results)\n",
    "            if(result is not None):\n",
    "                if(nodeItem.cc != None):\n",
    "                    self.insert_byOrder([nodeItem.cc],tempList)\n",
    "                self.insert_byOrder(result.nodeList, tempList)\n",
    "        center = self.insert_byOrder([node], tempList)\n",
    "        output = self.check_nodesForChunk(tempList, center, results)\n",
    "\n",
    "        return output\n",
    "    def combine_conj_chunk(self, chunkList):\n",
    "        out_results = []\n",
    "        chunkList.sort(key=(lambda x: x.node.start))\n",
    "        size = len(chunkList)\n",
    "        splitIndex = 0\n",
    "        if(chunkList != []):\n",
    "            temp = Chunk(chunkList[0].node, chunkList[0].nodeList.copy())\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "        for j in range(size -1):\n",
    "            if(chunkList[j+1].node.cc != None and chunkList[j].nodeList[-1].end + 1 == chunkList[j+1].node.cc.start):\n",
    "                temp.nodeList += [chunkList[j+1].node.cc]\n",
    "                temp.nodeList += chunkList[j+1].nodeList\n",
    "            else:\n",
    "                if(temp != []):\n",
    "                    out_results.append(temp)\n",
    "                temp = Chunk(chunkList[j+1].node, chunkList[j+1].nodeList.copy())\n",
    "        out_results.append(temp)\n",
    "\n",
    "        return out_results\n",
    "        \n",
    "    def make_chunks(self, graph_or_root, results):\n",
    "        if(type(graph_or_root) is Ugraph):\n",
    "            root = graph_or_root.root\n",
    "        else:\n",
    "            root = graph_or_root\n",
    "        cont_out = dict()\n",
    "        for cont in root.nexts.keys():\n",
    "            for contNode in root.nexts[cont]:\n",
    "                comp = self.chunk_from_nodes(contNode, results)\n",
    "                if(cont in cont_out):\n",
    "                    cont_out[cont].append(comp)\n",
    "                else:\n",
    "                    cont_out[cont] = []\n",
    "                    cont_out[cont].append(comp)\n",
    "            if(cont in cont_out):\n",
    "                cont_out[cont] = self.combine_conj_chunk(cont_out[cont])\n",
    "                results += cont_out[cont]           \n",
    "        if(\"verb\" in cont_out and \"obj\" in cont_out):\n",
    "            for vbChunk in cont_out[\"verb\"]:\n",
    "                for objChunk in cont_out[\"obj\"]:\n",
    "                    if(vbChunk.node.pair == objChunk.node.pair):\n",
    "                        vb = vbChunk.nodeList\n",
    "                        obj = objChunk.nodeList\n",
    "                        if(vb[-1].end +1 == obj[0].start):\n",
    "                                vpChunk = Chunk(vbChunk.node, vb+obj)\n",
    "                                vpChunk.ifVP = True\n",
    "                                results.append(vpChunk)\n",
    "        elif(\"verb\" in cont_out and not \"obj\" in cont_out):\n",
    "            for vbChunk in cont_out[\"verb\"]:\n",
    "                    vbChunk.ifVP = True\n",
    "            \n",
    "        outList = set()\n",
    "        for nodeChunk in results:\n",
    "            tempStr = \"\"\n",
    "            for node in nodeChunk.nodeList:\n",
    "                tempStr += node.word\n",
    "                tempStr += \" \"\n",
    "            #if(nodeChunk.ifVP):\n",
    "            #    tempStr = \"Somebody \" + tempStr\n",
    "            outList.add(tempStr.rstrip())\n",
    "\n",
    "        return list(outList)\n",
    "\n",
    "    def get_chunks_byDepTree(self, tree):\n",
    "        pipe1 = GraphPipeline()\n",
    "        g1 = pipe1.mono2Graph(tree)\n",
    "        return self.make_chunks(g1, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "DV68-8sDaHhu",
    "outputId": "59f22af6-ac99-40e0-c4f2-c807f15681ab"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-86bae68553ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"There is a girl with a bag\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Here is the homework that I just wrote\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"This is the pizza that I just ordered\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"There is no cat who playing with a device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolarizationPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresults_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PolarizationPipeline' is not defined"
     ]
    }
   ],
   "source": [
    "sentences = [\"There is a girl with a bag\", \"Here is the homework that I just wrote\", \"This is the pizza that I just ordered\",\"There is no cat who playing with a device\"]\n",
    "pipeline = PolarizationPipeline(verbose = 1)\n",
    "results = []\n",
    "results_tree = []\n",
    "for sent in sentences:\n",
    "    tree = pipeline.single_polarization(sent)[\"polarized_tree\"]\n",
    "    results_tree.append(tree)\n",
    "    results.append(pipeline.postprocess(tree,\"\"))\n",
    "print(results)\n",
    "    # visualize_tree(results[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7PSo4Iwbh03"
   },
   "outputs": [],
   "source": [
    "gp = GraphPipeline()\n",
    "chunker = Chunker()\n",
    "results = []\n",
    "gh1 = gp.mono2Graph(results_tree[3])\n",
    "chunks = chunker.make_chunks(gh1, results)\n",
    "print(chunks)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Chunker.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a875081b61e401081ba106d0976cb3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Downloading http://nlp.stanford.edu/software/stanza/1.2.2/en/default.zip:  54%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8dddf754681d4e6ba209e9e705ccc1ad",
      "max": 411784510,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_86dab5d84e9e47ee825aaabe39bcedc6",
      "value": 221118464
     }
    },
    "1da6f1d7a5774dc4931b9c376b65411c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "291a4aaa8dd24e6fb12c3e8b8c8ec56b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f976781716b34693b9ab569fbf55649a",
      "max": 23856,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1da6f1d7a5774dc4931b9c376b65411c",
      "value": 23856
     }
    },
    "4c5c7abb33fe44b4a8ecd12371f5194a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_291a4aaa8dd24e6fb12c3e8b8c8ec56b",
       "IPY_MODEL_8ed74b1d3482486785f72546a4203efe"
      ],
      "layout": "IPY_MODEL_894a549d042a45b19561238a4b0afe99"
     }
    },
    "7069310136b74f17883087c8ba9ea119": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0a875081b61e401081ba106d0976cb3e",
       "IPY_MODEL_9a552e7f9f864203a770cbd53600f9ed"
      ],
      "layout": "IPY_MODEL_dfab5adca25d4f399eb8789a1b48c3e7"
     }
    },
    "7ae1130c699d4ae7bcbe28b027b9629b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81840fd518154627aaed69b4dbc27a7d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86dab5d84e9e47ee825aaabe39bcedc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "894a549d042a45b19561238a4b0afe99": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8dddf754681d4e6ba209e9e705ccc1ad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ed74b1d3482486785f72546a4203efe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac28f855322242258e947cafe0cdf46f",
      "placeholder": "​",
      "style": "IPY_MODEL_7ae1130c699d4ae7bcbe28b027b9629b",
      "value": " 139k/? [00:00&lt;00:00, 2.61MB/s]"
     }
    },
    "9a552e7f9f864203a770cbd53600f9ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81840fd518154627aaed69b4dbc27a7d",
      "placeholder": "​",
      "style": "IPY_MODEL_d36e06be25154c2fbd98c951dfa28460",
      "value": " 221M/412M [02:00&lt;05:23, 589kB/s]"
     }
    },
    "ac28f855322242258e947cafe0cdf46f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d36e06be25154c2fbd98c951dfa28460": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dfab5adca25d4f399eb8789a1b48c3e7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f976781716b34693b9ab569fbf55649a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
