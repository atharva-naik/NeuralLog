{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-12-23 01:41:56 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | gum       |\n",
      "| pos       | gum       |\n",
      "| lemma     | gum       |\n",
      "| depparse  | gum       |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2020-12-23 01:41:57 INFO: Use device: gpu\n",
      "2020-12-23 01:41:57 INFO: Loading: tokenize\n",
      "2020-12-23 01:42:00 INFO: Loading: pos\n",
      "2020-12-23 01:42:01 INFO: Loading: lemma\n",
      "2020-12-23 01:42:01 INFO: Loading: depparse\n",
      "2020-12-23 01:42:03 INFO: Loading: ner\n",
      "2020-12-23 01:42:04 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from wordnet import *\n",
    "from Udep2Mono.binarization import BinaryDependencyTree\n",
    "from Udep2Mono.polarization import PolarizationPipeline\n",
    "from Udep2Mono.util import btreeToList\n",
    "from Udep2Mono.util import det_mark, det_type\n",
    "from copy import deepcopy\n",
    "from pattern.en import pluralize, singularize\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.UdepLog\n",
    "quantifier = db.quantifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5fd18789c624d91cdd508dfe'),\n",
       " 'word': 'several',\n",
       " '>': ['every', 'all', 'each', 'most', 'many', 'num'],\n",
       " '<': ['some', 'a', 'an', 'one', 'at-least-several'],\n",
       " '=': ['a few', 'several-of-the'],\n",
       " '!': []}"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "quantifier.find({\"word\": \"several\"})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lexical Knowledge based Lexical Replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LexicalGenerator:\n",
    "    def __init__(self):\n",
    "        self.deptree = None\n",
    "        self.hypothesis = \"\"\n",
    "        self.treeLog = []\n",
    "        self.polarLog = []\n",
    "        self.replacementLog = []\n",
    "        self.key_tokens = [\n",
    "            'NN','NNS','NNP','NNPS','VBD',\n",
    "            'VBG','VBN','VBZ','VB']\n",
    "\n",
    "    def deptree_generate(self, tree):\n",
    "        self.deptree = tree\n",
    "        self.generate(self.deptree)\n",
    "\n",
    "    def generate(self, tree):\n",
    "        if tree.npos is not None: \n",
    "            if tree.npos in self.key_tokens:\n",
    "                backup = tree.val\n",
    "                hyper = [] \n",
    "                hypo = [] \n",
    "                syn = [] \n",
    "                ant = []\n",
    "\n",
    "                hyper, hypo, syn, ant = get_word_sets(\n",
    "                    singularize(tree.val), tree.npos.lower())\n",
    "\n",
    "                for word in syn:\n",
    "                    if word in self.hypothesis:\n",
    "                        tree.val = word\n",
    "                        self.treeLog.append(self.save_tree())\n",
    "                        self.replacementLog.append(\n",
    "                            \"{} => {}\".format(backup, word))\n",
    "                tree.val = backup\n",
    "\n",
    "                for word in ant:\n",
    "                    if word in self.hypothesis:\n",
    "                        tree.val = word\n",
    "                        self.treeLog.append(self.save_tree())\n",
    "                        self.replacementLog.append(\n",
    "                            \"{} => {}\".format(backup, word))\n",
    "                tree.val = backup\n",
    "\n",
    "                if tree.mark == \"+\":                \n",
    "                    for word in hyper:\n",
    "                        if word in self.hypothesis:\n",
    "                            tree.val = word\n",
    "                            self.treeLog.append(self.save_tree())\n",
    "                            self.replacementLog.append(\n",
    "                            \"{} => {}\".format(backup, word))\n",
    "                    tree.val = backup\n",
    "\n",
    "                if tree.mark == \"-\":\n",
    "                    for word in hypo:\n",
    "                        if word in self.hypothesis:\n",
    "                            tree.val = word\n",
    "                            self.treeLog.append(self.save_tree())\n",
    "                            self.replacementLog.append(\n",
    "                            \"{} => {}\".format(backup, word))\n",
    "                    tree.val = backup\n",
    "            \n",
    "        elif tree.val == \"det\":\n",
    "            backup = tree.left.val\n",
    "            backup_mark = tree.right.mark\n",
    "            kb = quantifier.find({\"word\": tree.left.val.lower()})[0]\n",
    "\n",
    "            for word in kb[\"=\"]:\n",
    "                tree.left.val = word\n",
    "                detType = det_type(tree.left.val)\n",
    "                if detType is None:\n",
    "                    detType = \"det:exist\"\n",
    "                detMark = det_mark[detType]\n",
    "                tree.left.mark = detMark[1]\n",
    "                self.treeLog.append(self.save_tree())\n",
    "                self.replacementLog.append(\n",
    "                    \"{} => {}\".format(backup, word))\n",
    "            tree.left.val = backup\n",
    "            tree.left.mark = backup_mark\n",
    "\n",
    "            if tree.left.mark == \"+\":\n",
    "                for word in kb[\"<\"]:\n",
    "                    if word in self.hypothesis:\n",
    "                        tree.left.val = word\n",
    "                        detType = det_type(tree.left.val)\n",
    "                        if detType is None:\n",
    "                            detType = \"det:exist\"\n",
    "                        detMark = det_mark[detType]\n",
    "                        tree.left.mark = detMark[1]\n",
    "                        self.treeLog.append(self.save_tree())\n",
    "                        self.replacementLog.append(\n",
    "                            \"{} => {}\".format(backup, word))\n",
    "                tree.left.val = backup\n",
    "                tree.left.mark = backup_mark\n",
    "            \n",
    "            if tree.left.mark == \"-\":\n",
    "                for word in kb[\">\"]:\n",
    "                    if word in self.hypothesis:\n",
    "                        tree.val = word\n",
    "                        if detType is None:\n",
    "                            detType = \"det:exist\"\n",
    "                        detMark = det_mark[detType]\n",
    "                        tree.left.mark = detMark[1]\n",
    "                        self.treeLog.append(self.save_tree())\n",
    "                        self.replacementLog.append(\n",
    "                            \"{} => {}\".format(backup, word))\n",
    "                tree.left.val = backup\n",
    "                tree.left.mark = backup_mark\n",
    "        \n",
    "        if tree.left != \"N\":\n",
    "            self.generate(tree.left)\n",
    "        if tree.right != \"N\":\n",
    "            self.generate(tree.right)\n",
    "\n",
    "    def save_tree(self):\n",
    "        return deepcopy(self.deptree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "\n",
      "some↑ flowers↑ are↑ beautiful↑\n",
      "http://api.conceptnet.io/query?start=/c/en/flower&rel=/r/IsA&limit=500\n",
      "http://api.conceptnet.io/query?end=/c/en/flower&rel=/r/IsA&limit=500\n",
      "some => a\n",
      "some => an\n",
      "some => one\n",
      "flowers => flower\n",
      "flowers => flowering plant\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"Some flowers are beautiful\"]\n",
    "hypothesis = \"Some flowering plant are beautiful\"\n",
    "pipeline = PolarizationPipeline(sentences, verbose=2, parser=\"stanza\")\n",
    "pipeline.run_polarize_pipeline()\n",
    "print(\"\\nPolarization Complete\")\n",
    "\n",
    "lexicalGenerator = LexicalGenerator()\n",
    "for annotation in annotations:\n",
    "    print(\"================\")\n",
    "    print(\"Init Premise: \", annotation['annotated'])\n",
    "    lexicalGenerator.hypothesis = hypothesis\n",
    "    lexicalGenerator.deptree_generate(\n",
    "        len(annotation['original']), annotation['polarized_tree'])\n",
    "    for record in lexicalGenerator.replacementLog:\n",
    "        print(record) "
   ]
  },
  {
   "source": [
    "## Word Embedding Based Lexical Replacement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "from sapphire import Sapphire\n",
    "\n",
    "MODEL_NAME = \"sapphire/model/wiki-news-300d.bin\"\n",
    "model = fasttext.FastText.load_model(MODEL_NAME)\n",
    "aligner = Sapphire(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A => A\nman => man\nis => is\nslicing => cutting\na => a\norange => fruit\n"
     ]
    }
   ],
   "source": [
    "aligner.set_params(lambda_=0.5, delta=0.5, alpha=0.05, hungarian=True)\n",
    "\n",
    "s1 = \"Scientists created a vaccine against the virus\".split(\" \")\n",
    "s2 = \"Researchers developed the antivirus vaccine\".split(\" \")\n",
    "s1 = \"A man is slicing a orange\".split(\" \")\n",
    "s2 = \"A man is cutting a fruit\".split(\" \")\n",
    "wa, pa = aligner(s1, s2)\n",
    "\n",
    "for pair in wa:\n",
    "    print(s1[pair[0]-1], \"=>\", s2[pair[1]-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dreams => Wishes\nwill => will\ncome => in\ntrue => future\nvery => the\nsoon => be\n"
     ]
    }
   ],
   "source": [
    "s1 = \"Dreams will come true very soon\".split(\" \")\n",
    "s2 = \"Wishes will be fulfilled in the near future\".split(\" \")\n",
    "wa, pa = aligner(s1, s2)\n",
    "\n",
    "for pair in wa:\n",
    "    print(s1[pair[0]-1], \"=>\", s2[pair[1]-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}