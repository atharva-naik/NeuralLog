{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-MRPC were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,AutoModel\n",
    "\n",
    "roberta_MRPC = \"textattack/roberta-base-MRPC\"\n",
    "bert_MRPC = \"bert-base-cased-finetuned-mrpc\"\n",
    "\n",
    "paraphraseTokenizer = AutoTokenizer.from_pretrained(roberta_MRPC)  \n",
    "paraphraseModel = AutoModelForSequenceClassification.from_pretrained(roberta_MRPC)\n",
    "\n",
    "classes = [\"not paraphrase\", \"is paraphrase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "sentenceTransformer = SentenceTransformer(\"roberta-large-nli-stsb-mean-tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_similarity(s1, s2):\n",
    "    num_sim = 0\n",
    "    seq1 = s1.split(\" \")\n",
    "    for w in seq1:\n",
    "        if w in s2:\n",
    "            num_sim += 1\n",
    "    return num_sim / len(seq1)\n",
    "\n",
    "def inference_sts(seq1s, seq2s):\n",
    "    embeddings1 = sentenceTransformer.encode(seq1s, convert_to_tensor=True)\n",
    "    embeddings2 = sentenceTransformer.encode(seq2s, convert_to_tensor=True)\n",
    "    cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    for i in range(len(seq1s)):\n",
    "        print(\"Similarity Score: {:.4f}\".format(cosine_scores[i][i])) \n",
    "        # word_similarity(seq1s[i], seq2s[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_mrpc(seq1s, seq2s):\n",
    "    for i in range(len(seq1s)):\n",
    "        paraphrase = paraphraseTokenizer.encode_plus(\n",
    "            seq1s[i], seq2s[i], return_tensors=\"pt\")\n",
    "        logits = paraphraseModel(**paraphrase)[0]\n",
    "        paraphrase_results = torch.softmax(logits, dim=1).tolist()[0]\n",
    "        print(f\"{classes[1]}: {round(paraphrase_results[1] * 100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "is paraphrase: 82%\n",
      "is paraphrase: 100%\n",
      "is paraphrase: 100%\n",
      "is paraphrase: 92%\n",
      "Similarity Score: 0.8932\n",
      "Similarity Score: 0.8080\n",
      "Similarity Score: 0.9863\n",
      "Similarity Score: 0.9202\n"
     ]
    }
   ],
   "source": [
    "sentences1 = [\"ate an apple\", \n",
    "              \"jumping over a fence\", \n",
    "              \"riding a motorbike down the road\", \n",
    "              \"all the people walk\"]\n",
    "sentences2 = [\"an apple was eaten\",  \n",
    "              \"jumping over a enclosure\", \n",
    "              \"riding a motorbike along a roadway\",\n",
    "              \"everyone walks\"]\n",
    "\n",
    "inference_mrpc(sentences1, sentences2)\n",
    "inference_sts(sentences1, sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is paraphrase: 99%\n",
      "Similarity Score: 0.7890\n"
     ]
    }
   ],
   "source": [
    "sentences1 = [\"there is a seated women\"]\n",
    "sentences2 = [\"there is a women sitting\"]\n",
    "\n",
    "inference_mrpc(sentences1, sentences2)\n",
    "inference_sts(sentences1, sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is paraphrase: 99%\n",
      "Similarity Score: 0.9588\n"
     ]
    }
   ],
   "source": [
    "sentences1 = [\"a red apple\"]\n",
    "sentences2 = [\"an apple which is red\"]\n",
    "\n",
    "inference_mrpc(sentences1, sentences2)\n",
    "inference_sts(sentences1, sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is paraphrase: 69%\n",
      "Similarity Score: 0.0823\n"
     ]
    }
   ],
   "source": [
    "sentences1 = [\"a man is crying\"]\n",
    "sentences2 = [\"a man with a smile\"]\n",
    "\n",
    "inference_mrpc(sentences1, sentences2)\n",
    "inference_sts(sentences1, sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is paraphrase: 99%\n",
      "Similarity Score: 0.7147\n"
     ]
    }
   ],
   "source": [
    "sentences1 = [\"a problem is solved\"]\n",
    "sentences2 = [\"resolved a problem\"]\n",
    "\n",
    "inference_mrpc(sentences1, sentences2)\n",
    "inference_sts(sentences1, sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is paraphrase: 100%\n",
      "Similarity Score: 0.7243\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences1 = [\"enjoying a balloon joyride\"]\n",
    "sentences2 = [\"on a balloon joyride\"]\n",
    "\n",
    "inference_mrpc(sentences1, sentences2)\n",
    "inference_sts(sentences1, sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-03-08 05:45:24 INFO: Loading these models for language: en (English):\n",
      "========================================\n",
      "| Processor | Package                  |\n",
      "----------------------------------------\n",
      "| tokenize  | ../model/e...ize/gum.pt  |\n",
      "| pos       | ../model/en/pos/ewt.pt   |\n",
      "| lemma     | ../model/en/lemma/gum.pt |\n",
      "| depparse  | ../model/e...rse/gum.pt  |\n",
      "========================================\n",
      "\n",
      "2021-03-08 05:45:24 INFO: Use device: gpu\n",
      "2021-03-08 05:45:24 INFO: Loading: tokenize\n",
      "2021-03-08 05:45:26 INFO: Loading: pos\n",
      "2021-03-08 05:45:26 INFO: Loading: lemma\n",
      "2021-03-08 05:45:26 INFO: Loading: depparse\n",
      "2021-03-08 05:45:27 INFO: Done loading processors!\n",
      "2021-03-08 05:45:27 INFO: Loading these models for language: en (English):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | ../model/e...ize/gum.pt |\n",
      "=======================================\n",
      "\n",
      "2021-03-08 05:45:27 INFO: Use device: gpu\n",
      "2021-03-08 05:45:27 INFO: Loading: tokenize\n",
      "2021-03-08 05:45:27 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from Udep2Mono.polarization import PolarizationPipeline\n",
    "from chunker import Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['not expect', 'not expect guests']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "chunker = Chunker()\n",
    "pipeline = PolarizationPipeline(verbose=1)\n",
    "P = \"We did not expect guests\"\n",
    "H = \"We did not expect arrival of guests\"\n",
    "p_tree = pipeline.single_polarization(P)[\"polarized_tree\"]\n",
    "chunker.get_chunks_byDepTree(p_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['of guests',\n",
       " 'arrival of guests',\n",
       " 'not expect',\n",
       " 'not expect arrival of guests']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "h_tree = pipeline.single_polarization(H)[\"polarized_tree\"]\n",
    "chunker.get_chunks_byDepTree(h_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "is paraphrase: 99%\n"
     ]
    }
   ],
   "source": [
    "sentences1 = [\"not expect guests\"]\n",
    "sentences2 = [\"not expect arrival of guests\"]\n",
    "\n",
    "inference_mrpc(sentences1, sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['with a warm smile',\n",
       " 'A man with a warm smile',\n",
       " 'a lecture',\n",
       " 'giving a lecture']"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "P = \"A man with a warm smile is giving a lecture\"\n",
    "p_tree = pipeline.single_polarization(P)[\"polarized_tree\"]\n",
    "chunker.get_chunks_byDepTree(p_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['smiling warmly',\n",
       " 'smiling warmly',\n",
       " 'A man smiling warmly',\n",
       " 'a lecture',\n",
       " 'giving a lecture']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "H = \"A man smiling warmly is giving a lecture\"\n",
    "h_tree = pipeline.single_polarization(H)[\"polarized_tree\"]\n",
    "chunker.get_chunks_byDepTree(h_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "is paraphrase: 100%\n"
     ]
    }
   ],
   "source": [
    "sentences1 = [\"A man smiling warmly\"]\n",
    "sentences2 = [\"A man with a warm smile\"]\n",
    "\n",
    "inference_mrpc(sentences1, sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "is paraphrase: 1%\n"
     ]
    }
   ],
   "source": [
    "sentences1 = [\"giving a lecture\"]\n",
    "sentences2 = [\"A man with a warm smile\"]\n",
    "\n",
    "inference_mrpc(sentences1, sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['of the office',\n",
       " 'in front of the office',\n",
       " 'sitting in front of the office',\n",
       " 'sitting in front of the office',\n",
       " 'a women sitting in front of the office']"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "P = \"There is a women sitting in front of the office\"\n",
    "p_tree = pipeline.single_polarization(P)[\"polarized_tree\"]\n",
    "chunker.get_chunks_byDepTree(p_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['of the office',\n",
       " 'in front of the office',\n",
       " 'a seated women in front of the office']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "H = \"There is a seated women in front of the office\"\n",
    "h_tree = pipeline.single_polarization(H)[\"polarized_tree\"]\n",
    "chunker.get_chunks_byDepTree(h_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "is paraphrase: 100%\n"
     ]
    }
   ],
   "source": [
    "sentences1 = [\"a women sitting in front of the office\"]\n",
    "sentences2 = [\"a seated women in front of the office\"]\n",
    "\n",
    "inference_mrpc(sentences1, sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}