{
 "cells": [
  {
   "source": [
    "# UdepLog Neural-Logical Inference System"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tree import Tree\n",
    "from nltk.draw import TreeWidget\n",
    "from nltk.draw.util import CanvasFrame\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def jupyter_draw_nltk_tree(tree):\n",
    "    cf = CanvasFrame()\n",
    "    tc = TreeWidget(cf.canvas(), tree)\n",
    "    tc['node_font'] = 'arial 14 bold'\n",
    "    tc['leaf_font'] = 'arial 14'\n",
    "    tc['node_color'] = '#005990'\n",
    "    tc['leaf_color'] = '#3F8F57'\n",
    "    tc['line_color'] = '#175252'\n",
    "    cf.add_widget(tc, 20, 20)\n",
    "    os.system('rm -rf ../data/tree.png')\n",
    "    os.system('rm -rf ../data/tree.ps')\n",
    "    cf.print_to_file('../data/tree.ps')\n",
    "    cf.destroy()\n",
    "    os.system('convert ../data/tree.ps ../data/tree.png')\n",
    "    display(Image(filename='../data/tree.png'))"
   ]
  },
  {
   "source": [
    "## 2. BERT Model for Pharaphrase"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-MRPC were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Load Alignment Model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "roberta_MRPC = \"textattack/roberta-base-MRPC\"\n",
    "bert_MRPC = \"bert-base-cased-finetuned-mrpc\"\n",
    "\n",
    "paraphraseTokenizer = AutoTokenizer.from_pretrained(roberta_MRPC)  \n",
    "paraphraseModel = AutoModelForSequenceClassification.from_pretrained(roberta_MRPC)\n",
    "paraphraseModel.to('cuda')\n",
    "print(\"Load Alignment Model\")"
   ]
  },
  {
   "source": [
    "## 3. UD Parser and RoBERTa Semantic Similarity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-03-18 13:08:38 INFO: Loading these models for language: en (English):\n",
      "========================================\n",
      "| Processor | Package                  |\n",
      "----------------------------------------\n",
      "| tokenize  | ../model/e...ize/gum.pt  |\n",
      "| pos       | ../model/en/pos/ewt.pt   |\n",
      "| lemma     | ../model/en/lemma/gum.pt |\n",
      "| depparse  | ../model/e...rse/gum.pt  |\n",
      "========================================\n",
      "\n",
      "2021-03-18 13:08:38 INFO: Use device: gpu\n",
      "2021-03-18 13:08:38 INFO: Loading: tokenize\n",
      "2021-03-18 13:08:38 INFO: Loading: pos\n",
      "2021-03-18 13:08:39 INFO: Loading: lemma\n",
      "2021-03-18 13:08:39 INFO: Loading: depparse\n",
      "2021-03-18 13:08:39 INFO: Done loading processors!\n",
      "2021-03-18 13:08:39 INFO: Loading these models for language: en (English):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | ../model/e...ize/gum.pt |\n",
      "=======================================\n",
      "\n",
      "2021-03-18 13:08:39 INFO: Use device: cpu\n",
      "2021-03-18 13:08:39 INFO: Loading: tokenize\n",
      "2021-03-18 13:08:39 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from wordnet import *\n",
    "from copy import deepcopy\n",
    "from Udep2Mono.util import det_mark, det_type\n",
    "from Udep2Mono.util import btree2list\n",
    "from Udep2Mono.dependency_parse import tokenizer\n",
    "from Udep2Mono.dependency_parse import dependency_parse\n",
    "from Udep2Mono.binarization import BinaryDependencyTree\n",
    "from Udep2Mono.polarization import PolarizationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "sentenceTransformer = SentenceTransformer(\"roberta-base-nli-stsb-mean-tokens\")\n",
    "sentenceTransformer.to('cuda')\n",
    "\n",
    "def inference_sts(seq1s, seq2s, dist=False):\n",
    "    embeddings1 = sentenceTransformer.encode(seq1s, convert_to_tensor=True)\n",
    "    embeddings2 = sentenceTransformer.encode(seq2s, convert_to_tensor=True)\n",
    "    cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    distance = torch.dist(embeddings1, embeddings2)\n",
    "    if dist:\n",
    "        return distance\n",
    "    return cosine_scores[0][0]"
   ]
  },
  {
   "source": [
    "## 4. Phrasal Monotonicity Inference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import pluralize, singularize\n",
    "from copy import copy\n",
    "import re\n",
    "import torch\n",
    "\n",
    "class PhrasalGenerator:\n",
    "    def __init__(self):\n",
    "        self.deptree = None\n",
    "        self.annotated = None\n",
    "        self.original = None\n",
    "        self.kb = {}\n",
    "        self.hypothesis = \"\"\n",
    "        self.tree_log = []\n",
    "        self.sent_log = []\n",
    "        self.stop_critarion = False\n",
    "        self.mod_at_left = [\n",
    "            \"advmod\", \"amod\", \"advmod:count\", \n",
    "            \"acl:relcl\", \"obl\", 'obl:npmod', \"det\",\n",
    "            \"obl:tmod\", \"nmod\", \"nmod:npmod\", \n",
    "            \"nmod:poss\", \"nmod:tmod\", \"obl:npmod\",\n",
    "            \"acl\", \"advcl\", \"xcomp\", \"ccomp\", \n",
    "            'compound:ptr']\n",
    "        self.mod_at_right = [\"appos\"] #\"obj\"\n",
    "        self.mod_symmetric = [\"conj\", \"compound\"]\n",
    "        self.mod_special = [\"nsubj\"]\n",
    "        self.implicative = {\n",
    "            \"watching\": 1\n",
    "        }\n",
    "        \n",
    "        '''  \n",
    "            \"cop\": self.generate_inherite, \n",
    "            \"expl\": self.generate_expl,\n",
    "            \"nummod\": self.generate_nummod,\n",
    "        '''\n",
    "\n",
    "    def deptree_generate(self, tree, annotated, original):\n",
    "        self.stop_critarion = False\n",
    "        self.tree_log = []\n",
    "        self.sent_log = []\n",
    "        self.deptree = tree.copy()\n",
    "        self.original = original  \n",
    "        self.annotated = deepcopy(annotated)\n",
    "        self.sentence = original\n",
    "        self.generate(self.deptree)\n",
    "\n",
    "    def generate(self, tree):\n",
    "        if self.stop_critarion:\n",
    "            return\n",
    "        if not tree.is_tree:\n",
    "            self.generate_default(tree)\n",
    "        else:\n",
    "            generation = self.get_generation_type(tree)\n",
    "            #print(generation, tree.val)\n",
    "            generation(tree)\n",
    "\n",
    "    def get_generation_type(self, tree):\n",
    "        if tree.val in self.mod_special:\n",
    "            return self.generate_special\n",
    "\n",
    "        disjunction = False\n",
    "        if tree.val == \"conj\":\n",
    "            disjunction |= self.search_dependency('or', tree.left)\n",
    "            disjunction |= self.search_dependency('and', tree.left)\n",
    "        \n",
    "        left_mod = tree.left.mark == \"+\"\n",
    "        left_mod = left_mod or tree.left.mark == \"=\" or disjunction\n",
    "        left_mod = left_mod and tree.val in self.mod_at_left\n",
    "\n",
    "        right_mod = tree.right.mark == \"+\" or tree.right.mark == \"=\" or disjunction \n",
    "        right_mod = right_mod and tree.val in self.mod_at_right\n",
    "\n",
    "        sym_mod = tree.val in self.mod_symmetric and tree.left.mark == \"+\" and tree.right.mark == \"+\"\n",
    "\n",
    "        if left_mod:\n",
    "            return self.left_modifier_generate\n",
    "        elif right_mod:\n",
    "            return self.right_modifier_generate\n",
    "        elif sym_mod:\n",
    "            return self.symmetric_generate\n",
    "        else:\n",
    "            return self.generate_default\n",
    "\n",
    "    def generate_special(self, tree):\n",
    "        if tree.val == \"nsubj\":\n",
    "            if tree.left.val == \"who\" and tree.right.val == \"aux\":\n",
    "                self.left_modifier_generate(tree)\n",
    "\n",
    "        self.generate(tree.left)\n",
    "        self.generate(tree.right)\n",
    "\n",
    "    def delete_cc(self, tree):\n",
    "        if tree.val == \"cc\" and tree.left.val != \"but\":\n",
    "            self.delete_modifier(tree, tree.right)\n",
    "\n",
    "        if tree.is_tree:\n",
    "            self.delete_cc(tree.left)\n",
    "            self.delete_cc(tree.right)\n",
    "\n",
    "    def delete_modifier(self, tree, modifier):\n",
    "        tree.val = modifier.val\n",
    "        tree.mark = modifier.mark\n",
    "        tree.pos = modifier.pos\n",
    "        tree.id = modifier.id\n",
    "        \n",
    "        tree.is_tree = modifier.is_tree\n",
    "        tree.is_root = modifier.is_root\n",
    "\n",
    "        tree.left = modifier.left\n",
    "        tree.right = modifier.right\n",
    "\n",
    "        self.delete_cc(tree)\n",
    "        self.save_tree()\n",
    "\n",
    "    def delete_left_modifier(self, tree):\n",
    "        #print(\"Delet: \", tree.left.val)\n",
    "        self.delete_modifier(tree, tree.right)\n",
    "\n",
    "    def delete_right_modifier(self, tree):\n",
    "        #print(\"Delet: \", tree.right.val)\n",
    "        self.delete_modifier(tree, tree.left)\n",
    "\n",
    "    def rollback(self, tree, backup):\n",
    "        tree.val = backup.val\n",
    "        tree.left = deepcopy(backup.left)\n",
    "        tree.right = deepcopy(backup.right)\n",
    "        tree.mark = backup.mark\n",
    "        tree.pos = backup.pos\n",
    "        tree.id = backup.id\n",
    "        tree.is_tree = backup.is_tree\n",
    "        tree.is_root = backup.is_root\n",
    "\n",
    "    def symmetric_generate(self, tree):\n",
    "        self.right_modifier_generate(tree)\n",
    "        self.left_modifier_generate(tree)\n",
    "        #self.delete_cc(tree)\n",
    "\n",
    "    def right_modifier_generate(self, tree):\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "        backup = deepcopy(tree)\n",
    "\n",
    "        self.delete_right_modifier(tree)\n",
    "        self.save_tree()\n",
    "        self.rollback(tree, backup)    \n",
    "        \n",
    "        self.generate(tree.left)\n",
    "        self.generate(tree.right)\n",
    "\n",
    "    def left_modifier_generate(self, tree):\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "        backup = deepcopy(tree)\n",
    "\n",
    "        self.delete_left_modifier(tree)\n",
    "        self.save_tree()\n",
    "        self.rollback(tree, backup)   \n",
    "\n",
    "        self.generate(tree.left)\n",
    "        self.generate(tree.right)\n",
    "    \n",
    "    def return_last_leaf(self, tree):\n",
    "        max_id = 0\n",
    "        max_id_l = 0\n",
    "        max_id_r = 0\n",
    "\n",
    "        if tree.id != None:\n",
    "            max_id = int(tree.id)\n",
    "    \n",
    "        if tree.left.is_tree:\n",
    "            max_id_l = self.return_last_leaf(tree.left)\n",
    "        else:\n",
    "            max_id_l = tree.left.id\n",
    "\n",
    "        if tree.right.is_tree:\n",
    "            max_id_r = self.return_last_leaf(tree.right)\n",
    "        else:\n",
    "            max_id_r = tree.right.id\n",
    "\n",
    "        return max(max_id, max(max_id_l, max_id_r))\n",
    "\n",
    "    def return_first_leaf(self, tree):\n",
    "        min_id = 100\n",
    "        min_id_l = 100\n",
    "        min_id_r = 100\n",
    "\n",
    "        if tree.id != None:\n",
    "            min_id = int(tree.id)\n",
    "    \n",
    "        if tree.left.is_tree:\n",
    "            min_id_l = self.return_last_leaf(tree.left)\n",
    "        else:\n",
    "            min_id_l = tree.left.id\n",
    "\n",
    "        if tree.right.is_tree:\n",
    "            min_id_r = self.return_last_leaf(tree.right)\n",
    "        else:\n",
    "            min_id_r = tree.right.id\n",
    "\n",
    "        return min(min_id, min(min_id_l, min_id_r))\n",
    "\n",
    "    def add_modifier_sent(self, tree, modifier, direct=0): \n",
    "        sentence = deepcopy(self.sentence)\n",
    "        if direct == 0:\n",
    "            last_leaf = self.return_first_leaf(tree)\n",
    "            sentence.insert(last_leaf-1, modifier)\n",
    "        elif direct == 1:\n",
    "            last_leaf = self.return_last_leaf(tree)\n",
    "            sentence.insert(last_leaf, modifier)        \n",
    "\n",
    "        self.remove_adjcent_duplicate(sentence)\n",
    "        sentence = ' '.join(sentence)\n",
    "        sentence = sentence.replace(\"-\", \" \")\n",
    "        sentence = sentence.replace(\" 's\", \"'s\")\n",
    "\n",
    "        if abs(len(sentence) - len(self.hypothesis)) < 15:\n",
    "            re.sub(r'((\\b\\w+\\b.{1,2}\\w+\\b)+).+\\1', r'\\1', sentence, flags = re.I)\n",
    "            sentence = sentence.strip() \n",
    "            \n",
    "            if sentence.lower() == self.hypothesis.lower():\n",
    "                self.stop_critarion = True\n",
    "                self.sent_log.append((sentence, 1.0))\n",
    "                return\n",
    "                \n",
    "            similarity = inference_sts([sentence], [self.hypothesis])\n",
    "            if similarity > 0.90:\n",
    "                self.sent_log.append((sentence, similarity))\n",
    "            if similarity > 0.97:\n",
    "                self.sent_log.append((sentence, similarity))\n",
    "                self.stop_critarion = True\n",
    "\n",
    "    def add_modifier_lexical(self, tree, modifier, head, word_id, direct=0):\n",
    "        if direct == 0:\n",
    "            generated = ' '. join([modifier, head])\n",
    "        else:\n",
    "            generated = ' '. join([head, modifier])\n",
    "        \n",
    "        sentence = deepcopy(self.sentence)\n",
    "        diff = 0\n",
    "        if word_id > len(sentence):\n",
    "            diff = word_id - len(sentence)\n",
    "\n",
    "        goal = word_id-1-diff\n",
    "        sentence[goal] = \"DEL\"\n",
    "        sentence[goal:goal] = generated.split(' ')\n",
    "\n",
    "        if abs(len(sentence) - len(self.hypothesis.split(' '))) < 7:\n",
    "            self.remove_adjcent_duplicate(sentence)\n",
    "            sentence = ' '.join(sentence)\n",
    "            sentence = sentence.replace(\"DEL \", \"\")\n",
    "            sentence = sentence.replace(\"DEL\", \"\")\n",
    "            sentence = sentence.replace(\"-\", \" \")\n",
    "            sentence = sentence.replace(\" 's\", \"'s\")\n",
    "            re.sub(r'((\\b\\w+\\b.{1,2}\\w+\\b)+).+\\1', r'\\1', sentence, flags = re.I)\n",
    "            sentence = sentence.strip()\n",
    "\n",
    "            if sentence.lower() == self.hypothesis.lower():\n",
    "                self.stop_critarion = True\n",
    "                self.sent_log.append((sentence, 1.0))\n",
    "                return\n",
    "            \n",
    "            similarity = inference_sts([sentence], [self.hypothesis])\n",
    "            if similarity > 0.9:\n",
    "                self.sent_log.append((sentence, similarity))\n",
    "            if similarity > 0.97:\n",
    "                self.sent_log.append((sentence, similarity))\n",
    "                self.stop_critarion = True\n",
    "\n",
    "    def generate_default(self, tree):\n",
    "        VP_rel = {\n",
    "            \"aux\":1, \n",
    "            \"obj\":1, \n",
    "            \"obl\":1, \n",
    "            \"xcomp\":1, \n",
    "            \"ccomp\":1,\n",
    "            \"aux:pass\":1, \n",
    "            \"obl:tmod\":1, \n",
    "            \"obl:npmod\":1\n",
    "        }\n",
    "\n",
    "        VP_mod = {\n",
    "            \"advcl\":1, \n",
    "            \"xcomp\":1, \n",
    "            \"ccomp\":1,\n",
    "            \"obj\":1, \n",
    "            \"advmod\":1, \n",
    "            \"obl\":1, \n",
    "            \"obl:tmod\":1,\n",
    "            \"obl:nmod\":1, \n",
    "            \"parataxis\":1, \n",
    "            \"conj\":1\n",
    "        }\n",
    "\n",
    "        NP_rel = {\n",
    "            \"amod\":1,\n",
    "            \"compound\":1,\n",
    "            \"det\":1,\n",
    "            \"mark\":1,\n",
    "            \"nmod:poss\":1,\n",
    "            \"flat\":1,\n",
    "            \"acl:relcl\":1,\n",
    "            \"acl\":1,\n",
    "            \"nmod\":1\n",
    "        }\n",
    "\n",
    "        NP_mod = {\n",
    "            \"amod\":1,\n",
    "            \"compound\":1,\n",
    "            \"det\":1,\n",
    "            \"mark\":1,\n",
    "            \"nmod:poss\":1,\n",
    "            \"flat\":1,\n",
    "        }\n",
    "\n",
    "        if tree.pos is not None:\n",
    "            if (\"NN\" in tree.pos or \"JJ\" in tree.pos) and tree.mark == \"-\":\n",
    "                for rel in [\"amod\", \"compound\", \"det\", \"mark\", \"nmod:poss\", \"flat\", \"conj\", \"nummod\"]:\n",
    "                    if rel in self.kb:\n",
    "                        for phrase in self.kb[rel]:\n",
    "                            if phrase['head'] == tree.val:\n",
    "                                self.add_modifier_lexical(tree, phrase['mod'], tree.val, tree.id)\n",
    "                for rel in [\"amod\", \"acl:relcl\", \"compound\", \"acl\", \"nmod\"]:\n",
    "                    if rel in self.kb:\n",
    "                        for phrase in self.kb[rel]:\n",
    "                            if phrase['head'] == tree.val:\n",
    "                                self.add_modifier_lexical(tree, phrase['mod'], tree.val, tree.id, 1)\n",
    "                \n",
    "            elif \"VB\" in tree.pos and tree.mark == \"-\":\n",
    "                for rel in [\"advmod\"]:\n",
    "                    if rel in self.kb:\n",
    "                        for phrase in self.kb[rel]:\n",
    "                            self.add_modifier_lexical(tree, phrase['mod'], tree.val, tree.id)\n",
    "                            self.add_modifier_lexical(tree, phrase['mod'], tree.val, tree.id, 1)\n",
    "\n",
    "        elif VP_rel.get(tree.val, 0) and tree.mark == \"-\":\n",
    "            for rel in VP_mod:\n",
    "                if rel in self.kb:\n",
    "                    for phrase in self.kb[rel]:\n",
    "                        self.add_modifier_sent(tree, phrase['mod'], direct=1)\n",
    "\n",
    "        elif NP_rel.get(tree.val, 0) and tree.mark == \"-\":\n",
    "            for rel in NP_mod:\n",
    "                if rel in self.kb:\n",
    "                    for phrase in self.kb[rel]:\n",
    "                        self.add_modifier_sent(tree, phrase['mod'], direct=0)\n",
    "        \n",
    "        if VP_rel.get(tree.val, 0) and tree.right.val == \"watching\":\n",
    "            self.save_tree(tree=tree.left)\n",
    "        if tree.is_tree:\n",
    "            self.generate(tree.left)\n",
    "            self.generate(tree.right)  \n",
    "\n",
    "    def save_tree(self, tree=None):\n",
    "        if tree is None:\n",
    "            leaves = self.deptree.sorted_leaves().popkeys()\n",
    "            tree_copy = self.deptree.copy()\n",
    "        else:\n",
    "            leaves = tree.sorted_leaves().popkeys()\n",
    "            tree_copy = tree.copy()\n",
    "        \n",
    "        sentence = ' '.join([x[0] for x in leaves])\n",
    "        sentence = sentence.replace(\"-\", \" \")\n",
    "        if sentence.lower() == self.hypothesis.lower():\n",
    "            self.tree_log = []\n",
    "            self.stop_critarion = True\n",
    "            self.tree_log.append((tree_copy, sentence, 1.0))\n",
    "            return\n",
    "        \n",
    "        similarity = inference_sts([sentence], [self.hypothesis])\n",
    "        #print(sentence, similarity)\n",
    "        if similarity > 0.8:\n",
    "            self.tree_log.append((tree_copy, sentence, similarity))\n",
    "        if similarity > 0.97:\n",
    "            self.tree_log = []\n",
    "            self.tree_log.append((tree_copy, sentence, similarity))\n",
    "            self.stop_critarion = True\n",
    "    \n",
    "    def remove_adjcent_duplicate(self, string):\n",
    "        to_remove = -1\n",
    "        for i in range(len(string)-1):\n",
    "            if string[i] == string[i+1]:\n",
    "                to_remove = i\n",
    "        if to_remove > -1:\n",
    "            del string[to_remove]\n",
    "\n",
    "    def search_dependency(self, deprel, tree):\n",
    "        if tree.val == deprel:\n",
    "            return True\n",
    "        else:\n",
    "            right = tree.right\n",
    "            left = tree.left\n",
    "\n",
    "            left_found = False\n",
    "            right_found = False\n",
    "\n",
    "            if right is not None:\n",
    "                right_found = self.search_dependency(deprel, right)\n",
    "\n",
    "            if left is not None:\n",
    "                left_found = self.search_dependency(deprel, left)\n",
    "\n",
    "            return left_found or right_found\n",
    "    \n",
    "    def Diff(self, li1, li2):\n",
    "        return (list(list(set(li1)-set(li2)) + list(set(li2)-set(li1))))    \n",
    "    \n",
    "    def preprocess(self, sentence):\n",
    "        preprocessed = sentence.replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\")\n",
    "        preprocessed = preprocessed.replace(\"can't\", \"can not\")\n",
    "        preprocessed = preprocessed.replace(\"couldn't\", \"could not\")\n",
    "        preprocessed = preprocessed.replace(\"don't\", \"do not\")\n",
    "        preprocessed = preprocessed.replace(\"doesn't\", \"does not\")\n",
    "        preprocessed = preprocessed.replace(\"isn't\", \"is not\")\n",
    "        preprocessed = preprocessed.replace(\"won't\", \"will not\")\n",
    "        preprocessed = preprocessed.replace(\"wasn't\", \"was not\")\n",
    "        preprocessed = preprocessed.replace(\"weren't\", \"were not\")\n",
    "        preprocessed = preprocessed.replace(\"didn't\", \"did not\")\n",
    "        preprocessed = preprocessed.replace(\"aren't\", \"are not\")\n",
    "        preprocessed = preprocessed.replace(\"it's\", \"it is\")\n",
    "        preprocessed = preprocessed.replace(\"wouldn't\", \"would not\")\n",
    "        preprocessed = preprocessed.replace(\"There's\", \"There is\")\n",
    "        return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifier_relation = {\n",
    "    \"NN\": [\"amod\", \"nmod\", \"acl:relcl\", \"fixed\", \"compound\", \"det\", \"nmod:poss\", \"conj\", \"nummod\"],\n",
    "    \"VB\": [\"advmod\", \"acl\", \"obl\", \"xcomp\", \"advcl\", \"obl:tmod\", \"parataxis\", \"obj\",\"ccomp\"]\n",
    "}\n",
    "\n",
    "def down_right(tree):\n",
    "    if(tree.right == None):\n",
    "        return tree\n",
    "    return down_right(tree.right)\n",
    "\n",
    "def down_left(tree):\n",
    "    if(tree.left == None):\n",
    "        return tree\n",
    "    return down_left(tree.left)\n",
    "\n",
    "def collect_modifiers(tree, sent_set, mod_type=\"NN\"):\n",
    "    leaves = []\n",
    "    if tree.is_tree:\n",
    "        if tree.val in [\"mark\", \"case\", \"compound\", \"flat\", \"nmod\"]:\n",
    "            leaves.append(\n",
    "                (list(tree.right.sorted_leaves().popkeys()),\n",
    "                down_right(tree.left).val)\n",
    "            )\n",
    "        if tree.val in modifier_relation[mod_type]:\n",
    "            leaves.append(\n",
    "                (list(tree.left.sorted_leaves().popkeys()),\n",
    "                down_right(tree.right).val)\n",
    "            )\n",
    "\n",
    "        for leave in leaves:\n",
    "            if len(leave) > 0 and len(leave) < 10:\n",
    "                head = leave[1]\n",
    "                modifier = ' '.join([x[0] for x in leave[0]])\n",
    "                if tree.val in sent_set:\n",
    "                    sent_set[tree.val].append({'head': head,'mod': modifier})\n",
    "                else:\n",
    "                    sent_set[tree.val] = [{'head': head,'mod': modifier}]\n",
    "        \n",
    "        collect_modifiers(tree.left, sent_set, mod_type)\n",
    "        collect_modifiers(tree.right, sent_set, mod_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n====================================\n\nInit Premise: A family is watching a little boy who is hitting a baseball\n\nHypothesis: There is no beautiful flowers that open at night\n{   'acl:relcl': [{'head': 'flowers', 'mod': 'that open at night'}],\n    'amod': [{'head': 'flowers', 'mod': 'beautiful'}],\n    'case': [{'head': 'at', 'mod': 'night'}, {'head': 'at', 'mod': 'night'}],\n    'det': [{'head': 'flowers', 'mod': 'no'}],\n    'obl': [{'head': 'open', 'mod': 'at night'}]}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nFalse\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "up = [\"A family is watching a little boy who is hitting a baseball.\"]\n",
    "up_h = [\"There is no beautiful flowers that open at night\"]\n",
    "\n",
    "annotations = []\n",
    "phrasalGenerator = PhrasalGenerator()\n",
    "pipeline = PolarizationPipeline(verbose=0)\n",
    "for i in range(len(up)):\n",
    "    premise = up[i]\n",
    "    hypothesis = up_h[i]\n",
    "    premise = phrasalGenerator.preprocess(premise)\n",
    "    hypothesis = phrasalGenerator.preprocess(hypothesis)\n",
    "\n",
    "    tokenized = tokenizer(premise).sentences[0].words\n",
    "    tokens = [tok.text for tok in tokenized]\n",
    "\n",
    "    print(\"\\n====================================\")\n",
    "    print(\"\\nInit Premise: \" + premise)\n",
    "    print(\"\\nHypothesis: \" + hypothesis)\n",
    "\n",
    "    h_parsed, replaced = dependency_parse(hypothesis, parser=\"stanza\")\n",
    "    h_tree, _ = pipeline.run_binarization(h_parsed, hypothesis, {})\n",
    "    pipeline.modify_replacement(h_tree, replaced)\n",
    "    phrases = {} \n",
    "    collect_modifiers(h_tree, phrases, mod_type=\"NN\")\n",
    "    collect_modifiers(h_tree, phrases, mod_type=\"VB\")\n",
    "    annotation = pipeline.single_polarization(premise)\n",
    "    \n",
    "    phrasalGenerator.kb = phrases\n",
    "    phrasalGenerator.hypothesis = hypothesis.replace(',', '')\n",
    "    pp.pprint(phrasalGenerator.kb)\n",
    "    \n",
    "    polarized = pipeline.postprocess(annotation['polarized_tree'], {})\n",
    "    btreeViz = Tree.fromstring(polarized.replace('[', '(').replace(']', ')'))\n",
    "    jupyter_draw_nltk_tree(btreeViz) \n",
    "\n",
    "    polarized = pipeline.postprocess(h_tree, {})\n",
    "    btreeViz = Tree.fromstring(polarized.replace('[', '(').replace(']', ')'))\n",
    "    jupyter_draw_nltk_tree(btreeViz)\n",
    "    \n",
    "    phrasalGenerator.deptree_generate(\n",
    "        annotation['polarized_tree'], \n",
    "        annotation['annotated'], tokens)\n",
    "\n",
    "    for gen_tree in phrasalGenerator.tree_log:\n",
    "        #leaves = gen_tree[0].sorted_leaves().popkeys()\n",
    "        #sentence = ' '.join([x[0] for x in leaves])\n",
    "        print((gen_tree[1], gen_tree[2]))\n",
    "\n",
    "    print(*phrasalGenerator.sent_log, sep=\"\\n\")\n",
    "    print(phrasalGenerator.stop_critarion)"
   ]
  },
  {
   "source": [
    "## 5. Lexical Monotonicity Inference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "import wordnet\n",
    "from wordnet import get_word_sets\n",
    "import importlib\n",
    "importlib.reload(wordnet)\n",
    "\n",
    "class LexicalGenerator:\n",
    "    def __init__(self):\n",
    "        self.deptree = None\n",
    "        self.hypothesis = \"\"\n",
    "        self.tree_log = []\n",
    "        self.anti_tree_log = []\n",
    "        self.polar_log = []\n",
    "        self.replacement_log = []\n",
    "        self.stop_critarion = False\n",
    "        self.key_tokens = [\n",
    "            'NN','NNS','NNP','NNPS','VBD',\n",
    "            'VBG','VBN','VBZ','VB',\"JJ\"]\n",
    "\n",
    "        self.propers = [\"someone\", \"something\", \"somewhere\"]\n",
    "\n",
    "        self.quantifiers = {}\n",
    "        self.lemmatizer = WordNetLemmatizer() \n",
    "        with open('quantifier.json', 'r') as quants:\n",
    "             quantifier_data = json.load(quants)\n",
    "             for quantifier in quantifier_data:\n",
    "                 self.quantifiers[quantifier['word']] = quantifier\n",
    "\n",
    "    def deptree_generate(self, tree):\n",
    "        self.replacement_log = []\n",
    "        self.tree_log = []\n",
    "        self.anti_tree_log = []\n",
    "        self.stop_critarion = False\n",
    "        self.deptree = tree.copy()\n",
    "        self.generate(self.deptree)\n",
    "\n",
    "    def generate(self, tree):\n",
    "        if tree is None or self.stop_critarion:\n",
    "            return\n",
    "        if tree.pos is not None and not tree.val in self.hypothesis: \n",
    "            backup = copy(tree.val)\n",
    "            if tree.pos == \"NNP\" and tree.mark == \"+\":\n",
    "                for word in self.propers:\n",
    "                    if word in self.hypothesis_tokens:\n",
    "                        tree.val = word\n",
    "                        self.save_tree()\n",
    "                        self.replacement_log.append(\n",
    "                            \"{} => {}\".format(backup, word))\n",
    "                        tree.val = backup\n",
    "\n",
    "            if tree.pos in self.key_tokens:\n",
    "                hyper, hypo, syn, ant = get_word_sets(\n",
    "                    self.lemmatizer.lemmatize(tree.val))\n",
    "\n",
    "                #print(tree.val, tree.mark, hyper)\n",
    "\n",
    "                for word in self.hypothesis_tokens:\n",
    "                    if syn.get(word, 0):\n",
    "                        tree.val = word\n",
    "                        self.save_tree()\n",
    "                        self.replacement_log.append(\n",
    "                            \"{} => {}\".format(backup, word))\n",
    "                tree.val = backup\n",
    "\n",
    "                for word in self.hypothesis_tokens:\n",
    "                    if ant.get(word, 0):\n",
    "                        tree.val = word\n",
    "                        self.save_tree(entail=False)\n",
    "                        self.replacement_log.append(\n",
    "                            \"{} => {}\".format(backup, word))\n",
    "                tree.val = backup\n",
    "\n",
    "                if tree.mark == \"+\":             \n",
    "                    for lex in hyper.keys():\n",
    "                        lex_ls = lex.split(' ')\n",
    "                        for key in lex_ls:\n",
    "                            #print(key)\n",
    "                            if self.hypothesis_tokens.get(key, 0):\n",
    "                                tree.val = self.hypothesis_tokens.get(key, 0)\n",
    "                                self.save_tree()\n",
    "                                self.replacement_log.append(\n",
    "                                    \"{} => {}\".format(backup, word))\n",
    "                    tree.val = backup\n",
    "\n",
    "                if tree.mark == \"-\":\n",
    "                    for word in self.hypothesis_tokens:\n",
    "                        for lex in hypo.keys():\n",
    "                            if word in lex: \n",
    "                                tree.val = word\n",
    "                                self.save_tree()\n",
    "                                self.replacement_log.append(\n",
    "                                    \"{} => {}\".format(backup, word))\n",
    "                    tree.val = backup\n",
    "            \n",
    "        elif tree.val == \"det\":\n",
    "            backup = tree.left.val\n",
    "            backup_mark = tree.right.mark\n",
    "            kb = self.quantifiers.get(tree.left.val.lower(), {})\n",
    "            if len(kb) > 0:\n",
    "\n",
    "                for word in kb[\"=\"]:\n",
    "                    tree.left.val = word\n",
    "                    detType = det_type(tree.left.val)\n",
    "                    if detType is None:\n",
    "                        detType = \"det:exist\"\n",
    "                    tree.left.mark = det_mark[detType]\n",
    "                    self.save_tree()\n",
    "                    self.replacement_log.append(\n",
    "                        \"{} => {}\".format(backup, word))\n",
    "                tree.left.val = backup\n",
    "                tree.left.mark = backup_mark\n",
    "\n",
    "                if tree.left.mark == \"+\":\n",
    "                    for word in kb[\"<\"]:\n",
    "                        if word in self.hypothesis:\n",
    "                            tree.left.val = word\n",
    "                            detType = det_type(tree.left.val)\n",
    "                            if detType is None:\n",
    "                                detType = \"det:exist\"\n",
    "                            tree.left.mark = det_mark[detType]\n",
    "                            self.save_tree()\n",
    "                            self.replacement_log.append(\n",
    "                                \"{} => {}\".format(backup, word))\n",
    "                    tree.left.val = backup\n",
    "                    tree.left.mark = backup_mark\n",
    "                \n",
    "                if tree.left.mark == \"-\":\n",
    "                    for word in kb[\">\"]:\n",
    "                        if word in self.hypothesis:\n",
    "                            tree.val = word\n",
    "                            if detType is None:\n",
    "                                detType = \"det:exist\"\n",
    "                            tree.left.mark = det_mark[detType]\n",
    "                            self.save_tree()\n",
    "                            self.replacement_log.append(\n",
    "                                \"{} => {}\".format(backup, word))\n",
    "                    tree.left.val = backup\n",
    "                    tree.left.mark = backup_mark\n",
    "        \n",
    "        if tree.left != \"N\":\n",
    "            self.generate(tree.left)\n",
    "        if tree.right != \"N\":\n",
    "            self.generate(tree.right)\n",
    "\n",
    "    def save_tree(self, entail=True):\n",
    "        leaves = self.deptree.sorted_leaves().popkeys()\n",
    "        tree_copy = self.deptree.copy()\n",
    "     \n",
    "        sentence = ' '.join([x[0] for x in leaves])\n",
    "        if sentence.lower() == self.hypothesis.lower():\n",
    "            self.stop_critarion = True\n",
    "            if entail:\n",
    "                self.tree_log = []\n",
    "                self.tree_log.append((tree_copy, sentence, 1.0))\n",
    "            else:\n",
    "                self.anti_tree_log = []\n",
    "                self.anti_tree_log.append((tree_copy, sentence, 1.0))\n",
    "            return\n",
    "        \n",
    "        similarity = inference_sts([sentence], [self.hypothesis])\n",
    "        if similarity > 0.8:\n",
    "            if entail:\n",
    "                self.tree_log.append((tree_copy, sentence, similarity))\n",
    "            else:\n",
    "                self.anti_tree_log.append((tree_copy, sentence, similarity))\n",
    "        if similarity > 0.97:\n",
    "            self.stop_critarion = True\n",
    "            if entail:\n",
    "                self.tree_log = []\n",
    "                self.tree_log.append((tree_copy, sentence, similarity))\n",
    "            else:\n",
    "                self.anti_tree_log = []\n",
    "                self.anti_tree_log.append((tree_copy, sentence, similarity))\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "shirts + {'garment': 1, 'dress': 1, 'clothe': 1, 'enclothe': 1, 'garb': 1, 'raiment': 1, 'tog': 1, 'habilitate': 1, 'fit out': 1, 'apparel': 1, 'an item of clothing': 1, 'an article of clothing': 1, 'clothes': 1, 'top': 1, 'a garment': 1, 'enveloping covering': 1}\ngarment\ndress\nclothe\nenclothe\ngarb\nraiment\ntog\nhabilitate\nfit\nout\napparel\nan\nitem\nof\nclothing\nan\narticle\nof\nclothing\nclothes\ntop\na\ngarment\nenveloping\ncovering\n('Every alien bought some clothes', 1.0)\n['Every => each', 'Every => all', 'Every => all-of-the', 'Every => each-of-the', 'some => a', 'some => an', 'some => one', 'shirts => clothes']\nTrue\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "sentences = [\"Every alien bought some shirts.\"]\n",
    "hypotheses = [\"Every alien bought some clothes.\"]\n",
    "\n",
    "pipeline = PolarizationPipeline(verbose=0)\n",
    "lexicalGenerator = LexicalGenerator()\n",
    "phrasalGenerator = PhrasalGenerator()\n",
    "\n",
    "for premise, hypothesis in zip(sentences, hypotheses):\n",
    "    premise = phrasalGenerator.preprocess(premise)\n",
    "    hypothesis = phrasalGenerator.preprocess(hypothesis)\n",
    "\n",
    "    #print(\"\\n====================================\")\n",
    "    #print(\"\\nInit Premise: \" + premise)\n",
    "    #print(\"\\nHypothesis: \" + hypothesis)\n",
    "\n",
    "    tokenized = tokenizer(hypothesis).sentences[0].words\n",
    "    tokens = {} \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    for tok in tokenized:\n",
    "        tokens[lemmatizer.lemmatize(tok.text)] = tok.text\n",
    "    lexicalGenerator.hypothesis_tokens = tokens\n",
    "\n",
    "    annotation = pipeline.single_polarization(premise)\n",
    "    polarized = pipeline.postprocess(annotation['polarized_tree'], {})\n",
    "    btreeViz = Tree.fromstring(polarized.replace('[', '(').replace(']', ')'))\n",
    "    jupyter_draw_nltk_tree(btreeViz) \n",
    "\n",
    "    lexicalGenerator.hypothesis = hypothesis.replace(',', '')\n",
    "    lexicalGenerator.deptree_generate(annotation['polarized_tree'])\n",
    "    \n",
    "    for gen_tree in lexicalGenerator.tree_log:\n",
    "        print((gen_tree[1], gen_tree[2]))\n",
    "    for anti_tree in lexicalGenerator.anti_tree_log:\n",
    "        print((anti_tree[1], anti_tree[2]))\n",
    "\n",
    "    print(lexicalGenerator.replacement_log)\n",
    "    print(lexicalGenerator.stop_critarion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "168\n334\n"
     ]
    }
   ],
   "source": [
    "MED_upward = []\n",
    "MED_upward_hypo = []\n",
    "MED_downward = []\n",
    "MED_downward_hypo = []\n",
    "\n",
    "with open(\"../data/MED/upward_lexical.txt\") as upward_med:\n",
    "    lines = upward_med.readlines()\n",
    "    for i in range(len(lines) // 4):\n",
    "        MED_upward.append(lines[i*4+1])\n",
    "        MED_upward_hypo.append(lines[i*4+2])\n",
    "\n",
    "with open(\"../data/MED/downward_lexical.txt\") as donward_med:\n",
    "    lines = donward_med.readlines()\n",
    "    for i in range(len(lines) // 4):\n",
    "        MED_downward.append(lines[i*4+1])\n",
    "        MED_downward_hypo.append(lines[i*4+2])\n",
    "\n",
    "print(len(MED_upward))\n",
    "print(len(MED_downward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'MED_upward' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-9c7765bca763>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./generation_log_upward.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgenerate_log\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMED_upward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mpremise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphrasalGenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMED_upward\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mhypothesis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphrasalGenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMED_upward_hypo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MED_upward' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "sentences = [\"Some dogs like to scratch their ears.\",\n",
    "             \"Every alien bought shirts.\"]\n",
    "hypotheses = [\"Some animals like to scratch their ears.\",\n",
    "              \"Every alien bought clothes.\"]\n",
    "\n",
    "pipeline = PolarizationPipeline(verbose=0)\n",
    "lexicalGenerator = LexicalGenerator()\n",
    "phrasalGenerator = PhrasalGenerator()\n",
    "\n",
    "with open(\"./generation_log_upward.txt\", 'w') as generate_log:\n",
    "    for i in tqdm(range(0, len(MED_upward))):\n",
    "        premise = phrasalGenerator.preprocess(MED_upward[i])\n",
    "        hypothesis = phrasalGenerator.preprocess(MED_upward_hypo[i])\n",
    "\n",
    "        #print(\"\\n====================================\")\n",
    "        #print(\"\\nInit Premise: \" + premise)\n",
    "        #print(\"\\nHypothesis: \" + hypothesis)\n",
    "\n",
    "        tokenized = tokenizer(hypothesis).sentences[0].words\n",
    "        tokens = {} \n",
    "        lemmatizer = WordNetLemmatizer() \n",
    "        for tok in tokenized:\n",
    "            tokens[lemmatizer.lemmatize(tok.text)] = tok.text\n",
    "        lexicalGenerator.hypothesis_tokens = tokens\n",
    "\n",
    "        annotation = pipeline.single_polarization(premise)\n",
    "\n",
    "        lexicalGenerator.hypothesis = hypothesis.replace(',', '')\n",
    "        lexicalGenerator.deptree_generate(annotation['polarized_tree'])\n",
    "        \n",
    "        #for gen_tree in lexicalGenerator.tree_log:\n",
    "        #    print((gen_tree[1], gen_tree[2]))\n",
    "        #for anti_tree in lexicalGenerator.anti_tree_log:\n",
    "        #    print((anti_tree[1], anti_tree[2]))\n",
    "\n",
    "        if not lexicalGenerator.stop_critarion:\n",
    "            generate_log.write(\"\\nID: \" + str(i))\n",
    "            generate_log.write(\"\\nPremise: \" + premise)\n",
    "            generate_log.write(\"\\nHypothesis: \" + hypothesis)\n",
    "            #print(\"\\nPremise: \" + premise)\n",
    "            #print(\"\\nHypothesis: \" + hypothesis)\n",
    "            #print(*phrasalGenerator.sent_log, sep=\"\\n\")\n",
    "            #generate_log.writelines(phrasalGenerator.sent_log)\n",
    "            generate_log.write('\\n')\n",
    "\n",
    "        #print(lexicalGenerator.replacement_log)\n",
    "        #print(lexicalGenerator.stop_critarion)"
   ]
  },
  {
   "source": [
    "## 6. Syntactic Variational Inference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunker import Chunker\n",
    "\n",
    "class SyntacticVariator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chunker = Chunker()\n",
    "        self.paraphraseTokenizer = paraphraseTokenizer\n",
    "        self.paraphraseModel = paraphraseModel\n",
    "\n",
    "    def chunking(self, tree):\n",
    "        return self.chunker.get_chunks_byDepTree(tree)\n",
    "\n",
    "    def build_pairs(self, chunks1, chunks2):\n",
    "        chunk_pairs = []\n",
    "        for chunk1 in chunks1:\n",
    "            for chunk2 in chunks2:\n",
    "                if len(set(chunk1.split(' ')).intersection(chunk2.split(' '))) > 0:\n",
    "                     chunk_pairs.append((chunk1, chunk2))\n",
    "\n",
    "        return chunk_pairs\n",
    "\n",
    "    def inference_mrpc(self, seq1, seq2):\n",
    "        paraphrase = paraphraseTokenizer.encode_plus(\n",
    "            seq1, seq2, return_tensors=\"pt\")\n",
    "        paraphrase.to('cuda')\n",
    "        logits = paraphraseModel(**paraphrase)[0]\n",
    "        paraphrase_results = torch.softmax(logits, dim=1).tolist()[0]\n",
    "        return paraphrase_results[1]\n",
    "\n",
    "    def phrase_alignment(self, chunk_pairs):\n",
    "        alignments = []\n",
    "        for pair in chunk_pairs:\n",
    "            score = self.inference_mrpc(pair[0], pair[1])\n",
    "            #print(pair, score)\n",
    "            if score > 0.80:\n",
    "                alignments.append(pair)\n",
    "\n",
    "        return alignments\n",
    "\n",
    "    def variate(self, P, H, p_tree, h_tree, sent=False):\n",
    "        p_chunks = self.chunking(p_tree)\n",
    "        h_chunks = self.chunking(h_tree)\n",
    "\n",
    "        if sent:\n",
    "            p_chunks.append(P)\n",
    "            h_chunks.append(H)\n",
    "\n",
    "        chunk_pairs = self.build_pairs(p_chunks, h_chunks)\n",
    "        alignments = self.phrase_alignment(chunk_pairs)\n",
    "\n",
    "        #print(*p_chunks, sep=\"\\n\")\n",
    "        #print(*h_chunks, sep=\"\\n\")\n",
    "\n",
    "        variates = set()\n",
    "        for align in alignments:\n",
    "            var_sentence = P.replace(align[0], align[1])\n",
    "            variates.add(var_sentence)\n",
    "\n",
    "        return variates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Two children are hanging on a large branch tensor(0.7072)\n"
     ]
    }
   ],
   "source": [
    "premise = \"Two children are hanging on a large branch\"\n",
    "hypothesis = \"Two children are climing a tree\"\n",
    "\n",
    "pipeline = PolarizationPipeline()\n",
    "syntacticVariator = SyntacticVariator()\n",
    "\n",
    "h_parsed, replaced = dependency_parse(hypothesis, parser=\"stanza\")\n",
    "h_tree, _ = pipeline.run_binarization(h_parsed, hypothesis, {})\n",
    "pipeline.modify_replacement(h_tree, replaced)\n",
    "annotation = pipeline.single_polarization(premise)\n",
    "\n",
    "variates = syntacticVariator.variate(premise, hypothesis, annotation['polarized_tree'],  h_tree, sent=False)\n",
    "for v in variates:\n",
    "    similarity = inference_sts([v], [hypothesis])\n",
    "    print(v, similarity)"
   ]
  },
  {
   "source": [
    "## 7. A* Inference Search Engine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pqdict import pqdict\n",
    "\n",
    "class AStarPlanner:\n",
    "    def __init__(self):    \n",
    "        self.closed = []                  \n",
    "        self.entailments = set()\n",
    "        self.contradictions = set()\n",
    "        self.hypothesis = \"\"\n",
    "        self.h_tree = None\n",
    "\n",
    "        self.pipeline = PolarizationPipeline()\n",
    "        self.phrasalGenerator = PhrasalGenerator()\n",
    "        self.lexicalGenerator = LexicalGenerator()\n",
    "        self.syntacticVariator = SyntacticVariator() \n",
    "\n",
    "    def hypothesis_kb(self):\n",
    "        self.hypothesis = self.phrasalGenerator.preprocess(self.hypothesis)\n",
    "        h_parsed, replaced = dependency_parse(self.hypothesis, parser=\"stanza\")\n",
    "        h_tree, _ = self.pipeline.run_binarization(h_parsed, self.hypothesis, {})\n",
    "        self.pipeline.modify_replacement(h_tree, replaced)\n",
    "        phrases = {} \n",
    "        collect_modifiers(h_tree, phrases, mod_type=\"NN\")\n",
    "        collect_modifiers(h_tree, phrases, mod_type=\"VB\")\n",
    "        self.phrasalGenerator.kb = phrases\n",
    "        self.h_tree = h_tree\n",
    "\n",
    "    def generate_premises(self, start):\n",
    "        self.entailments.clear()\n",
    "        self.contradictions.clear()\n",
    "\n",
    "        # Polarization from Udeo2Mono\n",
    "        start = self.phrasalGenerator.preprocess(start)\n",
    "        annotation = self.pipeline.single_polarization(start)\n",
    "\n",
    "        # Monotonicity-based Phrasl Inference\n",
    "        self.phrasalGenerator.hypothesis = self.hypothesis.replace(',', '')\n",
    "\n",
    "        tokenized = tokenizer(start).sentences[0].words\n",
    "        tokens = [tok.text for tok in tokenized]\n",
    "\n",
    "        self.phrasalGenerator.deptree_generate(\n",
    "        annotation['polarized_tree'], \n",
    "        annotation['annotated'], tokens)\n",
    "        #print(\"============================\")\n",
    "        \n",
    "        if self.phrasalGenerator.stop_critarion:\n",
    "            return True\n",
    "\n",
    "        for tree in self.phrasalGenerator.tree_log:\n",
    "            self.entailments.add((tree[1], tree[2]))\n",
    "        self.entailments |= set(self.phrasalGenerator.sent_log)\n",
    "\n",
    "        #print(*self.entailments, sep=\"\\n\")\n",
    "\n",
    "        # Syntactic Vriation\n",
    "        # Sequence Chunking and Chunk Alignment from roBERTa\n",
    "        sent_level = False\n",
    "        if self.current_optimal > 0.93 :\n",
    "            sent_level = True\n",
    "        variates = self.syntacticVariator.variate(\n",
    "            start, \n",
    "            self.hypothesis, \n",
    "            annotation['polarized_tree'], \n",
    "            self.h_tree, sent_level)\n",
    "        for v in variates:\n",
    "            similarity = inference_sts([v], [self.hypothesis])\n",
    "            if similarity > 0.98:\n",
    "                return True\n",
    "            elif similarity > 0.9:\n",
    "                self.entailments.add((v, similarity))\n",
    "\n",
    "        #TODO: Monotonicity-based Lexical Inference\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer() \n",
    "        tokens_dict = {}\n",
    "        for tok in tokenized:\n",
    "            tokens_dict[lemmatizer.lemmatize(tok.text)] = tok.text\n",
    "        self.lexicalGenerator.hypothesis_tokens = tokens_dict\n",
    "        self.lexicalGenerator.hypothesis = self.hypothesis.replace(',', '')\n",
    "        \n",
    "        self.lexicalGenerator.deptree_generate(annotation['polarized_tree'])\n",
    "        if self.lexicalGenerator.stop_critarion:\n",
    "            return True\n",
    "        for tree in self.lexicalGenerator.tree_log:\n",
    "            #print((tree[1], tree[2]))\n",
    "            self.entailments.add((tree[1], tree[2]))\n",
    "\n",
    "        return False\n",
    "\n",
    "    def generate(self, start, opened):\n",
    "        terminate = self.generate_premises(start)\n",
    "        if terminate:\n",
    "            return True\n",
    "\n",
    "        for premise in self.entailments:\n",
    "            if premise in self.closed:\n",
    "                continue\n",
    "            cost = premise[1]\n",
    "            if premise[0] not in opened:\n",
    "                opened[premise[0]] = cost\n",
    "            if cost < opened[premise[0]]:\n",
    "                opened[premise[0]] = cost\n",
    "        return False\n",
    "\n",
    "    def search(self, premises, hypothesis):\n",
    "        self.closed = pqdict({})\n",
    "        self.hypothesis = hypothesis\n",
    "\n",
    "        self.hypothesis_kb()\n",
    "        self.phrasalGenerator.hypothesis = self.hypothesis\n",
    "        self.lexicalGenerator.hypothesis = self.hypothesis\n",
    "\n",
    "        open_lists = pqdict({}, reverse=True)\n",
    "        open_lists[premises] = inference_sts([premises], [hypothesis])\n",
    "\n",
    "        hop = 0\n",
    "        top_k = 2\n",
    "\n",
    "        while open_lists:\n",
    "            for _ in range(top_k):\n",
    "                if len(open_lists) > 0:\n",
    "                    optimal = open_lists.popitem()\n",
    "                    self.current_optimal = optimal[1]\n",
    "                    #print(\"Optimal: \", optimal)\n",
    "                    goal_found = self.generate(optimal[0], open_lists)\n",
    "                    self.closed[optimal] = len(self.closed) + 1\n",
    "                    if goal_found:\n",
    "                        self.closed[(self.hypothesis, 1.0)] = len(self.closed) + 1\n",
    "                        return True\n",
    "                else: break   \n",
    "            hop += 1\n",
    "            if hop > 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = AStarPlanner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 334/334 [09:06<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "with open(\"./generation_log_downward.txt\", 'w') as generate_log:\n",
    "    for i in tqdm(range(0, len(MED_downward))):\n",
    "        premise = phrasalGenerator.preprocess(MED_downward[i])\n",
    "        hypothesis = phrasalGenerator.preprocess(MED_downward_hypo[i])\n",
    "        try:\n",
    "            entail = planner.search(premise, hypothesis)\n",
    "            if not entail:\n",
    "                generate_log.write(\"\\nID: \" + str(i))\n",
    "                generate_log.write(\"\\nPremise: \" + premise)\n",
    "                generate_log.write(\"\\nHypothesis: \" + hypothesis)\n",
    "                generate_log.write('\\n')\n",
    "        except:\n",
    "            generate_log.write(\"\\nID: \" + str(i))\n",
    "            generate_log.write(\"\\nPremise: \" + premise)\n",
    "            generate_log.write(\"\\nHypothesis: \" + hypothesis)\n",
    "            generate_log.write('\\n')\n",
    "\n",
    "        #print(*planner.closed, sep=\" =>\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('Every alien bought some shirts', tensor(0.8394)) =>\n('Every alien bought some clothes', 1.0)\nTrue\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"Every alien bought some shirts\", \n",
    "             \"Every alien bought some clothes\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  ('A family is watching a little boy who is hitting a baseball', tensor(0.7123))\n",
      "============================\n",
      "Optimal:  ('a little boy who is hitting a baseball', tensor(0.9348))\n",
      "============================\n",
      "('A family is watching a little boy who is hitting a baseball', tensor(0.7123)) =>\n",
      "('a little boy who is hitting a baseball', tensor(0.9348)) =>\n",
      "('A child is hitting a baseball', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"A family is watching a little boy who is hitting a baseball\", \n",
    "             \"A child is hitting a baseball\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  ('You know that some life changing actions must be taken when grandma reacts with the sad emoji', tensor(0.9705))\n",
      "============================\n",
      "('You know that some life changing actions must be taken when grandma reacts with the sad emoji', tensor(0.9705)) =>\n",
      "('You know that some actions must be taken when grandma reacts with the sad emoji', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"You know that some life changing actions must be taken when grandma reacts with the sad emoji\", \"You know that some actions must be taken when grandma reacts with the sad emoji\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  ('A black and a white dog are joyfully running on the grass', tensor(0.6965))\n",
      "============================\n",
      "Optimal:  ('A black and a white dog are running on the grass', tensor(0.9178))\n",
      "============================\n",
      "Optimal:  ('A black and a white dog are running on the grass', tensor(0.9372))\n",
      "============================\n",
      "('A black and a white dog are joyfully running on the grass', tensor(0.6965)) =>\n",
      "('A black and a white dog are running on the grass', tensor(0.9178)) =>\n",
      "('A black and a white dog are running on the grass', tensor(0.9372)) =>\n",
      "('A dog, which has a black coat, and a white dog are running on the grass', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"A black and a white dog are joyfully running on the grass\", \n",
    "             \"A dog, which has a black coat, and a white dog are running on the grass\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  ('A motorcyclist with a red helmet is riding a blue motorcycle down the road', tensor(0.8065))\n",
      "============================\n",
      "Optimal:  ('A motorcyclist is riding a blue motorcycle down the road', tensor(0.8747))\n",
      "============================\n",
      "Optimal:  ('A motorcyclist is riding a motorbike down the road', tensor(0.9481))\n",
      "============================\n",
      "('A motorcyclist with a red helmet is riding a blue motorcycle down the road', tensor(0.8065)) =>\n",
      "('A motorcyclist is riding a blue motorcycle down the road', tensor(0.8747)) =>\n",
      "('A motorcyclist is riding a motorbike down the road', tensor(0.9481)) =>\n",
      "('A motorcyclist is riding a motorbike along a roadway', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"A motorcyclist with a red helmet is riding a blue motorcycle down the road\", \n",
    "             \"A motorcyclist is riding a motorbike along a roadway\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  ('A family is watching a little boy who is hitting a baseball', tensor(0.7123))\n",
      "============================\n",
      "Optimal:  ('a little boy who is hitting a baseball', tensor(0.9348))\n",
      "============================\n",
      "('A family is watching a little boy who is hitting a baseball', tensor(0.7123)) =>\n",
      "('a little boy who is hitting a baseball', tensor(0.9348)) =>\n",
      "('A child is hitting a baseball', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"A family is watching a little boy who is hitting a baseball\", \n",
    "             \"A child is hitting a baseball\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  ('A deer is jumping over a fence', tensor(0.9798))\n",
      "============================\n",
      "('A deer is jumping over a fence', tensor(0.9798)) =>\n",
      "('A deer is jumping a fence', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"A deer is jumping over a fence\", \n",
    "             \"A deer is jumping a fence\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  ('A boy is hitting a baseball', tensor(1.0000))\n",
      "============================\n",
      "('A boy is hitting a baseball', tensor(1.0000)) =>\n",
      "('A boy is hitting a baseball', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"A boy is hitting a baseball\", \n",
    "             \"A chil is hitting a baseball\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  ('A brown dog is attacking another animal in front of the tall man in pants', tensor(0.8783))\n",
      "============================\n",
      "Optimal:  ('A dog is attacking another animal in front of the tall man in pants', tensor(0.9582))\n",
      "============================\n",
      "('A brown dog is attacking another animal in front of the tall man in pants', tensor(0.8783)) =>\n",
      "('A dog is attacking another animal in front of the tall man in pants', tensor(0.9582)) =>\n",
      "('A dog is attacking another animal in front of the man in pants', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"A brown dog is attacking another animal in front of the tall man in pants\", \n",
    "             \"A dog is attacking another animal in front of the man in pants\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  ('A family is watching a little boy who is hitting a baseball', tensor(0.9915))\n",
      "============================\n",
      "('A family is watching a little boy who is hitting a baseball', tensor(0.9915)) =>\n",
      "('A family is watching a boy who is hitting a baseball', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"A family is watching a little boy who is hitting a baseball\", \n",
    "             \"A family is watching a boy who is hitting a baseball\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  (\"You can't park in front of my house on weekends.\", tensor(0.9529))\n",
      "============================\n",
      "(\"You can't park in front of my house on weekends.\", tensor(0.9529)) =>\n",
      "('You can not park in front of my large house on weekends', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"You can't park in front of my house on weekends.\", \n",
    "             \"You can't park in front of my large house on weekends.\")\n",
    "\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "annotations = []\n",
    "with open(\"./generation_log_upward.txt\", 'w') as generate_log:\n",
    "    phrasalGenerator = PhrasalGenerator()\n",
    "    pipeline = PolarizationPipeline(verbose=0)\n",
    "    for i in tqdm(range(0, 500)):\n",
    "        premise = MED_none[i].replace('\\n', '')\n",
    "        hypothesis = MED_none_hypo[i].replace('\\n', '')\n",
    "        premise = phrasalGenerator.preprocess(premise)\n",
    "        hypothesis = phrasalGenerator.preprocess(hypothesis)\n",
    "\n",
    "        tokenized = tokenizer(premise).sentences[0].words\n",
    "        tokens = [tok.text for tok in tokenized]\n",
    "\n",
    "        try:\n",
    "            h_parsed, replaced = dependency_parse(hypothesis, parser=\"stanza\")\n",
    "            h_tree, _ = pipeline.run_binarization(h_parsed, hypothesis, {})\n",
    "        except:\n",
    "            generate_log.write(\"\\nPremise: \" + premise)\n",
    "            generate_log.write(\"\\nHypothesis: \" + hypothesis)\n",
    "            continue\n",
    "        pipeline.modify_replacement(h_tree, replaced)\n",
    "        phrases = {} \n",
    "        collect_modifiers(h_tree, phrases, mod_type=\"NN\")\n",
    "        collect_modifiers(h_tree, phrases, mod_type=\"VB\")\n",
    "\n",
    "        try:\n",
    "            annotation = pipeline.single_polarization(premise)\n",
    "        except:\n",
    "            #generate_log.write(\"\\nPremise: \" + premise)\n",
    "            #generate_log.write(\"\\nHypothesis: \" + hypothesis)\n",
    "            continue\n",
    "    \n",
    "        phrasalGenerator.kb = phrases\n",
    "        #print(phrasalGenerator.kb)\n",
    "        phrasalGenerator.hypothesis = hypothesis.replace(',', '')\n",
    "        \n",
    "        phrasalGenerator.deptree_generate(\n",
    "            annotation['polarized_tree'], \n",
    "            annotation['annotated'], \n",
    "            tokens)\n",
    "\n",
    "        # for gen_tree in phrasalGenerator.tree_log:\n",
    "        #    leaves = gen_tree[0].sorted_leaves().popkeys()\n",
    "        #    sentence = ' '.join([x[0] for x in leaves])\n",
    "        #    print((sentence, gen_tree[1]))\n",
    "            \n",
    "        if phrasalGenerator.stop_critarion:\n",
    "            generate_log.write(\"\\nID: \" + str(i))\n",
    "            generate_log.write(\"\\nPremise: \" + premise)\n",
    "            generate_log.write(\"\\nHypothesis: \" + hypothesis)\n",
    "            #print(\"\\nPremise: \" + premise)\n",
    "            #print(\"\\nHypothesis: \" + hypothesis)\n",
    "            #print(*phrasalGenerator.sent_log, sep=\"\\n\")\n",
    "            #generate_log.writelines(phrasalGenerator.sent_log)\n",
    "            generate_log.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}