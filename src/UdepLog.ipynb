{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UdepLog Neural-Logical Inference System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tree import Tree\n",
    "from nltk.draw import TreeWidget\n",
    "from nltk.draw.util import CanvasFrame\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def jupyter_draw_nltk_tree(tree):\n",
    "    cf = CanvasFrame()\n",
    "    tc = TreeWidget(cf.canvas(), tree)\n",
    "    tc['node_font'] = 'arial 14 bold'\n",
    "    tc['leaf_font'] = 'arial 14'\n",
    "    tc['node_color'] = '#005990'\n",
    "    tc['leaf_color'] = '#3F8F57'\n",
    "    tc['line_color'] = '#175252'\n",
    "    cf.add_widget(tc, 20, 20)\n",
    "    os.system('rm -rf ../data/tree.png')\n",
    "    os.system('rm -rf ../data/tree.ps')\n",
    "    cf.print_to_file('../data/tree.ps')\n",
    "    cf.destroy()\n",
    "    os.system('magick convert ../data/tree.ps ../data/tree.png')\n",
    "    display(Image(filename='../data/tree.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. BERT Model for Pharaphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-MRPC were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Alignment Model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "roberta_MRPC = \"textattack/roberta-base-MRPC\"\n",
    "bert_MRPC = \"bert-base-cased-finetuned-mrpc\"\n",
    "\n",
    "paraphraseTokenizer = AutoTokenizer.from_pretrained(roberta_MRPC)  \n",
    "paraphraseModel = AutoModelForSequenceClassification.from_pretrained(roberta_MRPC)\n",
    "#paraphraseModel.to('cuda')\n",
    "print(\"Load Alignment Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. UD Parser and RoBERTa Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-21 19:15:05 INFO: Loading these models for language: en (English):\n",
      "========================================\n",
      "| Processor | Package                  |\n",
      "----------------------------------------\n",
      "| tokenize  | ../model/e...ize/gum.pt  |\n",
      "| pos       | ../model/en/pos/ewt.pt   |\n",
      "| lemma     | ../model/en/lemma/gum.pt |\n",
      "| depparse  | ../model/e...rse/gum.pt  |\n",
      "========================================\n",
      "\n",
      "2021-03-21 19:15:05 INFO: Use device: cpu\n",
      "2021-03-21 19:15:05 INFO: Loading: tokenize\n",
      "2021-03-21 19:15:05 INFO: Loading: pos\n",
      "2021-03-21 19:15:06 INFO: Loading: lemma\n",
      "2021-03-21 19:15:06 INFO: Loading: depparse\n",
      "2021-03-21 19:15:07 INFO: Done loading processors!\n",
      "2021-03-21 19:15:07 INFO: Loading these models for language: en (English):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | ../model/e...ize/gum.pt |\n",
      "=======================================\n",
      "\n",
      "2021-03-21 19:15:07 INFO: Use device: cpu\n",
      "2021-03-21 19:15:07 INFO: Loading: tokenize\n",
      "2021-03-21 19:15:07 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from wordnet import *\n",
    "from copy import deepcopy\n",
    "from Udep2Mono.util import det_mark, det_type\n",
    "from Udep2Mono.util import btree2list\n",
    "from Udep2Mono.dependency_parse import tokenizer\n",
    "from Udep2Mono.dependency_parse import dependency_parse\n",
    "from Udep2Mono.binarization import BinaryDependencyTree\n",
    "from Udep2Mono.polarization import PolarizationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gaoq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "sentenceTransformer = SentenceTransformer(\"roberta-large-nli-stsb-mean-tokens\")\n",
    "#sentenceTransformer.to('cuda')\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "ign_words = dict()\n",
    "for word in stopwords.words('english'):\n",
    "    ign_words[word] = 1\n",
    "\n",
    "def inference_sts(seq1s, seq2s, dist=False):\n",
    "    embeddings1 = sentenceTransformer.encode(seq1s, convert_to_tensor=True)\n",
    "    embeddings2 = sentenceTransformer.encode(seq2s, convert_to_tensor=True)\n",
    "    cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    distance = torch.dist(embeddings1, embeddings2)\n",
    "    if dist:\n",
    "        return distance\n",
    "    return cosine_scores[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Phrasal Monotonicity Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import pluralize, singularize\n",
    "from copy import copy\n",
    "import re\n",
    "import torch\n",
    "\n",
    "class PhrasalGenerator:\n",
    "    def __init__(self):\n",
    "        self.deptree = None\n",
    "        self.annotated = None\n",
    "        self.original = None\n",
    "        self.kb = {}\n",
    "        self.hypothesis = \"\"\n",
    "        self.tree_log = []\n",
    "        self.sent_log = []\n",
    "        self.stop_critarion = False\n",
    "        self.mod_at_left = [\n",
    "            \"advmod\", \"amod\", \"advmod:count\", \n",
    "            \"acl:relcl\", \"obl\", 'obl:npmod', \"det\",\n",
    "            \"obl:tmod\", \"nmod\", \"nmod:npmod\", \n",
    "            \"nmod:poss\", \"nmod:tmod\", \"obl:npmod\",\n",
    "            \"acl\", \"advcl\", \"xcomp\", \"ccomp\", \n",
    "            'compound:ptr']\n",
    "        self.mod_at_right = [\"appos\"] #\"obj\"\n",
    "        self.mod_symmetric = [\"conj\", \"compound\"]\n",
    "        self.mod_special = [\"nsubj\"]\n",
    "        self.implicative = {\n",
    "            \"watching\": 1\n",
    "        }\n",
    "        \n",
    "        '''  \n",
    "            \"cop\": self.generate_inherite, \n",
    "            \"expl\": self.generate_expl,\n",
    "            \"nummod\": self.generate_nummod,\n",
    "        '''\n",
    "\n",
    "    def deptree_generate(self, tree, annotated, original):\n",
    "        self.stop_critarion = False\n",
    "        self.tree_log = []\n",
    "        self.sent_log = []\n",
    "        self.deptree = tree.copy()\n",
    "        self.original = original  \n",
    "        self.annotated = deepcopy(annotated)\n",
    "        self.sentence = original\n",
    "        self.generate(self.deptree)\n",
    "\n",
    "    def generate(self, tree):\n",
    "        if self.stop_critarion:\n",
    "            return\n",
    "        if not tree.is_tree:\n",
    "            self.generate_default(tree)\n",
    "        else:\n",
    "            generation = self.get_generation_type(tree)\n",
    "            #print(generation, tree.val)\n",
    "            generation(tree)\n",
    "    def removeGroup(self, tree):\n",
    "        if(tree.val == \"nmod\"):\n",
    "            if(tree.right.is_tree and tree.right.left.val.lower() == \"a\"):\n",
    "                if(tree.left.is_tree and tree.left.left.val.lower() == \"of\"):\n",
    "                    noun = tree.left.right\n",
    "                    group = tree.right.right\n",
    "                    self.delete_modifier(tree, noun)\n",
    "                    self.delete_modifier(tree, group)\n",
    "                    return True\n",
    "        return False\n",
    "    def get_generation_type(self, tree):\n",
    "        if tree.val in self.mod_special:\n",
    "            return self.generate_special\n",
    "\n",
    "        disjunction = False\n",
    "        if tree.val == \"conj\":\n",
    "            disjunction |= self.search_dependency('or', tree.left)\n",
    "            disjunction |= self.search_dependency('and', tree.left)\n",
    "        \n",
    "        left_mod = tree.left.mark == \"+\"\n",
    "        left_mod = left_mod or tree.left.mark == \"=\" or disjunction\n",
    "        left_mod = left_mod and tree.val in self.mod_at_left\n",
    "\n",
    "        right_mod = tree.right.mark == \"+\" or tree.right.mark == \"=\" or disjunction \n",
    "        right_mod = right_mod and tree.val in self.mod_at_right\n",
    "\n",
    "        sym_mod = tree.val in self.mod_symmetric and tree.left.mark == \"+\" and tree.right.mark == \"+\"\n",
    "        \n",
    "        if left_mod:\n",
    "            return self.left_modifier_generate\n",
    "        elif right_mod:\n",
    "            return self.right_modifier_generate\n",
    "        elif sym_mod:\n",
    "            return self.symmetric_generate\n",
    "        else:\n",
    "            return self.generate_default\n",
    "\n",
    "    def generate_special(self, tree):\n",
    "        if tree.val == \"nsubj\":\n",
    "            if tree.left.val == \"who\" and tree.right.val == \"aux\":\n",
    "                self.left_modifier_generate(tree)\n",
    "\n",
    "        self.generate(tree.left)\n",
    "        self.generate(tree.right)\n",
    "\n",
    "    def delete_cc(self, tree):\n",
    "        if tree.val == \"cc\" and tree.left.val != \"but\":\n",
    "            self.delete_modifier(tree, tree.right)\n",
    "\n",
    "        if tree.is_tree:\n",
    "            self.delete_cc(tree.left)\n",
    "            self.delete_cc(tree.right)\n",
    "\n",
    "    def delete_modifier(self, tree, modifier):\n",
    "        tree.val = modifier.val\n",
    "        tree.mark = modifier.mark\n",
    "        tree.pos = modifier.pos\n",
    "        tree.id = modifier.id\n",
    "        \n",
    "        tree.is_tree = modifier.is_tree\n",
    "        tree.is_root = modifier.is_root\n",
    "\n",
    "        tree.left = modifier.left\n",
    "        tree.right = modifier.right\n",
    "\n",
    "        self.delete_cc(tree)\n",
    "        self.save_tree()\n",
    "\n",
    "    def delete_left_modifier(self, tree):\n",
    "        #print(\"Delet: \", tree.left.val)\n",
    "        group = self.removeGroup(tree)\n",
    "        if(not group):\n",
    "            self.delete_modifier(tree, tree.right)\n",
    "\n",
    "    def delete_right_modifier(self, tree):\n",
    "        #print(\"Delet: \", tree.right.val)\n",
    "        self.delete_modifier(tree, tree.left)\n",
    "\n",
    "    def rollback(self, tree, backup):\n",
    "        tree.val = backup.val\n",
    "        tree.left = deepcopy(backup.left)\n",
    "        tree.right = deepcopy(backup.right)\n",
    "        tree.mark = backup.mark\n",
    "        tree.pos = backup.pos\n",
    "        tree.id = backup.id\n",
    "        tree.is_tree = backup.is_tree\n",
    "        tree.is_root = backup.is_root\n",
    "\n",
    "    def symmetric_generate(self, tree):\n",
    "        self.right_modifier_generate(tree)\n",
    "        self.left_modifier_generate(tree)\n",
    "        #self.delete_cc(tree)\n",
    "\n",
    "    def right_modifier_generate(self, tree):\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "        backup = deepcopy(tree)\n",
    "\n",
    "        self.delete_right_modifier(tree)\n",
    "        self.save_tree()\n",
    "        self.rollback(tree, backup)    \n",
    "        \n",
    "        self.generate(tree.left)\n",
    "        self.generate(tree.right)\n",
    "\n",
    "    def left_modifier_generate(self, tree):\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "        backup = deepcopy(tree)\n",
    "\n",
    "        self.delete_left_modifier(tree)\n",
    "        self.save_tree()\n",
    "        self.rollback(tree, backup)   \n",
    "\n",
    "        self.generate(tree.left)\n",
    "        self.generate(tree.right)\n",
    "    \n",
    "    def return_last_leaf(self, tree):\n",
    "        max_id = 0\n",
    "        max_id_l = 0\n",
    "        max_id_r = 0\n",
    "\n",
    "        if tree.id != None:\n",
    "            max_id = int(tree.id)\n",
    "    \n",
    "        if tree.left.is_tree:\n",
    "            max_id_l = self.return_last_leaf(tree.left)\n",
    "        else:\n",
    "            max_id_l = tree.left.id\n",
    "\n",
    "        if tree.right.is_tree:\n",
    "            max_id_r = self.return_last_leaf(tree.right)\n",
    "        else:\n",
    "            max_id_r = tree.right.id\n",
    "\n",
    "        return max(max_id, max(max_id_l, max_id_r))\n",
    "\n",
    "    def return_first_leaf(self, tree):\n",
    "        min_id = 100\n",
    "        min_id_l = 100\n",
    "        min_id_r = 100\n",
    "\n",
    "        if tree.id != None:\n",
    "            min_id = int(tree.id)\n",
    "    \n",
    "        if tree.left.is_tree:\n",
    "            min_id_l = self.return_last_leaf(tree.left)\n",
    "        else:\n",
    "            min_id_l = tree.left.id\n",
    "\n",
    "        if tree.right.is_tree:\n",
    "            min_id_r = self.return_last_leaf(tree.right)\n",
    "        else:\n",
    "            min_id_r = tree.right.id\n",
    "\n",
    "        return min(min_id, min(min_id_l, min_id_r))\n",
    "\n",
    "    def add_modifier_sent(self, tree, modifier, direct=0): \n",
    "        sentence = deepcopy(self.sentence)\n",
    "        if direct == 0:\n",
    "            last_leaf = self.return_first_leaf(tree)\n",
    "            sentence.insert(last_leaf-1, modifier)\n",
    "        elif direct == 1:\n",
    "            last_leaf = self.return_last_leaf(tree)\n",
    "            sentence.insert(last_leaf, modifier)        \n",
    "\n",
    "        self.remove_adjcent_duplicate(sentence)\n",
    "        sentence = ' '.join(sentence)\n",
    "        sentence = sentence.replace(\"-\", \" \")\n",
    "        sentence = sentence.replace(\" 's\", \"'s\")\n",
    "\n",
    "        if abs(len(sentence) - len(self.hypothesis)) < 15:\n",
    "            re.sub(r'((\\b\\w+\\b.{1,2}\\w+\\b)+).+\\1', r'\\1', sentence, flags = re.I)\n",
    "            sentence = sentence.strip() \n",
    "            \n",
    "            if sentence.lower() == self.hypothesis.lower():\n",
    "                self.stop_critarion = True\n",
    "                self.sent_log.append((sentence, 1.0))\n",
    "                return\n",
    "                \n",
    "            similarity = inference_sts([sentence], [self.hypothesis])\n",
    "            if similarity > 0.90:\n",
    "                self.sent_log.append((sentence, similarity))\n",
    "            if similarity > 0.97:\n",
    "                self.sent_log.append((sentence, similarity))\n",
    "                self.stop_critarion = True\n",
    "\n",
    "    def add_modifier_lexical(self, tree, modifier, head, word_id, direct=0):\n",
    "        if direct == 0:\n",
    "            generated = ' '. join([modifier, head])\n",
    "        else:\n",
    "            generated = ' '. join([head, modifier])\n",
    "        \n",
    "        sentence = deepcopy(self.sentence)\n",
    "        diff = 0\n",
    "        if word_id > len(sentence):\n",
    "            diff = word_id - len(sentence)\n",
    "\n",
    "        goal = word_id-1-diff\n",
    "        sentence[goal] = \"DEL\"\n",
    "        sentence[goal:goal] = generated.split(' ')\n",
    "\n",
    "        if abs(len(sentence) - len(self.hypothesis.split(' '))) < 7:\n",
    "            self.remove_adjcent_duplicate(sentence)\n",
    "            sentence = ' '.join(sentence)\n",
    "            sentence = sentence.replace(\"DEL \", \"\")\n",
    "            sentence = sentence.replace(\"DEL\", \"\")\n",
    "            sentence = sentence.replace(\"-\", \" \")\n",
    "            sentence = sentence.replace(\" 's\", \"'s\")\n",
    "            re.sub(r'((\\b\\w+\\b.{1,2}\\w+\\b)+).+\\1', r'\\1', sentence, flags = re.I)\n",
    "            sentence = sentence.strip()\n",
    "\n",
    "            if sentence.lower() == self.hypothesis.lower():\n",
    "                self.stop_critarion = True\n",
    "                self.sent_log.append((sentence, 1.0))\n",
    "                return\n",
    "            \n",
    "            similarity = inference_sts([sentence], [self.hypothesis])\n",
    "            if similarity > 0.9:\n",
    "                self.sent_log.append((sentence, similarity))\n",
    "            if similarity > 0.97:\n",
    "                self.sent_log.append((sentence, similarity))\n",
    "                self.stop_critarion = True\n",
    "\n",
    "    def generate_default(self, tree):\n",
    "        VP_rel = {\n",
    "            \"aux\":1, \n",
    "            \"obj\":1, \n",
    "            \"obl\":1, \n",
    "            \"xcomp\":1, \n",
    "            \"ccomp\":1,\n",
    "            \"aux:pass\":1, \n",
    "            \"obl:tmod\":1, \n",
    "            \"obl:npmod\":1\n",
    "        }\n",
    "\n",
    "        VP_mod = {\n",
    "            \"advcl\":1, \n",
    "            \"xcomp\":1, \n",
    "            \"ccomp\":1,\n",
    "            \"obj\":1, \n",
    "            \"advmod\":1, \n",
    "            \"obl\":1, \n",
    "            \"obl:tmod\":1,\n",
    "            \"obl:nmod\":1, \n",
    "            \"parataxis\":1, \n",
    "            \"conj\":1\n",
    "        }\n",
    "\n",
    "        NP_rel = {\n",
    "            \"amod\":1,\n",
    "            \"compound\":1,\n",
    "            \"det\":1,\n",
    "            \"mark\":1,\n",
    "            \"nmod:poss\":1,\n",
    "            \"flat\":1,\n",
    "            \"acl:relcl\":1,\n",
    "            \"acl\":1,\n",
    "            \"nmod\":1\n",
    "        }\n",
    "\n",
    "        NP_mod = {\n",
    "            \"amod\":1,\n",
    "            \"compound\":1,\n",
    "            \"det\":1,\n",
    "            \"mark\":1,\n",
    "            \"nmod:poss\":1,\n",
    "            \"flat\":1,\n",
    "        }\n",
    "\n",
    "        if tree.pos is not None:\n",
    "            if (\"NN\" in tree.pos or \"JJ\" in tree.pos) and tree.mark == \"-\":\n",
    "                for rel in [\"amod\", \"compound\", \"det\", \"mark\", \"nmod:poss\", \"flat\", \"conj\", \"nummod\"]:\n",
    "                    if rel in self.kb:\n",
    "                        for phrase in self.kb[rel]:\n",
    "                            if phrase['head'] == tree.val:\n",
    "                                self.add_modifier_lexical(tree, phrase['mod'], tree.val, tree.id)\n",
    "                for rel in [\"amod\", \"acl:relcl\", \"compound\", \"acl\", \"nmod\"]:\n",
    "                    if rel in self.kb:\n",
    "                        for phrase in self.kb[rel]:\n",
    "                            if phrase['head'] == tree.val:\n",
    "                                self.add_modifier_lexical(tree, phrase['mod'], tree.val, tree.id, 1)\n",
    "                \n",
    "            elif \"VB\" in tree.pos and tree.mark == \"-\":\n",
    "                for rel in [\"advmod\"]:\n",
    "                    if rel in self.kb:\n",
    "                        for phrase in self.kb[rel]:\n",
    "                            self.add_modifier_lexical(tree, phrase['mod'], tree.val, tree.id)\n",
    "                            self.add_modifier_lexical(tree, phrase['mod'], tree.val, tree.id, 1)\n",
    "\n",
    "        elif VP_rel.get(tree.val, 0) and tree.mark == \"-\":\n",
    "            for rel in VP_mod:\n",
    "                if rel in self.kb:\n",
    "                    for phrase in self.kb[rel]:\n",
    "                        self.add_modifier_sent(tree, phrase['mod'], direct=1)\n",
    "\n",
    "        elif NP_rel.get(tree.val, 0) and tree.mark == \"-\":\n",
    "            for rel in NP_mod:\n",
    "                if rel in self.kb:\n",
    "                    for phrase in self.kb[rel]:\n",
    "                        self.add_modifier_sent(tree, phrase['mod'], direct=0)\n",
    "        \n",
    "        if VP_rel.get(tree.val, 0) and tree.right.val == \"watching\":\n",
    "            self.save_tree(tree=tree.left)\n",
    "        if tree.is_tree:\n",
    "            self.generate(tree.left)\n",
    "            self.generate(tree.right)  \n",
    "\n",
    "    def save_tree(self, tree=None):\n",
    "        if tree is None:\n",
    "            leaves = self.deptree.sorted_leaves().popkeys()\n",
    "            tree_copy = self.deptree.copy()\n",
    "        else:\n",
    "            leaves = tree.sorted_leaves().popkeys()\n",
    "            tree_copy = tree.copy()\n",
    "        \n",
    "        sentence = ' '.join([x[0] for x in leaves])\n",
    "        sentence = sentence.replace(\"-\", \" \")\n",
    "        if sentence.lower() == self.hypothesis.lower():\n",
    "            self.tree_log = []\n",
    "            self.stop_critarion = True\n",
    "            self.tree_log.append((tree_copy, sentence, 1.0))\n",
    "            return\n",
    "        \n",
    "        similarity = inference_sts([sentence], [self.hypothesis])\n",
    "        #print(sentence, similarity)\n",
    "       \n",
    "        self.tree_log.append((tree_copy, sentence, similarity))\n",
    "        if similarity > 0.97:\n",
    "            self.tree_log = []\n",
    "            self.tree_log.append((tree_copy, sentence, similarity))\n",
    "            self.stop_critarion = True\n",
    "    \n",
    "    def remove_adjcent_duplicate(self, string):\n",
    "        to_remove = -1\n",
    "        for i in range(len(string)-1):\n",
    "            if string[i] == string[i+1]:\n",
    "                to_remove = i\n",
    "        if to_remove > -1:\n",
    "            del string[to_remove]\n",
    "\n",
    "    def search_dependency(self, deprel, tree):\n",
    "        if tree.val == deprel:\n",
    "            return True\n",
    "        else:\n",
    "            right = tree.right\n",
    "            left = tree.left\n",
    "\n",
    "            left_found = False\n",
    "            right_found = False\n",
    "\n",
    "            if right is not None:\n",
    "                right_found = self.search_dependency(deprel, right)\n",
    "\n",
    "            if left is not None:\n",
    "                left_found = self.search_dependency(deprel, left)\n",
    "\n",
    "            return left_found or right_found\n",
    "    \n",
    "    def Diff(self, li1, li2):\n",
    "        return (list(list(set(li1)-set(li2)) + list(set(li2)-set(li1))))    \n",
    "    \n",
    "    def preprocess(self, sentence):\n",
    "        preprocessed = sentence.replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\")\n",
    "        preprocessed = preprocessed.replace(\"can't\", \"can not\")\n",
    "        preprocessed = preprocessed.replace(\"couldn't\", \"could not\")\n",
    "        preprocessed = preprocessed.replace(\"don't\", \"do not\")\n",
    "        preprocessed = preprocessed.replace(\"doesn't\", \"does not\")\n",
    "        preprocessed = preprocessed.replace(\"isn't\", \"is not\")\n",
    "        preprocessed = preprocessed.replace(\"won't\", \"will not\")\n",
    "        preprocessed = preprocessed.replace(\"wasn't\", \"was not\")\n",
    "        preprocessed = preprocessed.replace(\"weren't\", \"were not\")\n",
    "        preprocessed = preprocessed.replace(\"didn't\", \"did not\")\n",
    "        preprocessed = preprocessed.replace(\"aren't\", \"are not\")\n",
    "        preprocessed = preprocessed.replace(\"it's\", \"it is\")\n",
    "        preprocessed = preprocessed.replace(\"wouldn't\", \"would not\")\n",
    "        preprocessed = preprocessed.replace(\"There's\", \"There is\")\n",
    "        return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifier_relation = {\n",
    "    \"NN\": [\"amod\", \"nmod\", \"acl:relcl\", \"fixed\", \"compound\", \"det\", \"nmod:poss\", \"conj\", \"nummod\"],\n",
    "    \"VB\": [\"advmod\", \"acl\", \"obl\", \"xcomp\", \"advcl\", \"obl:tmod\", \"parataxis\", \"obj\",\"ccomp\"]\n",
    "}\n",
    "\n",
    "def down_right(tree):\n",
    "    if(tree.right == None):\n",
    "        return tree\n",
    "    return down_right(tree.right)\n",
    "\n",
    "def down_left(tree):\n",
    "    if(tree.left == None):\n",
    "        return tree\n",
    "    return down_left(tree.left)\n",
    "\n",
    "def collect_modifiers(tree, sent_set, mod_type=\"NN\"):\n",
    "    leaves = []\n",
    "    if tree.is_tree:\n",
    "        if tree.val in [\"mark\", \"case\", \"compound\", \"flat\", \"nmod\"]:\n",
    "            leaves.append(\n",
    "                (list(tree.right.sorted_leaves().popkeys()),\n",
    "                down_right(tree.left).val)\n",
    "            )\n",
    "        if tree.val in modifier_relation[mod_type]:\n",
    "            leaves.append(\n",
    "                (list(tree.left.sorted_leaves().popkeys()),\n",
    "                down_right(tree.right).val)\n",
    "            )\n",
    "\n",
    "        for leave in leaves:\n",
    "            if len(leave) > 0 and len(leave) < 10:\n",
    "                head = leave[1]\n",
    "                modifier = ' '.join([x[0] for x in leave[0]])\n",
    "                if tree.val in sent_set:\n",
    "                    sent_set[tree.val].append({'head': head,'mod': modifier})\n",
    "                else:\n",
    "                    sent_set[tree.val] = [{'head': head,'mod': modifier}]\n",
    "        \n",
    "        collect_modifiers(tree.left, sent_set, mod_type)\n",
    "        collect_modifiers(tree.right, sent_set, mod_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================\n",
      "\n",
      "Init Premise: A group of boys are playing with a ball, in front of a large door made of wood\n",
      "\n",
      "Hypothesis: The children are playing in front of a door, which is very large\n",
      "\n",
      "{   'acl:relcl': [{'head': 'front', 'mod': 'which is very large'}],\n",
      "    'advmod': [{'head': 'large', 'mod': 'very'}],\n",
      "    'case': [   {'head': 'in', 'mod': 'front of a door which is very large'},\n",
      "                {'head': 'of', 'mod': 'a door'},\n",
      "                {'head': 'in', 'mod': 'front of a door which is very large'},\n",
      "                {'head': 'of', 'mod': 'a door'}],\n",
      "    'det': [{'head': 'children', 'mod': 'The'}, {'head': 'door', 'mod': 'a'}],\n",
      "    'nmod': [   {'head': 'door', 'mod': 'front which is very large'},\n",
      "                {'head': 'front', 'mod': 'of a door'},\n",
      "                {'head': 'door', 'mod': 'front which is very large'}],\n",
      "    'obl': [   {   'head': 'playing',\n",
      "                   'mod': 'in front of a door which is very large'}]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delet:  case\n",
      "Delet:  A\n",
      "Delet:  case\n",
      "Delet:  a\n",
      "Delet:  case\n",
      "Delet:  case\n",
      "Delet:  a\n",
      "Delet:  obl\n",
      "Delet:  case\n",
      "Delet:  large\n",
      "('boys are playing with a ball in front of a large door made of wood', tensor(0.6101))\n",
      "('group are playing with a ball in front of a large door made of wood', tensor(0.5209))\n",
      "('group are playing with a ball in front of a large door made of wood', tensor(0.5209))\n",
      "('group of boys are playing with a ball in front of a large door made of wood', tensor(0.5942))\n",
      "('group of boys are playing with a ball in front of a large door made of wood', tensor(0.5942))\n",
      "('A group of boys are playing in front of a large door made of wood', tensor(0.7181))\n",
      "('A group of boys are playing in front of a large door made of wood', tensor(0.7181))\n",
      "('A group of boys are playing with ball in front of a large door made of wood', tensor(0.5997))\n",
      "('A group of boys are playing with ball in front of a large door made of wood', tensor(0.5997))\n",
      "('A group of boys are playing with a ball', tensor(0.4197))\n",
      "('A group of boys are playing with a ball', tensor(0.4197))\n",
      "('A group of boys are playing with a ball in front', tensor(0.4305))\n",
      "('A group of boys are playing with a ball in front', tensor(0.4305))\n",
      "('A group of boys are playing with a ball in front of large door made of wood', tensor(0.5958))\n",
      "('A group of boys are playing with a ball in front of large door made of wood', tensor(0.5958))\n",
      "('A group of boys are playing with a ball in front of a large door', tensor(0.6235))\n",
      "('A group of boys are playing with a ball in front of a large door', tensor(0.6235))\n",
      "('A group of boys are playing with a ball in front of a large door made', tensor(0.6233))\n",
      "('A group of boys are playing with a ball in front of a large door made', tensor(0.6233))\n",
      "('A group of boys are playing with a ball in front of a door made of wood', tensor(0.5432))\n",
      "('A group of boys are playing with a ball in front of a door made of wood', tensor(0.5432))\n",
      "\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "up = [\"A group of boys are playing with a ball, in front of a large door made of wood\"]\n",
    "up_h = [ entail_hypo[71]]\n",
    "\n",
    "annotations = []\n",
    "phrasalGenerator = PhrasalGenerator()\n",
    "pipeline = PolarizationPipeline(verbose=0)\n",
    "for i in range(len(up)):\n",
    "    premise = up[i]\n",
    "    hypothesis = up_h[i]\n",
    "    premise = phrasalGenerator.preprocess(premise)\n",
    "    hypothesis = phrasalGenerator.preprocess(hypothesis)\n",
    "\n",
    "    tokenized = tokenizer(premise).sentences[0].words\n",
    "    tokens = [tok.text for tok in tokenized]\n",
    "\n",
    "    print(\"\\n====================================\")\n",
    "    print(\"\\nInit Premise: \" + premise)\n",
    "    print(\"\\nHypothesis: \" + hypothesis)\n",
    "\n",
    "    h_parsed, replaced = dependency_parse(hypothesis, parser=\"stanza\")\n",
    "    h_tree, _ = pipeline.run_binarization(h_parsed, hypothesis, {})\n",
    "    pipeline.modify_replacement(h_tree, replaced)\n",
    "    phrases = {} \n",
    "    collect_modifiers(h_tree, phrases, mod_type=\"NN\")\n",
    "    collect_modifiers(h_tree, phrases, mod_type=\"VB\")\n",
    "    annotation = pipeline.single_polarization(premise)\n",
    "    \n",
    "    phrasalGenerator.kb = phrases\n",
    "    phrasalGenerator.hypothesis = hypothesis.replace(',', '')\n",
    "    pp.pprint(phrasalGenerator.kb)\n",
    "    \n",
    "    polarized = pipeline.postprocess(annotation['polarized_tree'], {})\n",
    "    btreeViz = Tree.fromstring(polarized.replace('[', '(').replace(']', ')'))\n",
    "    jupyter_draw_nltk_tree(btreeViz) \n",
    "\n",
    "    polarized = pipeline.postprocess(h_tree, {})\n",
    "    btreeViz = Tree.fromstring(polarized.replace('[', '(').replace(']', ')'))\n",
    "    jupyter_draw_nltk_tree(btreeViz)\n",
    "    \n",
    "    phrasalGenerator.deptree_generate(\n",
    "        annotation['polarized_tree'], \n",
    "        annotation['annotated'], tokens)\n",
    "\n",
    "    for gen_tree in phrasalGenerator.tree_log:\n",
    "        #leaves = gen_tree[0].sorted_leaves().popkeys()\n",
    "        #sentence = ' '.join([x[0] for x in leaves])\n",
    "        print((gen_tree[1], gen_tree[2]))\n",
    "\n",
    "    print(*phrasalGenerator.sent_log, sep=\"\\n\")\n",
    "    print(phrasalGenerator.stop_critarion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_sts(\"A yellow dog is sleeping\", \"A dog is sleeping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Lexical Monotonicity Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "import wordnet\n",
    "from wordnet import get_word_sets\n",
    "import importlib\n",
    "importlib.reload(wordnet)\n",
    "\n",
    "class LexicalGenerator:\n",
    "    def __init__(self):\n",
    "        self.deptree = None\n",
    "        self.hypothesis = \"\"\n",
    "        self.tree_log = []\n",
    "        self.sentence_base = set()\n",
    "        self.anti_tree_log = []\n",
    "        self.polar_log = []\n",
    "        self.replacement_log = []\n",
    "        self.stop_critarion = False\n",
    "        self.key_tokens = [\n",
    "            'NN','NNS','NNP','NNPS','VBD',\n",
    "            'VBG','VBN','VBZ','VB',\"JJ\"]\n",
    "\n",
    "        self.propers = [\"someone\", \"something\", \"somewhere\"]\n",
    "        self.memory = {}\n",
    "\n",
    "        self.quantifiers = {}\n",
    "        self.lemmatizer = WordNetLemmatizer() \n",
    "        with open('quantifier.json', 'r') as quants:\n",
    "            quantifier_data = json.load(quants)\n",
    "            for quantifier in quantifier_data:\n",
    "                self.quantifiers[quantifier['word']] = quantifier\n",
    "\n",
    "    def deptree_generate(self, tree):\n",
    "        self.replacement_log = []\n",
    "        self.sentence_base = set()\n",
    "        self.tree_log = []\n",
    "        self.anti_tree_log = []\n",
    "        self.stop_critarion = False\n",
    "        self.deptree = tree.copy()\n",
    "        self.generate(self.deptree)\n",
    "\n",
    "    def generate(self, tree):\n",
    "        if tree is None or self.stop_critarion:\n",
    "            return\n",
    "        if tree.pos is not None and not tree.val in self.hypothesis: \n",
    "            backup = copy(tree.val)\n",
    "            if tree.pos == \"NNP\" and tree.mark == \"+\":\n",
    "                for word in self.propers:\n",
    "                    if word in self.hypothesis_tokens:\n",
    "                        tree.val = word\n",
    "                        self.save_tree()\n",
    "                        self.replacement_log.append(\n",
    "                            \"{} => {}\".format(backup, word))\n",
    "                        tree.val = backup\n",
    "\n",
    "            if tree.pos in self.key_tokens:\n",
    "                if tree.val in self.memory:\n",
    "                    hyper, hypo, syn, ant = self.memory[tree.val]\n",
    "                else:\n",
    "                    hyper, hypo, syn, ant = get_word_sets(\n",
    "                        self.lemmatizer.lemmatize(tree.val))\n",
    "                    self.memory[tree.val] = (hyper, hypo, syn, ant)\n",
    "                print('s', syn)\n",
    "                #print(tree.val, tree.mark, hyper)\n",
    "\n",
    "                for lex in syn.keys():\n",
    "                    lex_ls = lex.split(' ')\n",
    "                    for key in lex_ls:\n",
    "                        #print(key)\n",
    "                        #print(self.hypothesis_tokens)\n",
    "                        if not ign_words.get(key,0):\n",
    "                            for tok in self.hypothesis_tokens:\n",
    "                                if tok in key or key in tok:\n",
    "                                    tree.val = tok\n",
    "                                    self.save_tree()\n",
    "                                    self.replacement_log.append(\n",
    "                                        \"{} => {}\".format(backup, tok))\n",
    "                tree.val = backup\n",
    "\n",
    "                for lex in ant.keys():\n",
    "                    lex_ls = lex.split(' ')\n",
    "                    for key in lex_ls:\n",
    "                        #print(key)\n",
    "                        #print(self.hypothesis_tokens)\n",
    "                        if not ign_words.get(key,0):\n",
    "                            for tok in self.hypothesis_tokens:\n",
    "                                if tok in key or key in tok:\n",
    "                                    tree.val = tok\n",
    "                                    self.save_tree(entail=False)\n",
    "                                    self.replacement_log.append(\n",
    "                                        \"{} => {}\".format(backup, tok))\n",
    "                tree.val = backup\n",
    "\n",
    "                if tree.mark == \"+\":             \n",
    "                    for lex in hyper.keys():\n",
    "                        \n",
    "                        lex_ls = lex.split(' ')\n",
    "                        for key in lex_ls:\n",
    "                            #print(key)\n",
    "                            #print(self.hypothesis_tokens)\n",
    "                            if not ign_words.get(key,0):\n",
    "                                for tok in self.hypothesis_tokens:\n",
    "                                    if tok in key or key in tok:\n",
    "                                        print(tok, \" \", key)\n",
    "                                        tree.val = tok\n",
    "                                        self.save_tree()\n",
    "                                        self.replacement_log.append(\n",
    "                                            \"{} => {}\".format(backup, tok))\n",
    "                    tree.val = backup\n",
    "\n",
    "                if tree.mark == \"-\":\n",
    "                    for lex in hypo.keys():\n",
    "                        lex_ls = lex.split(' ')\n",
    "                        for key in lex_ls:\n",
    "                            #print(key)\n",
    "                            #print(self.hypothesis_tokens)\n",
    "                            if not ign_words.get(key,0):\n",
    "                                for tok in self.hypothesis_tokens:\n",
    "                                    if tok in key or key in tok:\n",
    "                                        tree.val = tok\n",
    "                                        self.save_tree()\n",
    "                                        self.replacement_log.append(\n",
    "                                            \"{} => {}\".format(backup, tok))\n",
    "                    tree.val = backup\n",
    "            \n",
    "        elif tree.val == \"det\":\n",
    "            backup = tree.left.val\n",
    "            backup_mark = tree.right.mark\n",
    "            kb = self.quantifiers.get(tree.left.val.lower(), {})\n",
    "            if len(kb) > 0:\n",
    "\n",
    "                for word in kb[\"=\"]:\n",
    "                    tree.left.val = word\n",
    "                    detType = det_type(tree.left.val)\n",
    "                    if detType is None:\n",
    "                        detType = \"det:exist\"\n",
    "                    tree.left.mark = det_mark[detType]\n",
    "                    self.save_tree()\n",
    "                    self.replacement_log.append(\n",
    "                        \"{} => {}\".format(backup, word))\n",
    "                tree.left.val = backup\n",
    "                tree.left.mark = backup_mark\n",
    "\n",
    "                if tree.left.mark == \"+\":\n",
    "                    for word in kb[\"<\"]:\n",
    "                        if word in self.hypothesis:\n",
    "                            tree.left.val = word\n",
    "                            detType = det_type(tree.left.val)\n",
    "                            if detType is None:\n",
    "                                detType = \"det:exist\"\n",
    "                            tree.left.mark = det_mark[detType]\n",
    "                            self.save_tree()\n",
    "                            self.replacement_log.append(\n",
    "                                \"{} => {}\".format(backup, word))\n",
    "                    tree.left.val = backup\n",
    "                    tree.left.mark = backup_mark\n",
    "                \n",
    "                if tree.left.mark == \"-\":\n",
    "                    for word in kb[\">\"]:\n",
    "                        if word in self.hypothesis:\n",
    "                            tree.left.val = word\n",
    "                            if detType is None:\n",
    "                                detType = \"det:exist\"\n",
    "                            tree.left.mark = det_mark[detType]\n",
    "                            self.save_tree()\n",
    "                            self.replacement_log.append(\n",
    "                                \"{} => {}\".format(backup, word))\n",
    "                    tree.left.val = backup\n",
    "                    tree.left.mark = backup_mark\n",
    "        \n",
    "        if tree.left != \"N\":\n",
    "            self.generate(tree.left)\n",
    "        if tree.right != \"N\":\n",
    "            self.generate(tree.right)\n",
    "\n",
    "    def save_tree(self, entail=True):\n",
    "        leaves = self.deptree.sorted_leaves().popkeys()\n",
    "        tree_copy = self.deptree.copy()\n",
    "     \n",
    "        sentence = ' '.join([x[0] for x in leaves])\n",
    "        \n",
    "        if not sentence in self.sentence_base:\n",
    "            self.sentence_base.add(sentence)\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "        if sentence.lower() == self.hypothesis.lower():\n",
    "            self.stop_critarion = True\n",
    "            if entail:\n",
    "                self.tree_log = []\n",
    "                self.tree_log.append((tree_copy, sentence, 1.0))\n",
    "            else:\n",
    "                self.anti_tree_log = []\n",
    "                self.anti_tree_log.append((tree_copy, sentence, 1.0))\n",
    "            return\n",
    "        \n",
    "        similarity = inference_sts([sentence], [self.hypothesis])\n",
    "        print(sentence, similarity)\n",
    "        if entail:\n",
    "            self.tree_log.append((tree_copy, sentence, similarity))\n",
    "        else:\n",
    "            self.anti_tree_log.append((tree_copy, sentence, similarity))\n",
    "        if similarity > 0.97:\n",
    "            self.stop_critarion = True\n",
    "            if entail:\n",
    "                self.tree_log = []\n",
    "                self.tree_log.append((tree_copy, sentence, similarity))\n",
    "            else:\n",
    "                self.anti_tree_log = []\n",
    "                self.anti_tree_log.append((tree_copy, sentence, similarity))\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some man is sitting comfortably at a table tensor(0.8207)\n",
      "an man is sitting comfortably at a table tensor(0.8228)\n",
      "one man is sitting comfortably at a table tensor(0.7950)\n",
      "s {'man': 1, 'adult male': 1, 'serviceman': 1, 'military man': 1, 'military personnel': 1, 'homo': 1, 'human being': 1, 'human': 1, 'valet': 1, 'valet de chambre': 1, 'gentleman': 1, \"gentleman's gentleman\": 1, 'Man': 1, 'Isle of Man': 1, 'piece': 1, 'world': 1, 'human race': 1, 'humanity': 1, 'humankind': 1, 'human beings': 1, 'humans': 1, 'mankind': 1}\n",
      "A person is sitting comfortably at a table tensor(0.9982)\n",
      "person   person\n",
      "person   person\n",
      "('A person is sitting comfortably at a table', tensor(0.9982))\n",
      "['A => some', 'A => an', 'A => one', 'man => person', 'man => person', 'man => person']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "sentences = [\"A man is sitting comfortably at a table\"]\n",
    "hypotheses = [\"A person is sitting comfortably at the table\"]\n",
    "\n",
    "pipeline = PolarizationPipeline(verbose=0)\n",
    "lexicalGenerator = LexicalGenerator()\n",
    "phrasalGenerator = PhrasalGenerator()\n",
    "\n",
    "for premise, hypothesis in zip(sentences, hypotheses):\n",
    "    premise = phrasalGenerator.preprocess(premise)\n",
    "    hypothesis = phrasalGenerator.preprocess(hypothesis)\n",
    "\n",
    "    h_parsed, replaced = dependency_parse(hypothesis, parser=\"stanza\")\n",
    "    #h_tree, _ = pipeline.run_binarization(h_parsed, hypothesis, {})\n",
    "    #pipeline.modify_replacement(h_tree, replaced)\n",
    "    key_tokens = set()\n",
    "    for word in h_parsed[2]:\n",
    "        pos = h_parsed[2][word][1]\n",
    "        if 'NN' in pos or 'JJ' in pos or 'VB' in pos:\n",
    "            if(not ign_words.get(h_parsed[2][word][0],0)):\n",
    "                key_tokens.add(h_parsed[2][word][0])\n",
    "\n",
    "    #print(\"\\n====================================\")\n",
    "    #print(\"\\nInit Premise: \" + premise)\n",
    "    #print(\"\\nHypothesis: \" + hypothesis)\n",
    "\n",
    "    #tokenized = tokenizer(hypothesis).sentences[0].words\n",
    "    #tokens = {} \n",
    "    #lemmatizer = WordNetLemmatizer() \n",
    "    #for tok in tokenized:\n",
    "    #    tokens[lemmatizer.lemmatize(tok.text)] = tok.text\n",
    "    lexicalGenerator.hypothesis_tokens = key_tokens\n",
    "\n",
    "    annotation = pipeline.single_polarization(premise)\n",
    "    polarized = pipeline.postprocess(annotation['polarized_tree'], {})\n",
    "    btreeViz = Tree.fromstring(polarized.replace('[', '(').replace(']', ')'))\n",
    "    jupyter_draw_nltk_tree(btreeViz) \n",
    "\n",
    "    lexicalGenerator.hypothesis = hypothesis.replace(',', '')\n",
    "    lexicalGenerator.deptree_generate(annotation['polarized_tree'])\n",
    "    \n",
    "    for gen_tree in lexicalGenerator.tree_log:\n",
    "        print((gen_tree[1], gen_tree[2]))\n",
    "    for anti_tree in lexicalGenerator.anti_tree_log:\n",
    "        print((anti_tree[1], anti_tree[2]))\n",
    "\n",
    "    print(lexicalGenerator.replacement_log)\n",
    "    print(lexicalGenerator.stop_critarion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458\n",
      "1738\n"
     ]
    }
   ],
   "source": [
    "MED_upward = []\n",
    "MED_upward_hypo = []\n",
    "MED_downward = []\n",
    "MED_downward_hypo = []\n",
    "\n",
    "with open(\"../data/MED/upward.txt\") as upward_med:\n",
    "    lines = upward_med.readlines()\n",
    "    for i in range(len(lines) // 4):\n",
    "        MED_upward.append(lines[i*4+1])\n",
    "        MED_upward_hypo.append(lines[i*4+2])\n",
    "\n",
    "with open(\"../data/MED/downward.txt\") as donward_med:\n",
    "    lines = donward_med.readlines()\n",
    "    for i in range(len(lines) // 4):\n",
    "        MED_downward.append(lines[i*4+1])\n",
    "        MED_downward_hypo.append(lines[i*4+2])\n",
    "\n",
    "print(len(MED_upward))\n",
    "print(len(MED_downward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Syntactic Variational Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Chunker import Chunker\n",
    "\n",
    "class SyntacticVariator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chunker = Chunker()\n",
    "        self.paraphraseTokenizer = paraphraseTokenizer\n",
    "        self.paraphraseModel = paraphraseModel\n",
    "        self.replacement_log = []\n",
    "\n",
    "    def chunking(self, tree):\n",
    "        return self.chunker.get_chunks_byDepTree(tree)\n",
    "\n",
    "    def build_pairs(self, chunks1, chunks2):\n",
    "        chunk_pairs = []\n",
    "        for chunk1 in chunks1:\n",
    "            for chunk2 in chunks2:\n",
    "                if len(set(chunk1.split(' ')).intersection(chunk2.split(' '))) > 0:\n",
    "                     chunk_pairs.append((chunk1, chunk2))\n",
    "\n",
    "        return chunk_pairs\n",
    "\n",
    "    def inference_mrpc(self, seq1, seq2):\n",
    "        paraphrase = paraphraseTokenizer.encode_plus(\n",
    "            seq1, seq2, return_tensors=\"pt\")\n",
    "        #paraphrase.to('cuda')\n",
    "        logits = paraphraseModel(**paraphrase)[0]\n",
    "        paraphrase_results = torch.softmax(logits, dim=1).tolist()[0]\n",
    "        return paraphrase_results[1]\n",
    "\n",
    "    def phrase_alignment(self, chunk_pairs):\n",
    "        alignments = []\n",
    "        for pair in chunk_pairs:\n",
    "            score = self.inference_mrpc(pair[0], pair[1])\n",
    "            #print(pair, score)\n",
    "            if score > 0.80:\n",
    "                alignments.append(pair)\n",
    "\n",
    "        return alignments\n",
    "\n",
    "    def variate(self, P, H, p_tree, h_tree, sent=False):\n",
    "        self.replacement_log = []\n",
    "        p_chunks = self.chunking(p_tree)\n",
    "        h_chunks = self.chunking(h_tree)\n",
    "\n",
    "     \n",
    "\n",
    "        if sent:\n",
    "            p_chunks.append(P)\n",
    "            h_chunks.append(H)\n",
    "\n",
    "        chunk_pairs = self.build_pairs(p_chunks, h_chunks)\n",
    "        alignments = self.phrase_alignment(chunk_pairs)\n",
    "\n",
    "        #print(*p_chunks, sep=\"\\n\")\n",
    "        #print(*h_chunks, sep=\"\\n\")\n",
    "\n",
    "        variates = set()\n",
    "        for align in alignments:\n",
    "            alignList1 = align[1].split(' ')\n",
    "            if(alignList1[0] == \"Somebody\"):\n",
    "                alignList2 = align[0].split(' ')\n",
    "                var_sentence = P.replace(' '.join(alignList2[1:]), ' '.join(alignList1[1:]))\n",
    "                self.replacement_log.append(\n",
    "                        \"{} => {}\".format(' '.join(alignList2[1:]), ' '.join(alignList1[1:])))\n",
    "            else:\n",
    "                var_sentence = P.replace(align[0], align[1])\n",
    "                self.replacement_log.append(\n",
    "                        \"{} => {}\".format(align[0], align[1]))\n",
    "            \n",
    "            variates.add(var_sentence)\n",
    "\n",
    "        return variates\n",
    "#ie_pred_p = ie_extractor.predict(P)['verbs']\n",
    "    '''    ie_pred_h = ie_extractor.predict(H)['verbs']\n",
    "\n",
    "        for verb in ie_pred_p:\n",
    "            if \"ARG\" in verb['description']:\n",
    "                p_chunks.append(fix_info(verb['description'])[0].strip())\n",
    "                p_chunks.append(verb['verb'] + ' '+ fix_info(verb['description'])[2].strip())\n",
    "\n",
    "        for verb in ie_pred_h:\n",
    "            if \"ARG\" in verb['description']:\n",
    "                h_chunks.append(fix_info(verb['description'])[0].strip())\n",
    "                h_chunks.append(verb['verb'] + ' '+ fix_info(verb['description'])[2].strip())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'allennlp_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9c3d5e38d3fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mallennlp_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructured_prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mie_extractor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'allennlp_models'"
     ]
    }
   ],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.structured_prediction\n",
    "\n",
    "ie_extractor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_info(desc):\n",
    "    out = desc.replace(\"[ARG0: \", \"\")\n",
    "    out = out.replace(\"[ARG1: \", \"\")\n",
    "    out = out.replace(\"[V: \", \"\")\n",
    "    out = out.replace(\"]\", \",\")\n",
    "    out = out.split(\",\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie_pred = ie_extractor.predict(\"Two men are standing near the water and are holding fishing poles\")['verbs']\n",
    "print(ie_pred)\n",
    "for verb in ie_pred:\n",
    "    if \"ARG\" in verb['description']:\n",
    "        print(fix_info(verb['description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A laughing child is holding a is holding a squirt gun and getting sprayed with water tensor(0.7736)\n",
      "A laughing child is is holding a squirt gun a squirt gun and getting sprayed with water tensor(0.7838)\n",
      "A laughing child is holding a squirt gun and getting sprayed with water tensor(0.7746)\n"
     ]
    }
   ],
   "source": [
    "premise = \"A laughing child is holding a squirt gun and getting sprayed with water\"\n",
    "hypothesis = \"A child is holding a squirt gun\"\n",
    "\n",
    "pipeline = PolarizationPipeline()\n",
    "syntacticVariator = SyntacticVariator()\n",
    "\n",
    "h_parsed, replaced = dependency_parse(hypothesis, parser=\"stanza\")\n",
    "h_tree, _ = pipeline.run_binarization(h_parsed, hypothesis, {})\n",
    "pipeline.modify_replacement(h_tree, replaced)\n",
    "annotation = pipeline.single_polarization(premise)\n",
    "\n",
    "variates = syntacticVariator.variate(premise, hypothesis, annotation['polarized_tree'],  h_tree, sent=False)\n",
    "for v in variates:\n",
    "    similarity = inference_sts([v], [hypothesis])\n",
    "    print(v, similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntacticVariator.inference_mrpc(\"hiking\", \"are walking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3412)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_sts([\"is wearing\"], [\"Somebody is wearing beads that are red\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. A* Inference Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pqdict import pqdict\n",
    "\n",
    "class AStarPlanner:\n",
    "    def __init__(self):    \n",
    "        self.closed = []                  \n",
    "        self.entailments = set()\n",
    "        self.contradictions = set()\n",
    "        self.hypothesis = \"\"\n",
    "        self.h_tree = None\n",
    "\n",
    "        self.pipeline = PolarizationPipeline()\n",
    "        self.phrasalGenerator = PhrasalGenerator()\n",
    "        self.lexicalGenerator = LexicalGenerator()\n",
    "        self.syntacticVariator = SyntacticVariator() \n",
    "\n",
    "    def hypothesis_kb(self):\n",
    "        self.hypothesis = self.phrasalGenerator.preprocess(self.hypothesis).replace('\\n', '')\n",
    "        h_parsed, replaced = dependency_parse(self.hypothesis, parser=\"stanza\")\n",
    "        h_tree, _ = self.pipeline.run_binarization(h_parsed, self.hypothesis, {})\n",
    "        self.pipeline.modify_replacement(h_tree, replaced)\n",
    "        phrases = {} \n",
    "        collect_modifiers(h_tree, phrases, mod_type=\"NN\")\n",
    "        collect_modifiers(h_tree, phrases, mod_type=\"VB\")\n",
    "        self.phrasalGenerator.kb = phrases\n",
    "        key_tokens = set()\n",
    "        for word in h_parsed[2]:\n",
    "            pos = h_parsed[2][word][1]\n",
    "            if 'NN' in pos or 'JJ' in pos or 'VB' in pos:\n",
    "                if(not ign_words.get(h_parsed[2][word][0],0)):\n",
    "                    key_tokens.add(h_parsed[2][word][0])\n",
    "        self.lexicalGenerator.hypothesis_tokens = key_tokens\n",
    "        self.lexicalGenerator.hypothesis = self.hypothesis.replace(',','')\n",
    "        self.h_tree = h_tree\n",
    "        \n",
    "\n",
    "    def generate_premises(self, start):\n",
    "        self.entailments.clear()\n",
    "        self.contradictions.clear()\n",
    "\n",
    "        # Polarization from Udeo2Mono\n",
    "        start = self.phrasalGenerator.preprocess(start)\n",
    "        annotation = self.pipeline.single_polarization(start)\n",
    "\n",
    "        # Monotonicity-based Phrasl Inference\n",
    "        self.phrasalGenerator.hypothesis = self.hypothesis.replace(',', '')\n",
    "\n",
    "        tokenized = tokenizer(start).sentences[0].words\n",
    "        tokens = [tok.text for tok in tokenized]\n",
    "\n",
    "        self.phrasalGenerator.deptree_generate(\n",
    "        annotation['polarized_tree'], \n",
    "        annotation['annotated'], tokens)\n",
    "        print(\"============================\")\n",
    "        \n",
    "        if self.phrasalGenerator.stop_critarion:\n",
    "            return True\n",
    "\n",
    "        for tree in self.phrasalGenerator.tree_log:\n",
    "            self.entailments.add((tree[1], tree[2]))\n",
    "        self.entailments |= set(self.phrasalGenerator.sent_log)\n",
    "\n",
    "        print(*self.entailments, sep=\"\\n\")\n",
    "        \n",
    "\n",
    "        # Syntactic Vriation\n",
    "        # Sequence Chunking and Chunk Alignment from roBERTa\n",
    "        sent_level = False\n",
    "        if self.current_optimal > 0.93 :\n",
    "            sent_level = True\n",
    "        variates = self.syntacticVariator.variate(\n",
    "            start, \n",
    "            self.hypothesis, \n",
    "            annotation['polarized_tree'], \n",
    "            self.h_tree, sent_level)\n",
    "        for v in variates:\n",
    "            similarity = inference_sts([v], [self.hypothesis])\n",
    "            print(similarity, v)\n",
    "            if similarity > 0.98:\n",
    "                return True\n",
    "            elif similarity > 0.9:\n",
    "                self.entailments.add((v, similarity))\n",
    "        print(self.syntacticVariator.replacement_log)\n",
    "\n",
    "        #TODO: Monotonicity-based Lexical Inference\n",
    "        print(\"Generate Lexical Variation\")\n",
    "        #lemmatizer = WordNetLemmatizer() \n",
    "        #tokens_dict = {}\n",
    "        #for tok in tokenized:\n",
    "        #    tokens_dict[lemmatizer.lemmatize(tok.text)] = tok.text\n",
    "        #tokens_dict = set()\n",
    "        #self.lexicalGenerator.hypothesis_tokens = tokens_dict\n",
    "        self.lexicalGenerator.hypothesis = self.hypothesis.replace(',', '')\n",
    "        \n",
    "        self.lexicalGenerator.deptree_generate(annotation['polarized_tree'])\n",
    "        print(self.lexicalGenerator.replacement_log)\n",
    "        if self.lexicalGenerator.stop_critarion:\n",
    "            return True\n",
    "        for tree in self.lexicalGenerator.tree_log:\n",
    "            #rint((tree[1], tree[2]))\n",
    "            self.entailments.add((tree[1], tree[2]))\n",
    "            \n",
    "\n",
    "        return False\n",
    "\n",
    "    def generate(self, start, opened):\n",
    "        terminate = self.generate_premises(start)\n",
    "        if terminate:\n",
    "            return True\n",
    "\n",
    "        for premise in self.entailments:\n",
    "            if premise in self.closed:\n",
    "                continue\n",
    "            cost = premise[1]\n",
    "            if premise[0] not in opened:\n",
    "                opened[premise[0]] = cost\n",
    "            if cost < opened[premise[0]]:\n",
    "                opened[premise[0]] = cost\n",
    "        return False\n",
    "\n",
    "    def search(self, premises, hypothesis):\n",
    "        self.closed = pqdict({})\n",
    "        self.hypothesis = hypothesis\n",
    "        premises = premises.replace('\\n','')\n",
    "\n",
    "        self.hypothesis_kb()\n",
    "        self.phrasalGenerator.hypothesis = self.hypothesis\n",
    "        self.lexicalGenerator.hypothesis = self.hypothesis\n",
    "\n",
    "        open_lists = pqdict({}, reverse=True)\n",
    "        open_lists[premises] = inference_sts([premises], [hypothesis])\n",
    "\n",
    "        hop = 0\n",
    "        top_k = 2\n",
    "\n",
    "        while open_lists:\n",
    "            for _ in range(top_k):\n",
    "                if len(open_lists) > 0:\n",
    "                    optimal = open_lists.popitem()\n",
    "                    self.current_optimal = optimal[1]\n",
    "                    self.closed[optimal] = len(self.closed) + 1\n",
    "                    print(\"Optimal: \", optimal)\n",
    "                    goal_found = self.generate(optimal[0], open_lists)\n",
    "                    if goal_found:\n",
    "                        optimal = open_lists.popitem()\n",
    "                        self.closed[optimal] = len(self.closed) + 1\n",
    "                        print(\"Optimal: \", optimal)\n",
    "                        self.closed[(self.hypothesis, 1.0)] = len(self.closed) + 1\n",
    "                        return True\n",
    "                else: break   \n",
    "            hop += 1\n",
    "            if hop > 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = AStarPlanner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1414\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "entail_p = []\n",
    "entail_hypo = []\n",
    "with open(\"../data/SICk/entail.txt\") as upward_med:\n",
    "    lines = upward_med.readlines()\n",
    "    for i in range(len(lines) // 3):\n",
    "        entail_p.append(lines[i*3])\n",
    "        entail_hypo.append(lines[i*3+1])\n",
    "\n",
    "print(len(entail_p))\n",
    "\n",
    "with open(\"./generation_log_SICK.txt\", 'w') as generate_log:\n",
    "    for i in tqdm(range(0, len(entail_p))):\n",
    "        premise = entail_p[i].replace('\\n', '')\n",
    "        hypothesis = entail_hypo[i].replace('\\n', '')\n",
    "        try:\n",
    "            entail = planner.search(premise, hypothesis)\n",
    "            if not entail:\n",
    "                generate_log.write(\"\\nID: \" + str(i))\n",
    "                generate_log.write(\"\\nPremise: \" + premise)\n",
    "                generate_log.write(\"\\nHypothesis: \" + hypothesis)\n",
    "                generate_log.write('\\n')\n",
    "        except:\n",
    "            generate_log.write(\"\\nID: \" + str(i))\n",
    "            generate_log.write(\"\\nPremise: \" + premise)\n",
    "            generate_log.write(\"\\nHypothesis: \" + hypothesis)\n",
    "            generate_log.write('\\n')\n",
    "\n",
    "        #print(*planner.closed, sep=\" =>\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entail = planner.search(\"Two people wearing snowsuits are on the ground making snow angels\",\n",
    "        \"Two people in snowsuits are lying in the snow and making snow angels\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entail = planner.search(\"Tambourines are being played by a group of children\", \n",
    "             \"A group of children is playing tambourines\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entail = planner.search(\"A family is watching a little boy who is hitting a baseball\", \n",
    "             \"A child is hitting a baseball\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entail = planner.search(\"You know that some life changing actions must be taken when grandma reacts with the sad emoji\", \"You know that some actions must be taken when grandma reacts with the sad emoji\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entail = planner.search(\"A black and a white dog are joyfully running on the grass\", \n",
    "             \"A dog, which has a black coat, and a white dog are running on the grass\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entail = planner.search(\"A group of boys are playing with a ball, in front of a large door made of wood\", \n",
    "             \"The children are playing in front of a large door\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entail = planner.search(\"A man with a red helmet is riding a blue motorcycle down the road\", \n",
    "             \"A motorcyclist is riding a motorbike along a roadway\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal:  ('A young lady with light brown hair is wearing a red necklace, a sweatshirt and earrings and is smiling', tensor(0.5387))\n",
      "============================\n",
      "('A young lady with light brown hair is wearing a red necklace sweatshirt earrings and is smiling', tensor(0.5326))\n",
      "('A young lady with brown hair is wearing a red necklace a sweatshirt and earrings and is smiling', tensor(0.4895))\n",
      "('A young lady with light brown hair is wearing a necklace a sweatshirt and earrings and is smiling', tensor(0.4437))\n",
      "('young lady with light brown hair is wearing a red necklace a sweatshirt and earrings and is smiling', tensor(0.5001))\n",
      "('A young lady with light brown hair is wearing a a sweatshirt earrings and is smiling', tensor(0.4188))\n",
      "('A young lady with light brown is wearing a red necklace a sweatshirt and earrings and is smiling', tensor(0.5039))\n",
      "('A young lady with light brown hair is wearing red necklace a sweatshirt earrings and is smiling', tensor(0.5245))\n",
      "('A young lady with light brown hair is wearing a red necklace a earrings and is smiling', tensor(0.6017))\n",
      "('A young lady with light brown is wearing a red necklace a sweatshirt and earrings and is smiling', tensor(0.5039))\n",
      "('A young lady with light brown hair is wearing red necklace a sweatshirt earrings and is smiling', tensor(0.5245))\n",
      "('A young lady with light brown hair is wearing a red necklace a earrings and is smiling', tensor(0.6017))\n",
      "('A young lady with light brown hair is wearing a a sweatshirt earrings and is smiling', tensor(0.4188))\n",
      "('A young lady with light brown hair is wearing a a sweatshirt earrings and is smiling', tensor(0.4188))\n",
      "('A young lady with light brown hair is wearing a red necklace sweatshirt earrings and is smiling', tensor(0.5326))\n",
      "('A young lady with light hair is wearing a red necklace a sweatshirt and earrings and is smiling', tensor(0.5253))\n",
      "('A young lady with light brown hair is wearing a red necklace a sweatshirt and is smiling', tensor(0.4870))\n",
      "('A young lady with light brown hair is wearing a red necklace a earrings and is smiling', tensor(0.6017))\n",
      "('A young lady with light brown hair is wearing a necklace a sweatshirt and earrings and is smiling', tensor(0.4437))\n",
      "('A young lady is wearing a red necklace a sweatshirt and earrings and is smiling', tensor(0.5707))\n",
      "('A young lady with light brown hair is wearing a red necklace a sweatshirt and earrings', tensor(0.6210))\n",
      "('A lady with light brown hair is wearing a red necklace a sweatshirt and earrings and is smiling', tensor(0.4647))\n",
      "('A young lady with light brown hair is wearing a red necklace a sweatshirt and is smiling', tensor(0.4870))\n",
      "('A young lady with light hair is wearing a red necklace a sweatshirt and earrings and is smiling', tensor(0.5253))\n",
      "('young lady with light brown hair is wearing a red necklace a sweatshirt and earrings and is smiling', tensor(0.5001))\n",
      "('A young lady with light brown hair is a red necklace a sweatshirt and earrings is smiling', tensor(0.4965))\n",
      "('A young lady with light brown hair is a red necklace a sweatshirt and earrings is smiling', tensor(0.4965))\n",
      "('A young lady with light brown hair is a red necklace a sweatshirt and earrings is smiling', tensor(0.4965))\n",
      "('A young lady with light brown hair is wearing a red necklace sweatshirt earrings and is smiling', tensor(0.5326))\n",
      "('A young lady with brown hair is wearing a red necklace a sweatshirt and earrings and is smiling', tensor(0.4895))\n",
      "('A young lady with light brown hair is wearing a red necklace a sweatshirt and earrings', tensor(0.6210))\n",
      "('A young lady with light brown hair is wearing red necklace a sweatshirt earrings and is smiling', tensor(0.5245))\n",
      "('A young lady is wearing a red necklace a sweatshirt and earrings and is smiling', tensor(0.5707))\n",
      "('A lady with light brown hair is wearing a red necklace a sweatshirt and earrings and is smiling', tensor(0.4647))\n",
      "tensor(0.5441) A young lady with light brown hair is wearing beads that are red a red necklace, a sweatshirt and earrings and is smiling\n",
      "tensor(0.5224) A young lady with light brown hair is wearing a red necklace, a sweatshirt and earrings and is smiling\n",
      "tensor(0.5389) A young lady with light brown hair is is wearing beads that are red a red necklace, a sweatshirt and earrings and is smiling\n",
      "tensor(0.6170) A teenage girl with light brown hair is wearing a red necklace, a sweatshirt and earrings and is smiling\n",
      "['Somebody is wearing => is wearing', 'is wearing => is wearing beads that are red', 'is wearing => is wearing', 'wearing => is wearing beads that are red', 'A young lady => A teenage girl']\n",
      "Generate Lexical Variation\n",
      "s {'brown': 1, 'brownness': 1, 'Brown': 1, 'Robert Brown': 1, 'John Brown': 1, 'Brown University': 1, 'embrown': 1, 'brownish': 1, 'chocolate-brown': 1, 'dark-brown': 1, 'browned': 1}\n",
      "red   colored\n",
      "A young lady with light red hair is wearing a red necklace a sweatshirt and earrings and is smiling tensor(0.5621)\n",
      "s {'light': 1, 'visible light': 1, 'visible radiation': 1, 'light source': 1, 'luminosity': 1, 'brightness': 1, 'brightness level': 1, 'luminance': 1, 'luminousness': 1, 'illumination': 1, 'lightness': 1, 'lighting': 1, 'sparkle': 1, 'twinkle': 1, 'spark': 1, 'Inner Light': 1, 'Light': 1, 'Light Within': 1, 'Christ Within': 1, 'lighter': 1, 'igniter': 1, 'ignitor': 1, 'illume': 1, 'illumine': 1, 'light up': 1, 'illuminate': 1, 'fire up': 1, 'alight': 1, 'perch': 1, 'ignite': 1, 'fall': 1, 'unhorse': 1, 'dismount': 1, 'get off': 1, 'get down': 1, 'light-colored': 1, 'unaccented': 1, 'weak': 1, 'clean': 1, 'clear': 1, 'unclouded': 1, 'lightsome': 1, 'tripping': 1, 'faint': 1, 'swooning': 1, 'light-headed': 1, 'lightheaded': 1, 'abstemious': 1, 'scant': 1, 'short': 1, 'idle': 1, 'lite': 1, 'low-cal': 1, 'calorie-free': 1, 'wakeful': 1, 'easy': 1, 'loose': 1, 'promiscuous': 1, 'sluttish': 1, 'wanton': 1, 'lightly': 1}\n",
      "A young lady with red brown hair is wearing a red necklace a sweatshirt and earrings and is smiling tensor(0.5192)\n",
      "s {'hair': 1, \"hair's-breadth\": 1, 'hairsbreadth': 1, 'whisker': 1, 'fuzz': 1, 'tomentum': 1, 'pilus': 1, 'haircloth': 1}\n",
      "some young lady with light brown hair is wearing a red necklace a sweatshirt and earrings and is smiling tensor(0.5132)\n",
      "an young lady with light brown hair is wearing a red necklace a sweatshirt and earrings and is smiling tensor(0.5014)\n",
      "one young lady with light brown hair is wearing a red necklace a sweatshirt and earrings and is smiling tensor(0.5143)\n",
      "s {'young': 1, 'offspring': 1, 'Young': 1, 'Loretta Young': 1, 'Whitney Young': 1, 'Whitney Moore Young Jr.': 1, 'Thomas Young': 1, 'Pres Young': 1, 'Lester Willis Young': 1, 'Edward Young': 1, 'Cy Young': 1, 'Danton True Young': 1, 'Brigham Young': 1, 'youth': 1, 'immature': 1, 'new': 1, 'youthful': 1, 'vernal': 1, 'unseasoned': 1, 'untested': 1, 'untried': 1}\n",
      "A teenage lady with light brown hair is wearing a red necklace a sweatshirt and earrings and is smiling tensor(0.5938)\n",
      "teenage   age\n",
      "teenage   age\n",
      "s {'lady': 1, 'dame': 1, 'madam': 1, \"ma'am\": 1, 'gentlewoman': 1, 'Lady': 1, 'noblewoman': 1, 'peeress': 1}\n",
      "A young lady with light brown hair is wearing some red necklace a sweatshirt and earrings and is smiling tensor(0.5115)\n",
      "A young lady with light brown hair is wearing an red necklace a sweatshirt and earrings and is smiling tensor(0.5020)\n",
      "A young lady with light brown hair is wearing one red necklace a sweatshirt and earrings and is smiling tensor(0.5044)\n",
      "A young lady with light brown hair is wearing a red necklace some sweatshirt and earrings and is smiling tensor(0.5147)\n",
      "A young lady with light brown hair is wearing a red necklace an sweatshirt and earrings and is smiling tensor(0.5137)\n",
      "A young lady with light brown hair is wearing a red necklace one sweatshirt and earrings and is smiling tensor(0.5151)\n",
      "s {'earring': 1}\n",
      "s {'sweatshirt': 1}\n",
      "s {'necklace': 1}\n",
      "A young lady with light brown hair is wearing a red wearing a sweatshirt and earrings and is smiling tensor(0.4898)\n",
      "wearing   wear\n",
      "s {'smile': 1, 'smiling': 1, 'grin': 1, 'grinning': 1, 'beamish': 1, 'twinkly': 1}\n",
      "['brown => red', 'light => red', 'A => some', 'A => an', 'A => one', 'young => teenage', 'young => teenage', 'young => teenage', 'a => some', 'a => an', 'a => one', 'a => some', 'a => an', 'a => one', 'necklace => wearing', 'necklace => wearing']\n",
      "Optimal:  ('A young lady with light brown hair is wearing a red necklace a sweatshirt and earrings', tensor(0.6210))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "('A young lady with light brown hair is wearing a red necklace a earrings', tensor(0.6950))\n",
      "('A young lady with light brown hair is wearing a red necklace sweatshirt earrings', tensor(0.6284))\n",
      "('A young lady with light brown hair is wearing red necklace a sweatshirt and earrings', tensor(0.6206))\n",
      "('A young lady with light brown is wearing a red necklace a sweatshirt and earrings', tensor(0.6142))\n",
      "('young lady with light brown hair is wearing a red necklace a sweatshirt and earrings', tensor(0.6063))\n",
      "('A young lady with light brown hair is wearing a necklace a sweatshirt and earrings', tensor(0.5321))\n",
      "('A young lady with light brown hair is wearing a necklace a sweatshirt and earrings', tensor(0.5321))\n",
      "('A young lady with light brown hair is wearing red necklace a sweatshirt and earrings', tensor(0.6206))\n",
      "('A young lady with light brown hair is wearing a red necklace sweatshirt earrings', tensor(0.6284))\n",
      "('A young lady with light brown is wearing a red necklace a sweatshirt and earrings', tensor(0.6142))\n",
      "('A young lady with light brown hair is wearing a red necklace a earrings', tensor(0.6950))\n",
      "('A young lady is wearing a red necklace a sweatshirt and earrings', tensor(0.6675))\n",
      "('A young lady with light hair is wearing a red necklace a sweatshirt and earrings', tensor(0.6299))\n",
      "('A young lady with brown hair is wearing a red necklace a sweatshirt and earrings', tensor(0.5498))\n",
      "('A young lady is wearing a red necklace a sweatshirt and earrings', tensor(0.6675))\n",
      "('A young lady with light brown hair is wearing a red necklace a sweatshirt', tensor(0.5890))\n",
      "('A young lady with light hair is wearing a red necklace a sweatshirt and earrings', tensor(0.6299))\n",
      "('A young lady with light brown hair is wearing a red necklace a earrings', tensor(0.6950))\n",
      "('A young lady with light brown hair is wearing a red necklace a sweatshirt', tensor(0.5890))\n",
      "('A lady with light brown hair is wearing a red necklace a sweatshirt and earrings', tensor(0.5631))\n",
      "('A young lady with light brown hair is wearing a red necklace sweatshirt earrings', tensor(0.6284))\n",
      "('young lady with light brown hair is wearing a red necklace a sweatshirt and earrings', tensor(0.6063))\n",
      "('A young lady with brown hair is wearing a red necklace a sweatshirt and earrings', tensor(0.5498))\n",
      "('A lady with light brown hair is wearing a red necklace a sweatshirt and earrings', tensor(0.5631))\n",
      "tensor(0.5577) A young lady with light brown hair are red a sweatshirt and earrings\n",
      "tensor(0.6532) A young lady with light brown hair is wearing beads that are red a sweatshirt and earrings\n",
      "tensor(0.6627) A young lady with light brown hair is wearing a is wearing beads that are red a sweatshirt and earrings\n",
      "tensor(0.6210) A young lady with light brown hair is wearing a red necklace a sweatshirt and earrings\n",
      "tensor(0.6506) A young lady with light brown hair is is wearing beads that are red a red necklace a sweatshirt and earrings\n",
      "tensor(0.7206) A teenage girl with light brown hair is wearing a red necklace a sweatshirt and earrings\n",
      "['is wearing a red necklace => are red', 'is wearing a red necklace => is wearing beads that are red', 'is wearing => is wearing', 'wearing => is wearing beads that are red', 'red necklace => is wearing beads that are red', 'A young lady => A teenage girl']\n",
      "Generate Lexical Variation\n",
      "s {'brown': 1, 'brownness': 1, 'Brown': 1, 'Robert Brown': 1, 'John Brown': 1, 'Brown University': 1, 'embrown': 1, 'brownish': 1, 'chocolate-brown': 1, 'dark-brown': 1, 'browned': 1}\n",
      "red   colored\n",
      "A young lady with light red hair is wearing a red necklace a sweatshirt and earrings tensor(0.6767)\n",
      "s {'light': 1, 'visible light': 1, 'visible radiation': 1, 'light source': 1, 'luminosity': 1, 'brightness': 1, 'brightness level': 1, 'luminance': 1, 'luminousness': 1, 'illumination': 1, 'lightness': 1, 'lighting': 1, 'sparkle': 1, 'twinkle': 1, 'spark': 1, 'Inner Light': 1, 'Light': 1, 'Light Within': 1, 'Christ Within': 1, 'lighter': 1, 'igniter': 1, 'ignitor': 1, 'illume': 1, 'illumine': 1, 'light up': 1, 'illuminate': 1, 'fire up': 1, 'alight': 1, 'perch': 1, 'ignite': 1, 'fall': 1, 'unhorse': 1, 'dismount': 1, 'get off': 1, 'get down': 1, 'light-colored': 1, 'unaccented': 1, 'weak': 1, 'clean': 1, 'clear': 1, 'unclouded': 1, 'lightsome': 1, 'tripping': 1, 'faint': 1, 'swooning': 1, 'light-headed': 1, 'lightheaded': 1, 'abstemious': 1, 'scant': 1, 'short': 1, 'idle': 1, 'lite': 1, 'low-cal': 1, 'calorie-free': 1, 'wakeful': 1, 'easy': 1, 'loose': 1, 'promiscuous': 1, 'sluttish': 1, 'wanton': 1, 'lightly': 1}\n",
      "A young lady with red brown hair is wearing a red necklace a sweatshirt and earrings tensor(0.5955)\n",
      "s {'hair': 1, \"hair's-breadth\": 1, 'hairsbreadth': 1, 'whisker': 1, 'fuzz': 1, 'tomentum': 1, 'pilus': 1, 'haircloth': 1}\n",
      "some young lady with light brown hair is wearing a red necklace a sweatshirt and earrings tensor(0.6188)\n",
      "an young lady with light brown hair is wearing a red necklace a sweatshirt and earrings tensor(0.6188)\n",
      "one young lady with light brown hair is wearing a red necklace a sweatshirt and earrings tensor(0.6190)\n",
      "s {'young': 1, 'offspring': 1, 'Young': 1, 'Loretta Young': 1, 'Whitney Young': 1, 'Whitney Moore Young Jr.': 1, 'Thomas Young': 1, 'Pres Young': 1, 'Lester Willis Young': 1, 'Edward Young': 1, 'Cy Young': 1, 'Danton True Young': 1, 'Brigham Young': 1, 'youth': 1, 'immature': 1, 'new': 1, 'youthful': 1, 'vernal': 1, 'unseasoned': 1, 'untested': 1, 'untried': 1}\n",
      "A teenage lady with light brown hair is wearing a red necklace a sweatshirt and earrings tensor(0.7203)\n",
      "teenage   age\n",
      "teenage   age\n",
      "s {'lady': 1, 'dame': 1, 'madam': 1, \"ma'am\": 1, 'gentlewoman': 1, 'Lady': 1, 'noblewoman': 1, 'peeress': 1}\n",
      "A young lady with light brown hair is wearing some red necklace a sweatshirt and earrings tensor(0.6214)\n",
      "A young lady with light brown hair is wearing an red necklace a sweatshirt and earrings tensor(0.6163)\n",
      "A young lady with light brown hair is wearing one red necklace a sweatshirt and earrings tensor(0.6043)\n",
      "s {'necklace': 1}\n",
      "A young lady with light brown hair is wearing a red wearing a sweatshirt and earrings tensor(0.6002)\n",
      "wearing   wear\n",
      "A young lady with light brown hair is wearing a red necklace some sweatshirt and earrings tensor(0.6231)\n",
      "A young lady with light brown hair is wearing a red necklace an sweatshirt and earrings tensor(0.6287)\n",
      "A young lady with light brown hair is wearing a red necklace one sweatshirt and earrings tensor(0.6197)\n",
      "s {'earring': 1}\n",
      "s {'sweatshirt': 1}\n",
      "['brown => red', 'light => red', 'A => some', 'A => an', 'A => one', 'young => teenage', 'young => teenage', 'young => teenage', 'a => some', 'a => an', 'a => one', 'necklace => wearing', 'necklace => wearing', 'a => some', 'a => an', 'a => one']\n",
      "Optimal:  ('A young lady with light brown hair is wearing a red necklace a earrings', tensor(0.6950))\n",
      "============================\n",
      "('A young lady with light hair is wearing a red necklace a earrings', tensor(0.6705))\n",
      "('A young lady with brown hair is wearing a red necklace a earrings', tensor(0.6662))\n",
      "('A young lady with brown hair is wearing a red necklace a earrings', tensor(0.6662))\n",
      "('A young lady with light brown hair is wearing a necklace a earrings', tensor(0.5678))\n",
      "('A lady with light brown hair is wearing a red necklace a earrings', tensor(0.6442))\n",
      "('A young lady with light brown hair is wearing a red necklace earrings', tensor(0.6994))\n",
      "('A young lady with light brown hair is wearing red necklace a earrings', tensor(0.6883))\n",
      "('A young lady with light brown hair is wearing a a earrings', tensor(0.5256))\n",
      "('A young lady with light brown hair is wearing red necklace a earrings', tensor(0.6883))\n",
      "('young lady with light brown hair is wearing a red necklace a earrings', tensor(0.6881))\n",
      "('A young lady with light brown hair is wearing a necklace a earrings', tensor(0.5678))\n",
      "('A young lady with light hair is wearing a red necklace a earrings', tensor(0.6705))\n",
      "('A lady with light brown hair is wearing a red necklace a earrings', tensor(0.6442))\n",
      "('A young lady with light brown hair is wearing a red necklace earrings', tensor(0.6994))\n",
      "('A young lady is wearing a red necklace a earrings', tensor(0.7557))\n",
      "('young lady with light brown hair is wearing a red necklace a earrings', tensor(0.6881))\n",
      "('A young lady with light brown hair is wearing a a earrings', tensor(0.5256))\n",
      "('A young lady with light brown is wearing a red necklace a earrings', tensor(0.6932))\n",
      "('A young lady with light brown is wearing a red necklace a earrings', tensor(0.6932))\n",
      "('A young lady is wearing a red necklace a earrings', tensor(0.7557))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6950) A young lady with light brown hair is wearing a red necklace a earrings\n",
      "tensor(0.7118) A young lady with light brown hair is wearing beads that are red a red necklace a earrings\n",
      "tensor(0.8222) A teenage girl with light brown hair is wearing a red necklace a earrings\n",
      "tensor(0.7088) A young lady with light brown hair is is wearing beads that are red a red necklace a earrings\n",
      "['is wearing => is wearing', 'wearing => is wearing beads that are red', 'A young lady => A teenage girl', 'Somebody is wearing => is wearing', 'is wearing => is wearing beads that are red']\n",
      "Generate Lexical Variation\n",
      "s {'brown': 1, 'brownness': 1, 'Brown': 1, 'Robert Brown': 1, 'John Brown': 1, 'Brown University': 1, 'embrown': 1, 'brownish': 1, 'chocolate-brown': 1, 'dark-brown': 1, 'browned': 1}\n",
      "red   colored\n",
      "A young lady with light red hair is wearing a red necklace a earrings tensor(0.7178)\n",
      "s {'light': 1, 'visible light': 1, 'visible radiation': 1, 'light source': 1, 'luminosity': 1, 'brightness': 1, 'brightness level': 1, 'luminance': 1, 'luminousness': 1, 'illumination': 1, 'lightness': 1, 'lighting': 1, 'sparkle': 1, 'twinkle': 1, 'spark': 1, 'Inner Light': 1, 'Light': 1, 'Light Within': 1, 'Christ Within': 1, 'lighter': 1, 'igniter': 1, 'ignitor': 1, 'illume': 1, 'illumine': 1, 'light up': 1, 'illuminate': 1, 'fire up': 1, 'alight': 1, 'perch': 1, 'ignite': 1, 'fall': 1, 'unhorse': 1, 'dismount': 1, 'get off': 1, 'get down': 1, 'light-colored': 1, 'unaccented': 1, 'weak': 1, 'clean': 1, 'clear': 1, 'unclouded': 1, 'lightsome': 1, 'tripping': 1, 'faint': 1, 'swooning': 1, 'light-headed': 1, 'lightheaded': 1, 'abstemious': 1, 'scant': 1, 'short': 1, 'idle': 1, 'lite': 1, 'low-cal': 1, 'calorie-free': 1, 'wakeful': 1, 'easy': 1, 'loose': 1, 'promiscuous': 1, 'sluttish': 1, 'wanton': 1, 'lightly': 1}\n",
      "A young lady with red brown hair is wearing a red necklace a earrings tensor(0.6920)\n",
      "s {'hair': 1, \"hair's-breadth\": 1, 'hairsbreadth': 1, 'whisker': 1, 'fuzz': 1, 'tomentum': 1, 'pilus': 1, 'haircloth': 1}\n",
      "some young lady with light brown hair is wearing a red necklace a earrings tensor(0.6822)\n",
      "an young lady with light brown hair is wearing a red necklace a earrings tensor(0.6939)\n",
      "one young lady with light brown hair is wearing a red necklace a earrings tensor(0.6777)\n",
      "s {'young': 1, 'offspring': 1, 'Young': 1, 'Loretta Young': 1, 'Whitney Young': 1, 'Whitney Moore Young Jr.': 1, 'Thomas Young': 1, 'Pres Young': 1, 'Lester Willis Young': 1, 'Edward Young': 1, 'Cy Young': 1, 'Danton True Young': 1, 'Brigham Young': 1, 'youth': 1, 'immature': 1, 'new': 1, 'youthful': 1, 'vernal': 1, 'unseasoned': 1, 'untested': 1, 'untried': 1}\n",
      "A teenage lady with light brown hair is wearing a red necklace a earrings tensor(0.8061)\n",
      "teenage   age\n",
      "teenage   age\n",
      "s {'lady': 1, 'dame': 1, 'madam': 1, \"ma'am\": 1, 'gentlewoman': 1, 'Lady': 1, 'noblewoman': 1, 'peeress': 1}\n",
      "A young lady with light brown hair is wearing some red necklace a earrings tensor(0.6831)\n",
      "A young lady with light brown hair is wearing an red necklace a earrings tensor(0.6918)\n",
      "A young lady with light brown hair is wearing one red necklace a earrings tensor(0.6631)\n",
      "A young lady with light brown hair is wearing a red necklace some earrings tensor(0.6773)\n",
      "A young lady with light brown hair is wearing a red necklace an earrings tensor(0.6983)\n",
      "A young lady with light brown hair is wearing a red necklace one earrings tensor(0.6734)\n",
      "s {'earring': 1}\n",
      "s {'necklace': 1}\n",
      "A young lady with light brown hair is wearing a red wearing a earrings tensor(0.6812)\n",
      "wearing   wear\n",
      "['brown => red', 'light => red', 'A => some', 'A => an', 'A => one', 'young => teenage', 'young => teenage', 'young => teenage', 'a => some', 'a => an', 'a => one', 'a => some', 'a => an', 'a => one', 'necklace => wearing', 'necklace => wearing']\n",
      "Optimal:  ('A young lady is wearing a red necklace a earrings', tensor(0.7557))\n",
      "============================\n",
      "('young lady is wearing a red necklace a earrings', tensor(0.7588))\n",
      "('A young lady is wearing a necklace a earrings', tensor(0.5318))\n",
      "('A young lady is wearing a red necklace earrings', tensor(0.7614))\n",
      "('A young lady is wearing a red necklace earrings', tensor(0.7614))\n",
      "('A lady is wearing a red necklace a earrings', tensor(0.7081))\n",
      "('young lady is wearing a red necklace a earrings', tensor(0.7588))\n",
      "('A young lady is wearing red necklace a earrings', tensor(0.7524))\n",
      "('A young lady is wearing red necklace a earrings', tensor(0.7524))\n",
      "('A young lady is wearing a necklace a earrings', tensor(0.5318))\n",
      "('A lady is wearing a red necklace a earrings', tensor(0.7081))\n",
      "tensor(0.7950) A young lady is is wearing beads that are red a red necklace a earrings\n",
      "tensor(0.8979) A teenage girl is wearing a red necklace a earrings\n",
      "tensor(0.8076) A young lady is wearing beads that are red a earrings\n",
      "tensor(0.8201) A young lady is wearing a is wearing beads that are red a earrings\n",
      "tensor(0.7162) A young lady are red a earrings\n",
      "tensor(0.7557) A young lady is wearing a red necklace a earrings\n",
      "['is wearing a red necklace => are red', 'is wearing a red necklace => is wearing beads that are red', 'is wearing => is wearing', 'wearing => is wearing beads that are red', 'red necklace => is wearing beads that are red', 'A young lady => A teenage girl']\n",
      "Generate Lexical Variation\n",
      "some young lady is wearing a red necklace a earrings tensor(0.7492)\n",
      "an young lady is wearing a red necklace a earrings tensor(0.7512)\n",
      "one young lady is wearing a red necklace a earrings tensor(0.7487)\n",
      "s {'young': 1, 'offspring': 1, 'Young': 1, 'Loretta Young': 1, 'Whitney Young': 1, 'Whitney Moore Young Jr.': 1, 'Thomas Young': 1, 'Pres Young': 1, 'Lester Willis Young': 1, 'Edward Young': 1, 'Cy Young': 1, 'Danton True Young': 1, 'Brigham Young': 1, 'youth': 1, 'immature': 1, 'new': 1, 'youthful': 1, 'vernal': 1, 'unseasoned': 1, 'untested': 1, 'untried': 1}\n",
      "A teenage lady is wearing a red necklace a earrings tensor(0.8849)\n",
      "teenage   age\n",
      "teenage   age\n",
      "s {'lady': 1, 'dame': 1, 'madam': 1, \"ma'am\": 1, 'gentlewoman': 1, 'Lady': 1, 'noblewoman': 1, 'peeress': 1}\n",
      "A young lady is wearing some red necklace a earrings tensor(0.7516)\n",
      "A young lady is wearing an red necklace a earrings tensor(0.7535)\n",
      "A young lady is wearing one red necklace a earrings tensor(0.7196)\n",
      "s {'necklace': 1}\n",
      "A young lady is wearing a red wearing a earrings tensor(0.7224)\n",
      "wearing   wear\n",
      "A young lady is wearing a red necklace some earrings tensor(0.7369)\n",
      "A young lady is wearing a red necklace an earrings tensor(0.7593)\n",
      "A young lady is wearing a red necklace one earrings tensor(0.7383)\n",
      "s {'earring': 1}\n",
      "['A => some', 'A => an', 'A => one', 'young => teenage', 'young => teenage', 'young => teenage', 'a => some', 'a => an', 'a => one', 'necklace => wearing', 'necklace => wearing', 'a => some', 'a => an', 'a => one']\n",
      "Optimal:  ('A young lady is wearing a red necklace earrings', tensor(0.7614))\n",
      "============================\n",
      "('A young lady is wearing red necklace earrings', tensor(0.7667))\n",
      "('A young lady is wearing a red necklace', tensor(0.7640))\n",
      "('A young lady is wearing a red necklace', tensor(0.7640))\n",
      "('young lady is wearing a red necklace earrings', tensor(0.7664))\n",
      "('A young lady is wearing a necklace earrings', tensor(0.5514))\n",
      "('A young lady is wearing a necklace earrings', tensor(0.5514))\n",
      "('A young lady is wearing a earrings', tensor(0.4741))\n",
      "('A young lady is wearing a earrings', tensor(0.4741))\n",
      "('A young lady is wearing red necklace earrings', tensor(0.7667))\n",
      "('A lady is wearing a red necklace earrings', tensor(0.7219))\n",
      "('young lady is wearing a red necklace earrings', tensor(0.7664))\n",
      "('A young lady is wearing a necklace earrings', tensor(0.5514))\n",
      "('A young lady is wearing a necklace earrings', tensor(0.5514))\n",
      "('A lady is wearing a red necklace earrings', tensor(0.7219))\n",
      "tensor(0.7964) A young lady is is wearing beads that are red a red necklace earrings\n",
      "tensor(0.9007) A teenage girl is wearing a red necklace earrings\n",
      "tensor(0.7614) A young lady is wearing a red necklace earrings\n",
      "['is wearing a amod earrings => is wearing beads that are red', 'A young lady => A teenage girl', 'is wearing => is wearing', 'wearing => is wearing beads that are red']\n",
      "Generate Lexical Variation\n",
      "some young lady is wearing a red necklace earrings tensor(0.7576)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an young lady is wearing a red necklace earrings tensor(0.7578)\n",
      "one young lady is wearing a red necklace earrings tensor(0.7550)\n",
      "s {'young': 1, 'offspring': 1, 'Young': 1, 'Loretta Young': 1, 'Whitney Young': 1, 'Whitney Moore Young Jr.': 1, 'Thomas Young': 1, 'Pres Young': 1, 'Lester Willis Young': 1, 'Edward Young': 1, 'Cy Young': 1, 'Danton True Young': 1, 'Brigham Young': 1, 'youth': 1, 'immature': 1, 'new': 1, 'youthful': 1, 'vernal': 1, 'unseasoned': 1, 'untested': 1, 'untried': 1}\n",
      "A teenage lady is wearing a red necklace earrings tensor(0.8850)\n",
      "teenage   age\n",
      "teenage   age\n",
      "s {'lady': 1, 'dame': 1, 'madam': 1, \"ma'am\": 1, 'gentlewoman': 1, 'Lady': 1, 'noblewoman': 1, 'peeress': 1}\n",
      "A young lady is wearing some red necklace earrings tensor(0.7616)\n",
      "A young lady is wearing an red necklace earrings tensor(0.7595)\n",
      "A young lady is wearing one red necklace earrings tensor(0.7091)\n",
      "s {'necklace': 1}\n",
      "A young lady is wearing a red wearing earrings tensor(0.7323)\n",
      "wearing   wear\n",
      "s {'earring': 1}\n",
      "['A => some', 'A => an', 'A => one', 'young => teenage', 'young => teenage', 'young => teenage', 'a => some', 'a => an', 'a => one', 'necklace => wearing', 'necklace => wearing']\n",
      "Optimal:  ('A teenage girl is wearing a red necklace earrings', tensor(0.9007))\n",
      "============================\n",
      "('A girl is wearing a red necklace earrings', tensor(0.7799))\n",
      "('A teenage girl is wearing red necklace earrings', tensor(0.8986))\n",
      "('A teenage girl is wearing a necklace earrings', tensor(0.6726))\n",
      "('A teenage is wearing a red necklace earrings', tensor(0.8629))\n",
      "('A teenage is wearing a red necklace earrings', tensor(0.8629))\n",
      "('A teenage girl is wearing a necklace earrings', tensor(0.6726))\n",
      "('A teenage girl is wearing a necklace earrings', tensor(0.6726))\n",
      "('A teenage girl is wearing a red necklace', tensor(0.9033))\n",
      "('A teenage girl is wearing a red necklace', tensor(0.9033))\n",
      "('teenage girl is wearing a red necklace earrings', tensor(0.8893))\n",
      "('teenage girl is wearing a red necklace earrings', tensor(0.8893))\n",
      "('A girl is wearing a red necklace earrings', tensor(0.7799))\n",
      "('A teenage girl is wearing red necklace earrings', tensor(0.8986))\n",
      "('A teenage girl is wearing a earrings', tensor(0.6121))\n",
      "('A teenage girl is wearing a necklace earrings', tensor(0.6726))\n",
      "('A teenage girl is wearing a earrings', tensor(0.6121))\n",
      "tensor(0.9007) A teenage girl is wearing a red necklace earrings\n",
      "tensor(0.9479) A teenage girl is is wearing beads that are red a red necklace earrings\n",
      "['is wearing a amod earrings => is wearing beads that are red', 'is wearing => is wearing', 'wearing => is wearing beads that are red', 'A teenage girl => A teenage girl']\n",
      "Generate Lexical Variation\n",
      "some teenage girl is wearing a red necklace earrings tensor(0.8908)\n",
      "an teenage girl is wearing a red necklace earrings tensor(0.8984)\n",
      "one teenage girl is wearing a red necklace earrings tensor(0.8891)\n",
      "A teenage girl is wearing some red necklace earrings tensor(0.8970)\n",
      "A teenage girl is wearing an red necklace earrings tensor(0.8995)\n",
      "A teenage girl is wearing one red necklace earrings tensor(0.8618)\n",
      "s {'necklace': 1}\n",
      "A teenage girl is wearing a red wearing earrings tensor(0.8721)\n",
      "wearing   wear\n",
      "s {'earring': 1}\n",
      "['A => some', 'A => an', 'A => one', 'a => some', 'a => an', 'a => one', 'necklace => wearing', 'necklace => wearing']\n",
      "Optimal:  ('A teenage girl is is wearing beads that are red a red necklace earrings', tensor(0.9479))\n",
      "============================\n",
      "Optimal:  ('A teenage girl is wearing a red necklace', tensor(0.9033))\n",
      "('A young lady with light brown hair is wearing a red necklace, a sweatshirt and earrings and is smiling', tensor(0.5387)) =>\n",
      "('A young lady with light brown hair is wearing a red necklace a sweatshirt and earrings', tensor(0.6210)) =>\n",
      "('A young lady with light brown hair is wearing a red necklace a earrings', tensor(0.6950)) =>\n",
      "('A young lady is wearing a red necklace a earrings', tensor(0.7557)) =>\n",
      "('A young lady is wearing a red necklace earrings', tensor(0.7614)) =>\n",
      "('A teenage girl is wearing a red necklace earrings', tensor(0.9007)) =>\n",
      "('A teenage girl is is wearing beads that are red a red necklace earrings', tensor(0.9479)) =>\n",
      "('A teenage girl is wearing a red necklace', tensor(0.9033)) =>\n",
      "('A teenage girl is wearing beads that are red', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(entail_p[76], entail_hypo[76])\n",
    "#entail = planner.search(\"A dog that has a black and white coat is trotting through shallow water\", \n",
    "#             \"A dog that has a white and black colored coat is trotting through shallow water.\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entail = planner.search(\"A family is watching a little boy who is hitting a baseball\", \n",
    "             \"A child is hitting a baseball\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entail = planner.search(\"A deer is jumping over a fence\", \n",
    "             \"A deer is jumping a fence\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entail = planner.search(\"A boy is hitting a baseball\", \n",
    "             \"A chil is hitting a baseball\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entail = planner.search(\"A brown dog is attacking another animal in front of the tall man in pants\", \n",
    "             \"A dog is attacking another animal in front of the man in pants\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entail = planner.search(\"A family is watching a little boy who is hitting a baseball\", \n",
    "             \"A family is watching a boy who is hitting a baseball\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entail = planner.search(\"You can't park in front of my house on weekends.\", \n",
    "             \"You can't park in front of my large house on weekends.\")\n",
    "\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "annotations = []\n",
    "with open(\"./generation_log_upward.txt\", 'w') as generate_log:\n",
    "    phrasalGenerator = PhrasalGenerator()\n",
    "    pipeline = PolarizationPipeline(verbose=0)\n",
    "    for i in tqdm(range(0, 500)):\n",
    "        premise = MED_none[i].replace('\\n', '')\n",
    "        hypothesis = MED_none_hypo[i].replace('\\n', '')\n",
    "        premise = phrasalGenerator.preprocess(premise)\n",
    "        hypothesis = phrasalGenerator.preprocess(hypothesis)\n",
    "\n",
    "        tokenized = tokenizer(premise).sentences[0].words\n",
    "        tokens = [tok.text for tok in tokenized]\n",
    "\n",
    "        try:\n",
    "            h_parsed, replaced = dependency_parse(hypothesis, parser=\"stanza\")\n",
    "            h_tree, _ = pipeline.run_binarization(h_parsed, hypothesis, {})\n",
    "        except:\n",
    "            generate_log.write(\"\\nPremise: \" + premise)\n",
    "            generate_log.write(\"\\nHypothesis: \" + hypothesis)\n",
    "            continue\n",
    "        pipeline.modify_replacement(h_tree, replaced)\n",
    "        phrases = {} \n",
    "        collect_modifiers(h_tree, phrases, mod_type=\"NN\")\n",
    "        collect_modifiers(h_tree, phrases, mod_type=\"VB\")\n",
    "\n",
    "        try:\n",
    "            annotation = pipeline.single_polarization(premise)\n",
    "        except:\n",
    "            #generate_log.write(\"\\nPremise: \" + premise)\n",
    "            #generate_log.write(\"\\nHypothesis: \" + hypothesis)\n",
    "            continue\n",
    "    \n",
    "        phrasalGenerator.kb = phrases\n",
    "        #print(phrasalGenerator.kb)\n",
    "        phrasalGenerator.hypothesis = hypothesis.replace(',', '')\n",
    "        \n",
    "        phrasalGenerator.deptree_generate(\n",
    "            annotation['polarized_tree'], \n",
    "            annotation['annotated'], \n",
    "            tokens)\n",
    "\n",
    "        # for gen_tree in phrasalGenerator.tree_log:\n",
    "        #    leaves = gen_tree[0].sorted_leaves().popkeys()\n",
    "        #    sentence = ' '.join([x[0] for x in leaves])\n",
    "        #    print((sentence, gen_tree[1]))\n",
    "            \n",
    "        if phrasalGenerator.stop_critarion:\n",
    "            generate_log.write(\"\\nID: \" + str(i))\n",
    "            generate_log.write(\"\\nPremise: \" + premise)\n",
    "            generate_log.write(\"\\nHypothesis: \" + hypothesis)\n",
    "            #print(\"\\nPremise: \" + premise)\n",
    "            #print(\"\\nHypothesis: \" + hypothesis)\n",
    "            #print(*phrasalGenerator.sent_log, sep=\"\\n\")\n",
    "            #generate_log.writelines(phrasalGenerator.sent_log)\n",
    "            generate_log.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
