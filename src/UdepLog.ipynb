{
 "cells": [
  {
   "source": [
    "# UdepLog Neural-Logical Inference System"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tree import Tree\n",
    "from nltk.draw import TreeWidget\n",
    "from nltk.draw.util import CanvasFrame\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def jupyter_draw_nltk_tree(tree):\n",
    "    cf = CanvasFrame()\n",
    "    tc = TreeWidget(cf.canvas(), tree)\n",
    "    tc['node_font'] = 'arial 14 bold'\n",
    "    tc['leaf_font'] = 'arial 14'\n",
    "    tc['node_color'] = '#005990'\n",
    "    tc['leaf_color'] = '#3F8F57'\n",
    "    tc['line_color'] = '#175252'\n",
    "    cf.add_widget(tc, 20, 20)\n",
    "    os.system('rm -rf ../data/tree.png')\n",
    "    os.system('rm -rf ../data/tree.ps')\n",
    "    cf.print_to_file('../data/tree.ps')\n",
    "    cf.destroy()\n",
    "    os.system('convert ../data/tree.ps ../data/tree.png')\n",
    "    display(Image(filename='../data/tree.png'))"
   ]
  },
  {
   "source": [
    "## 2. BERT Model for Pharaphrase"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-MRPC were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "roberta_MRPC = \"textattack/roberta-base-MRPC\"\n",
    "bert_MRPC = \"bert-base-cased-finetuned-mrpc\"\n",
    "\n",
    "paraphraseTokenizer = AutoTokenizer.from_pretrained(roberta_MRPC)  \n",
    "paraphraseModel = AutoModelForSequenceClassification.from_pretrained(roberta_MRPC)"
   ]
  },
  {
   "source": [
    "## 3. UD Parser and RoBERTa Semantic Similarity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-03-15 17:02:04 INFO: Loading these models for language: en (English):\n",
      "========================================\n",
      "| Processor | Package                  |\n",
      "----------------------------------------\n",
      "| tokenize  | ../model/e...ize/gum.pt  |\n",
      "| pos       | ../model/en/pos/ewt.pt   |\n",
      "| lemma     | ../model/en/lemma/gum.pt |\n",
      "| depparse  | ../model/e...rse/gum.pt  |\n",
      "========================================\n",
      "\n",
      "2021-03-15 17:02:04 INFO: Use device: gpu\n",
      "2021-03-15 17:02:04 INFO: Loading: tokenize\n",
      "2021-03-15 17:02:05 INFO: Loading: pos\n",
      "2021-03-15 17:02:06 INFO: Loading: lemma\n",
      "2021-03-15 17:02:06 INFO: Loading: depparse\n",
      "2021-03-15 17:02:07 INFO: Done loading processors!\n",
      "2021-03-15 17:02:07 INFO: Loading these models for language: en (English):\n",
      "=======================================\n",
      "| Processor | Package                 |\n",
      "---------------------------------------\n",
      "| tokenize  | ../model/e...ize/gum.pt |\n",
      "=======================================\n",
      "\n",
      "2021-03-15 17:02:07 INFO: Use device: cpu\n",
      "2021-03-15 17:02:07 INFO: Loading: tokenize\n",
      "2021-03-15 17:02:07 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from wordnet import *\n",
    "from copy import deepcopy\n",
    "from Udep2Mono.util import det_mark, det_type\n",
    "from Udep2Mono.util import btree2list\n",
    "from Udep2Mono.dependency_parse import tokenizer\n",
    "from Udep2Mono.dependency_parse import dependency_parse\n",
    "from Udep2Mono.binarization import BinaryDependencyTree\n",
    "from Udep2Mono.polarization import PolarizationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "sentenceTransformer = SentenceTransformer(\"roberta-base-nli-stsb-mean-tokens\")\n",
    "\n",
    "def inference_sts(seq1s, seq2s, dist=False):\n",
    "    embeddings1 = sentenceTransformer.encode(seq1s, convert_to_tensor=True)\n",
    "    embeddings2 = sentenceTransformer.encode(seq2s, convert_to_tensor=True)\n",
    "    cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    distance = torch.dist(embeddings1, embeddings2)\n",
    "    if dist:\n",
    "        return distance\n",
    "    return cosine_scores[0][0]"
   ]
  },
  {
   "source": [
    "## 4. Phrasal Monotonicity Inference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import pluralize, singularize\n",
    "from copy import copy\n",
    "import re\n",
    "import torch\n",
    "\n",
    "class PhrasalGenerator:\n",
    "    def __init__(self):\n",
    "        self.deptree = None\n",
    "        self.annotated = None\n",
    "        self.original = None\n",
    "        self.kb = {}\n",
    "        self.hypothesis = \"\"\n",
    "        self.tree_log = []\n",
    "        self.sent_log = []\n",
    "        self.stop_critarion = False\n",
    "        self.mod_at_left = [\n",
    "            \"advmod\", \"amod\", \"advmod:count\", \n",
    "            \"acl:relcl\", \"obl\", 'obl:npmod', \"det\",\n",
    "            \"obl:tmod\", \"nmod\", \"nmod:npmod\", \n",
    "            \"nmod:poss\", \"nmod:tmod\", \"obl:npmod\",\n",
    "            \"acl\", \"advcl\", \"xcomp\", \"ccomp\", \n",
    "            'compound:ptr']\n",
    "        self.mod_at_right = [\"obj\", \"appos\"]\n",
    "        self.mod_symmetric = [\"conj\", \"compound\"]\n",
    "        self.mod_special = [\"nsubj\"]\n",
    "        self.implicative = {\n",
    "            \"watching\": 1\n",
    "        }\n",
    "        \n",
    "        '''  \n",
    "            \"cop\": self.generate_inherite, \n",
    "            \"expl\": self.generate_expl,\n",
    "            \"nummod\": self.generate_nummod,\n",
    "        '''\n",
    "\n",
    "    def deptree_generate(self, tree, annotated, original):\n",
    "        self.stop_critarion = False\n",
    "        self.tree_log = []\n",
    "        self.sent_log = []\n",
    "        self.deptree = tree.copy()\n",
    "        self.original = original  \n",
    "        self.annotated = deepcopy(annotated)\n",
    "        self.sentence = original\n",
    "        self.generate(self.deptree)\n",
    "\n",
    "    def generate(self, tree):\n",
    "        if self.stop_critarion:\n",
    "            return\n",
    "        if not tree.is_tree:\n",
    "            self.generate_default(tree)\n",
    "        else:\n",
    "            generation = self.get_generation_type(tree)\n",
    "            #print(generation, tree.val)\n",
    "            generation(tree)\n",
    "\n",
    "    def get_generation_type(self, tree):\n",
    "        if tree.val in self.mod_special:\n",
    "            return self.generate_special\n",
    "\n",
    "        disjunction = False\n",
    "        if tree.val == \"conj\":\n",
    "            disjunction |= self.search_dependency('or', tree.left)\n",
    "            disjunction |= self.search_dependency('and', tree.left)\n",
    "        \n",
    "        left_mod = tree.left.mark == \"+\"\n",
    "        left_mod = left_mod or tree.left.mark == \"=\" or disjunction\n",
    "        left_mod = left_mod and tree.val in self.mod_at_left\n",
    "\n",
    "        right_mod = tree.right.mark == \"+\" or tree.right.mark == \"=\" or disjunction \n",
    "        right_mod = right_mod and tree.val in self.mod_at_right\n",
    "\n",
    "        sym_mod = tree.val in self.mod_symmetric and tree.left.mark == \"+\" and tree.right.mark == \"+\"\n",
    "\n",
    "        if left_mod:\n",
    "            return self.left_modifier_generate\n",
    "        elif right_mod:\n",
    "            return self.right_modifier_generate\n",
    "        elif sym_mod:\n",
    "            return self.symmetric_generate\n",
    "        else:\n",
    "            return self.generate_default\n",
    "\n",
    "    def generate_special(self, tree):\n",
    "        if tree.val == \"nsubj\":\n",
    "            if tree.left.val == \"who\" and tree.right.val == \"aux\":\n",
    "                self.left_modifier_generate(tree)\n",
    "\n",
    "        self.generate(tree.left)\n",
    "        self.generate(tree.right)\n",
    "\n",
    "    def delete_cc(self, tree):\n",
    "        if tree.val == \"cc\" and tree.left.val != \"but\":\n",
    "            self.delete_modifier(tree, tree.right)\n",
    "\n",
    "        if tree.is_tree:\n",
    "            self.delete_cc(tree.left)\n",
    "            self.delete_cc(tree.right)\n",
    "\n",
    "    def delete_modifier(self, tree, modifier):\n",
    "        tree.val = modifier.val\n",
    "        tree.mark = modifier.mark\n",
    "        tree.pos = modifier.pos\n",
    "        tree.id = modifier.id\n",
    "        \n",
    "        tree.is_tree = modifier.is_tree\n",
    "        tree.is_root = modifier.is_root\n",
    "\n",
    "        tree.left = modifier.left\n",
    "        tree.right = modifier.right\n",
    "\n",
    "        self.delete_cc(tree)\n",
    "        self.save_tree()\n",
    "\n",
    "    def delete_left_modifier(self, tree):\n",
    "        #print(\"Delet: \", tree.left.val)\n",
    "        self.delete_modifier(tree, tree.right)\n",
    "\n",
    "    def delete_right_modifier(self, tree):\n",
    "        #print(\"Delet: \", tree.right.val)\n",
    "        self.delete_modifier(tree, tree.left)\n",
    "\n",
    "    def rollback(self, tree, backup):\n",
    "        tree.val = backup.val\n",
    "        tree.left = deepcopy(backup.left)\n",
    "        tree.right = deepcopy(backup.right)\n",
    "        tree.mark = backup.mark\n",
    "        tree.pos = backup.pos\n",
    "        tree.id = backup.id\n",
    "        tree.is_tree = backup.is_tree\n",
    "        tree.is_root = backup.is_root\n",
    "\n",
    "    def symmetric_generate(self, tree):\n",
    "        self.right_modifier_generate(tree)\n",
    "        self.left_modifier_generate(tree)\n",
    "        #self.delete_cc(tree)\n",
    "\n",
    "    def right_modifier_generate(self, tree):\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "        backup = deepcopy(tree)\n",
    "\n",
    "        self.delete_right_modifier(tree)\n",
    "        self.save_tree()\n",
    "        self.rollback(tree, backup)    \n",
    "        \n",
    "        self.generate(tree.left)\n",
    "        self.generate(tree.right)\n",
    "\n",
    "    def left_modifier_generate(self, tree):\n",
    "        left = tree.left\n",
    "        right = tree.right\n",
    "        backup = deepcopy(tree)\n",
    "\n",
    "        self.delete_left_modifier(tree)\n",
    "        self.save_tree()\n",
    "        self.rollback(tree, backup)   \n",
    "\n",
    "        self.generate(tree.left)\n",
    "        self.generate(tree.right)\n",
    "    \n",
    "    def return_last_leaf(self, tree):\n",
    "        max_id = 0\n",
    "        max_id_l = 0\n",
    "        max_id_r = 0\n",
    "\n",
    "        if tree.id != None:\n",
    "            max_id = int(tree.id)\n",
    "    \n",
    "        if tree.left.is_tree:\n",
    "            max_id_l = self.return_last_leaf(tree.left)\n",
    "        else:\n",
    "            max_id_l = tree.left.id\n",
    "\n",
    "        if tree.right.is_tree:\n",
    "            max_id_r = self.return_last_leaf(tree.right)\n",
    "        else:\n",
    "            max_id_r = tree.right.id\n",
    "\n",
    "        return max(max_id, max(max_id_l, max_id_r))\n",
    "\n",
    "    def return_first_leaf(self, tree):\n",
    "        min_id = 100\n",
    "        min_id_l = 100\n",
    "        min_id_r = 100\n",
    "\n",
    "        if tree.id != None:\n",
    "            min_id = int(tree.id)\n",
    "    \n",
    "        if tree.left.is_tree:\n",
    "            min_id_l = self.return_last_leaf(tree.left)\n",
    "        else:\n",
    "            min_id_l = tree.left.id\n",
    "\n",
    "        if tree.right.is_tree:\n",
    "            min_id_r = self.return_last_leaf(tree.right)\n",
    "        else:\n",
    "            min_id_r = tree.right.id\n",
    "\n",
    "        return min(min_id, min(min_id_l, min_id_r))\n",
    "\n",
    "    def add_modifier_sent(self, tree, modifier, direct=0): \n",
    "        sentence = deepcopy(self.sentence)\n",
    "        if direct == 0:\n",
    "            last_leaf = self.return_first_leaf(tree)\n",
    "            sentence.insert(last_leaf-1, modifier)\n",
    "        elif direct == 1:\n",
    "            last_leaf = self.return_last_leaf(tree)\n",
    "            sentence.insert(last_leaf, modifier)        \n",
    "\n",
    "        self.remove_adjcent_duplicate(sentence)\n",
    "        sentence = ' '.join(sentence)\n",
    "        sentence = sentence.replace(\"-\", \" \")\n",
    "        sentence = sentence.replace(\" 's\", \"'s\")\n",
    "\n",
    "        if abs(len(sentence) - len(self.hypothesis)) < 15:\n",
    "            re.sub(r'((\\b\\w+\\b.{1,2}\\w+\\b)+).+\\1', r'\\1', sentence, flags = re.I)\n",
    "            sentence = sentence.strip() \n",
    "            \n",
    "            if sentence.lower() == self.hypothesis.lower():\n",
    "                self.stop_critarion = True\n",
    "                self.sent_log.append((sentence, 1.0))\n",
    "                return\n",
    "                \n",
    "            similarity = inference_sts([sentence], [self.hypothesis])\n",
    "            if similarity > 0.90:\n",
    "                self.sent_log.append((sentence, similarity))\n",
    "            if similarity > 0.97:\n",
    "                self.sent_log.append((sentence, similarity))\n",
    "                self.stop_critarion = True\n",
    "\n",
    "    def add_modifier_lexical(self, tree, modifier, head, word_id, direct=0):\n",
    "        if direct == 0:\n",
    "            generated = ' '. join([modifier, head])\n",
    "        else:\n",
    "            generated = ' '. join([head, modifier])\n",
    "        \n",
    "        sentence = deepcopy(self.sentence)\n",
    "        diff = 0\n",
    "        if word_id > len(sentence):\n",
    "            diff = word_id - len(sentence)\n",
    "\n",
    "        goal = word_id-1-diff\n",
    "        sentence[goal] = \"DEL\"\n",
    "        sentence[goal:goal] = generated.split(' ')\n",
    "\n",
    "        if abs(len(sentence) - len(self.hypothesis.split(' '))) < 7:\n",
    "            self.remove_adjcent_duplicate(sentence)\n",
    "            sentence = ' '.join(sentence)\n",
    "            sentence = sentence.replace(\"DEL \", \"\")\n",
    "            sentence = sentence.replace(\"DEL\", \"\")\n",
    "            sentence = sentence.replace(\"-\", \" \")\n",
    "            sentence = sentence.replace(\" 's\", \"'s\")\n",
    "            re.sub(r'((\\b\\w+\\b.{1,2}\\w+\\b)+).+\\1', r'\\1', sentence, flags = re.I)\n",
    "            sentence = sentence.strip()\n",
    "\n",
    "            if sentence.lower() == self.hypothesis.lower():\n",
    "                self.stop_critarion = True\n",
    "                self.sent_log.append((sentence, 1.0))\n",
    "                return\n",
    "            \n",
    "            similarity = inference_sts([sentence], [self.hypothesis])\n",
    "            if similarity > 0.9:\n",
    "                self.sent_log.append((sentence, similarity))\n",
    "            if similarity > 0.97:\n",
    "                self.sent_log.append((sentence, similarity))\n",
    "                self.stop_critarion = True\n",
    "\n",
    "    def generate_default(self, tree):\n",
    "        VP_rel = {\n",
    "            \"aux\":1, \n",
    "            \"obj\":1, \n",
    "            \"obl\":1, \n",
    "            \"xcomp\":1, \n",
    "            \"ccomp\":1,\n",
    "            \"aux:pass\":1, \n",
    "            \"obl:tmod\":1, \n",
    "            \"obl:npmod\":1\n",
    "        }\n",
    "\n",
    "        VP_mod = {\n",
    "            \"advcl\":1, \n",
    "            \"xcomp\":1, \n",
    "            \"ccomp\":1,\n",
    "            \"obj\":1, \n",
    "            \"advmod\":1, \n",
    "            \"obl\":1, \n",
    "            \"obl:tmod\":1,\n",
    "            \"obl:nmod\":1, \n",
    "            \"parataxis\":1, \n",
    "            \"conj\":1\n",
    "        }\n",
    "\n",
    "        NP_rel = {\n",
    "            \"amod\":1,\n",
    "            \"compound\":1,\n",
    "            \"det\":1,\n",
    "            \"mark\":1,\n",
    "            \"nmod:poss\":1,\n",
    "            \"flat\":1,\n",
    "            \"acl:relcl\":1,\n",
    "            \"acl\":1,\n",
    "            \"nmod\":1\n",
    "        }\n",
    "\n",
    "        NP_mod = {\n",
    "            \"amod\":1,\n",
    "            \"compound\":1,\n",
    "            \"det\":1,\n",
    "            \"mark\":1,\n",
    "            \"nmod:poss\":1,\n",
    "            \"flat\":1,\n",
    "        }\n",
    "\n",
    "        if tree.pos is not None:\n",
    "            if (\"NN\" in tree.pos or \"JJ\" in tree.pos) and tree.mark == \"-\":\n",
    "                for rel in [\"amod\", \"compound\", \"det\", \"mark\", \"nmod:poss\", \"flat\", \"conj\", \"nummod\"]:\n",
    "                    if rel in self.kb:\n",
    "                        for phrase in self.kb[rel]:\n",
    "                            if phrase['head'] == tree.val:\n",
    "                                self.add_modifier_lexical(tree, phrase['mod'], tree.val, tree.id)\n",
    "                for rel in [\"amod\", \"acl:relcl\", \"compound\", \"acl\", \"nmod\"]:\n",
    "                    if rel in self.kb:\n",
    "                        for phrase in self.kb[rel]:\n",
    "                            if phrase['head'] == tree.val:\n",
    "                                self.add_modifier_lexical(tree, phrase['mod'], tree.val, tree.id, 1)\n",
    "                \n",
    "            elif \"VB\" in tree.pos and tree.mark == \"-\":\n",
    "                for rel in [\"advmod\"]:\n",
    "                    if rel in self.kb:\n",
    "                        for phrase in self.kb[rel]:\n",
    "                            self.add_modifier_lexical(tree, phrase['mod'], tree.val, tree.id)\n",
    "                            self.add_modifier_lexical(tree, phrase['mod'], tree.val, tree.id, 1)\n",
    "\n",
    "        elif VP_rel.get(tree.val, 0) and tree.mark == \"-\":\n",
    "            for rel in VP_mod:\n",
    "                if rel in self.kb:\n",
    "                    for phrase in self.kb[rel]:\n",
    "                        self.add_modifier_sent(tree, phrase['mod'], direct=1)\n",
    "\n",
    "        elif NP_rel.get(tree.val, 0) and tree.mark == \"-\":\n",
    "            for rel in NP_mod:\n",
    "                if rel in self.kb:\n",
    "                    for phrase in self.kb[rel]:\n",
    "                        self.add_modifier_sent(tree, phrase['mod'], direct=0)\n",
    "\n",
    "        elif VP_rel.get(tree.val, 0) and self.implicative.get(tree.right.val):\n",
    "            self.save_tree(tree=tree.left)\n",
    "        if tree.is_tree:\n",
    "            self.generate(tree.left)\n",
    "            self.generate(tree.right)  \n",
    "\n",
    "    def save_tree(self, tree=None):\n",
    "        if tree is None:\n",
    "            leaves = self.deptree.sorted_leaves().popkeys()\n",
    "            tree_copy = self.deptree.copy()\n",
    "        else:\n",
    "            leaves = tree.sorted_leaves().popkeys()\n",
    "            tree_copy = tree.copy()\n",
    "        \n",
    "        sentence = ' '.join([x[0] for x in leaves])\n",
    "        sentence = sentence.replace(\"-\", \" \")\n",
    "        if sentence.lower() == self.hypothesis.lower():\n",
    "            self.tree_log = []\n",
    "            self.stop_critarion = True\n",
    "            self.tree_log.append((tree_copy, sentence, 1.0))\n",
    "            return\n",
    "        \n",
    "        similarity = inference_sts([sentence], [self.hypothesis])\n",
    "        #print(sentence, similarity)\n",
    "        if similarity > 0.8:\n",
    "            self.tree_log.append((tree_copy, sentence, similarity))\n",
    "        if similarity > 0.97:\n",
    "            self.tree_log = []\n",
    "            self.tree_log.append((tree_copy, sentence, similarity))\n",
    "            self.stop_critarion = True\n",
    "    \n",
    "    def remove_adjcent_duplicate(self, string):\n",
    "        to_remove = -1\n",
    "        for i in range(len(string)-1):\n",
    "            if string[i] == string[i+1]:\n",
    "                to_remove = i\n",
    "        if to_remove > -1:\n",
    "            del string[to_remove]\n",
    "\n",
    "    def search_dependency(self, deprel, tree):\n",
    "        if tree.val == deprel:\n",
    "            return True\n",
    "        else:\n",
    "            right = tree.right\n",
    "            left = tree.left\n",
    "\n",
    "            left_found = False\n",
    "            right_found = False\n",
    "\n",
    "            if right is not None:\n",
    "                right_found = self.search_dependency(deprel, right)\n",
    "\n",
    "            if left is not None:\n",
    "                left_found = self.search_dependency(deprel, left)\n",
    "\n",
    "            return left_found or right_found\n",
    "    \n",
    "    def Diff(self, li1, li2):\n",
    "        return (list(list(set(li1)-set(li2)) + list(set(li2)-set(li1))))    \n",
    "    \n",
    "    def preprocess(self, sentence):\n",
    "        preprocessed = sentence.replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\")\n",
    "        preprocessed = preprocessed.replace(\"can't\", \"can not\")\n",
    "        preprocessed = preprocessed.replace(\"couldn't\", \"could not\")\n",
    "        preprocessed = preprocessed.replace(\"don't\", \"do not\")\n",
    "        preprocessed = preprocessed.replace(\"doesn't\", \"does not\")\n",
    "        preprocessed = preprocessed.replace(\"isn't\", \"is not\")\n",
    "        preprocessed = preprocessed.replace(\"won't\", \"will not\")\n",
    "        preprocessed = preprocessed.replace(\"wasn't\", \"was not\")\n",
    "        preprocessed = preprocessed.replace(\"weren't\", \"were not\")\n",
    "        preprocessed = preprocessed.replace(\"didn't\", \"did not\")\n",
    "        preprocessed = preprocessed.replace(\"aren't\", \"are not\")\n",
    "        preprocessed = preprocessed.replace(\"it's\", \"it is\")\n",
    "        preprocessed = preprocessed.replace(\"wouldn't\", \"would not\")\n",
    "        preprocessed = preprocessed.replace(\"There's\", \"There is\")\n",
    "        return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifier_relation = {\n",
    "    \"NN\": [\"amod\", \"nmod\", \"acl:relcl\", \"fixed\", \"compound\", \"det\", \"nmod:poss\", \"conj\", \"nummod\"],\n",
    "    \"VB\": [\"advmod\", \"acl\", \"obl\", \"xcomp\", \"advcl\", \"obl:tmod\", \"parataxis\", \"obj\",\"ccomp\"]\n",
    "}\n",
    "\n",
    "def down_right(tree):\n",
    "    if(tree.right == None):\n",
    "        return tree\n",
    "    return down_right(tree.right)\n",
    "\n",
    "def down_left(tree):\n",
    "    if(tree.left == None):\n",
    "        return tree\n",
    "    return down_left(tree.left)\n",
    "\n",
    "def collect_modifiers(tree, sent_set, mod_type=\"NN\"):\n",
    "    leaves = []\n",
    "    if tree.is_tree:\n",
    "        if tree.val in [\"mark\", \"case\", \"compound\", \"flat\", \"nmod\"]:\n",
    "            leaves.append(\n",
    "                (list(tree.right.sorted_leaves().popkeys()),\n",
    "                down_right(tree.left).val)\n",
    "            )\n",
    "        if tree.val in modifier_relation[mod_type]:\n",
    "            leaves.append(\n",
    "                (list(tree.left.sorted_leaves().popkeys()),\n",
    "                down_right(tree.right).val)\n",
    "            )\n",
    "\n",
    "        for leave in leaves:\n",
    "            if len(leave) > 0 and len(leave) < 10:\n",
    "                head = leave[1]\n",
    "                modifier = ' '.join([x[0] for x in leave[0]])\n",
    "                if tree.val in sent_set:\n",
    "                    sent_set[tree.val].append({'head': head,'mod': modifier})\n",
    "                else:\n",
    "                    sent_set[tree.val] = [{'head': head,'mod': modifier}]\n",
    "        \n",
    "        collect_modifiers(tree.left, sent_set, mod_type)\n",
    "        collect_modifiers(tree.right, sent_set, mod_type)"
   ]
  },
  {
   "source": [
    "## 5. Lexical Monotonicity Inference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LexicalGenerator:\n",
    "    def __init__(self):\n",
    "        self.deptree = None\n",
    "        self.hypothesis = \"\"\n",
    "        self.tree_log = []\n",
    "        self.polar_log = []\n",
    "        self.replacement_log = []\n",
    "        self.stop_critarion = False\n",
    "        self.key_tokens = [\n",
    "            'NN','NNS','NNP','NNPS','VBD',\n",
    "            'VBG','VBN','VBZ','VB']\n",
    "\n",
    "        self.propers = [\"someone\", \"something\", \"somewhere\"]\n",
    "\n",
    "        self.quantifiers = {}\n",
    "        with open('quantifier.json', 'r') as quants:\n",
    "             quantifier_data = json.load(quants)\n",
    "             for quantifier in quantifier_data:\n",
    "                 self.quantifiers[quantifier['word']] = quantifier\n",
    "\n",
    "    def deptree_generate(self, tree):\n",
    "        self.stop_critarion = False\n",
    "        self.deptree = tree\n",
    "        self.generate(self.deptree)\n",
    "\n",
    "    def generate(self, tree):\n",
    "        if tree is None or self.stop_critarion:\n",
    "            return\n",
    "        if tree.pos is not None: \n",
    "            backup = copy(tree.val)\n",
    "            if tree.pos == \"NNP\" and tree.mark == \"+\":\n",
    "                for word in self.propers:\n",
    "                    if word in self.hypothesis_tokens:\n",
    "                        tree.val = word\n",
    "                        self.save_tree()\n",
    "                        self.replacement_log.append(\n",
    "                            \"{} => {}\".format(backup, word))\n",
    "                        tree.val = backup\n",
    "\n",
    "            if tree.pos in self.key_tokens:\n",
    "                hyper, hypo, syn, ant = get_word_sets(\n",
    "                    singularize(tree.val), tree.pos.lower())\n",
    "\n",
    "                for word in self.hypothesis_tokens:\n",
    "                    if syn.get(word, 0):\n",
    "                        tree.val = word\n",
    "                        self.save_tree()\n",
    "                        self.replacement_log.append(\n",
    "                            \"{} => {}\".format(backup, word))\n",
    "                tree.val = backup\n",
    "\n",
    "                for word in self.hypothesis_tokens:\n",
    "                    if ant.get(word, 0):\n",
    "                        tree.val = word\n",
    "                        self.save_tree()\n",
    "                        self.replacement_log.append(\n",
    "                            \"{} => {}\".format(backup, word))\n",
    "                tree.val = backup\n",
    "\n",
    "                if tree.mark == \"+\":                \n",
    "                    for word in self.hypothesis_tokens:\n",
    "                        if hyper.get(word, 0):\n",
    "                            tree.val = word\n",
    "                            self.save_tree()\n",
    "                            self.replacement_log.append(\n",
    "                                \"{} => {}\".format(backup, word))\n",
    "                    tree.val = backup\n",
    "\n",
    "                if tree.mark == \"-\":\n",
    "                    for word in self.hypothesis_tokens:\n",
    "                        if hypo.get(word, 0):\n",
    "                            tree.val = word\n",
    "                            self.save_tree()\n",
    "                            self.replacement_log.append(\n",
    "                                \"{} => {}\".format(backup, word))\n",
    "                    tree.val = backup\n",
    "            \n",
    "        elif tree.val == \"det\":\n",
    "            backup = tree.left.val\n",
    "            backup_mark = tree.right.mark\n",
    "            kb = self.quantifiers[tree.left.val.lower()]\n",
    "\n",
    "            for word in kb[\"=\"]:\n",
    "                tree.left.val = word\n",
    "                detType = det_type(tree.left.val)\n",
    "                if detType is None:\n",
    "                    detType = \"det:exist\"\n",
    "                tree.left.mark = det_mark[detType]\n",
    "                self.save_tree()\n",
    "                self.replacement_log.append(\n",
    "                    \"{} => {}\".format(backup, word))\n",
    "            tree.left.val = backup\n",
    "            tree.left.mark = backup_mark\n",
    "\n",
    "            if tree.left.mark == \"+\":\n",
    "                for word in kb[\"<\"]:\n",
    "                    if word in self.hypothesis:\n",
    "                        tree.left.val = word\n",
    "                        detType = det_type(tree.left.val)\n",
    "                        if detType is None:\n",
    "                            detType = \"det:exist\"\n",
    "                        tree.left.mark = det_mark[detType]\n",
    "                        self.save_tree()\n",
    "                        self.replacement_log.append(\n",
    "                            \"{} => {}\".format(backup, word))\n",
    "                tree.left.val = backup\n",
    "                tree.left.mark = backup_mark\n",
    "            \n",
    "            if tree.left.mark == \"-\":\n",
    "                for word in kb[\">\"]:\n",
    "                    if word in self.hypothesis:\n",
    "                        tree.val = word\n",
    "                        if detType is None:\n",
    "                            detType = \"det:exist\"\n",
    "                        tree.left.mark = det_mark[detType]\n",
    "                        self.save_tree()\n",
    "                        self.replacement_log.append(\n",
    "                            \"{} => {}\".format(backup, word))\n",
    "                tree.left.val = backup\n",
    "                tree.left.mark = backup_mark\n",
    "        \n",
    "        if tree.left != \"N\":\n",
    "            self.generate(tree.left)\n",
    "        if tree.right != \"N\":\n",
    "            self.generate(tree.right)\n",
    "\n",
    "    def save_tree(self):\n",
    "        leaves = self.deptree.sorted_leaves().popkeys()\n",
    "        tree_copy = self.deptree.copy()\n",
    "     \n",
    "        sentence = ' '.join([x[0] for x in leaves])\n",
    "        if sentence.lower() == self.hypothesis.lower():\n",
    "            self.tree_log = []\n",
    "            self.stop_critarion = True\n",
    "            self.tree_log.append((tree_copy, sentence, 1.0))\n",
    "            return\n",
    "        \n",
    "        similarity = inference_sts([sentence], [self.hypothesis])\n",
    "        if similarity > 0.8:\n",
    "            self.tree_log.append((tree_copy, sentence, similarity))\n",
    "        if similarity > 0.97:\n",
    "            self.tree_log = []\n",
    "            self.tree_log.append((tree_copy, sentence, similarity))\n",
    "            self.stop_critarion = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "====================================\n",
      "\n",
      "Init Premise: A man is talking\n",
      "\n",
      "Hypothesis: A man is speaking\n",
      "http://api.conceptnet.io/query?start=/c/en/man&rel=/r/IsA&limit=500\n",
      "http://api.conceptnet.io/query?start=/c/en/is&rel=/r/IsA&limit=500\n",
      "http://api.conceptnet.io/query?start=/c/en/talking&rel=/r/IsA&limit=500\n",
      "('A some man is talking', tensor(0.8719))\n",
      "('an man is talking', tensor(0.8943))\n",
      "('one man is talking', tensor(0.8349))\n",
      "('A man is talking', tensor(0.8894))\n",
      "('A man is talking', tensor(0.8894))\n",
      "False\n",
      "\n",
      "====================================\n",
      "\n",
      "Init Premise: A cheetah is chasing its prey across a field\n",
      "\n",
      "Hypothesis: A cheetah is quickly running behind its prey\n",
      "http://api.conceptnet.io/query?start=/c/en/cheetah&rel=/r/IsA&limit=500\n",
      "http://api.conceptnet.io/query?start=/c/en/is&rel=/r/IsA&limit=500\n",
      "http://api.conceptnet.io/query?start=/c/en/field&rel=/r/IsA&limit=500\n",
      "http://api.conceptnet.io/query?start=/c/en/prey&rel=/r/IsA&limit=500\n",
      "http://api.conceptnet.io/query?start=/c/en/chasing&rel=/r/IsA&limit=500\n",
      "('A some man is talking', tensor(0.8719))\n",
      "('an man is talking', tensor(0.8943))\n",
      "('one man is talking', tensor(0.8349))\n",
      "('A man is talking', tensor(0.8894))\n",
      "('A man is talking', tensor(0.8894))\n",
      "('A some cheetah is chasing its prey across a field', tensor(0.8931))\n",
      "('an cheetah is chasing its prey across a field', tensor(0.8971))\n",
      "('one cheetah is chasing its prey across a field', tensor(0.8814))\n",
      "('A cheetah is chasing its prey across a field', tensor(0.8958))\n",
      "('A cheetah is chasing its prey across some field', tensor(0.8902))\n",
      "('A cheetah is chasing its prey across an field', tensor(0.8933))\n",
      "('A cheetah is chasing its prey across one field', tensor(0.8896))\n",
      "('A cheetah is chasing its prey across a field', tensor(0.8958))\n",
      "False\n",
      "\n",
      "====================================\n",
      "\n",
      "Init Premise: A boy is playing\n",
      "\n",
      "Hypothesis: A child is playing\n",
      "http://api.conceptnet.io/query?start=/c/en/boy&rel=/r/IsA&limit=500\n",
      "('A child is playing', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"A man is talking\", \n",
    "             \"A cheetah is chasing its prey across a field\", \n",
    "             \"A boy is playing\"]\n",
    "hypotheses = [\"A man is speaking\",\n",
    "              \"A cheetah is quickly running behind its prey\",\n",
    "              \"A child is playing\"]\n",
    "\n",
    "pipeline = PolarizationPipeline(verbose=0)\n",
    "lexicalGenerator = LexicalGenerator()\n",
    "phrasalGenerator = PhrasalGenerator()\n",
    "for premise, hypothesis in zip(sentences, hypotheses):\n",
    "    premise = phrasalGenerator.preprocess(premise)\n",
    "    hypothesis = phrasalGenerator.preprocess(hypothesis)\n",
    "\n",
    "    print(\"\\n====================================\")\n",
    "    print(\"\\nInit Premise: \" + premise)\n",
    "    print(\"\\nHypothesis: \" + hypothesis)\n",
    "\n",
    "    tokenized = tokenizer(hypothesis).sentences[0].words\n",
    "    tokens = [tok.text for tok in tokenized]\n",
    "    lexicalGenerator.hypothesis_tokens = tokens\n",
    "\n",
    "    annotation = pipeline.single_polarization(premise)\n",
    "\n",
    "    lexicalGenerator.hypothesis = hypothesis\n",
    "    lexicalGenerator.deptree_generate(annotation['polarized_tree'])\n",
    "    \n",
    "    for gen_tree in lexicalGenerator.tree_log:\n",
    "        print((gen_tree[1], gen_tree[2]))\n",
    "    \n",
    "    print(lexicalGenerator.stop_critarion)"
   ]
  },
  {
   "source": [
    "## 6. Syntactic Variational Inference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunker import Chunker\n",
    "\n",
    "class SyntacticVariator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chunker = Chunker()\n",
    "        self.paraphraseTokenizer = paraphraseTokenizer\n",
    "        self.paraphraseModel = paraphraseModel\n",
    "\n",
    "    def chunking(self, tree):\n",
    "        return self.chunker.get_chunks_byDepTree(tree)\n",
    "\n",
    "    def build_pairs(self, chunks1, chunks2):\n",
    "        chunk_pairs = []\n",
    "        for chunk1 in chunks1:\n",
    "            for chunk2 in chunks2:\n",
    "                if len(set(chunk1.split(' ')).intersection(chunk2.split(' '))) > 0:\n",
    "                     chunk_pairs.append((chunk1, chunk2))\n",
    "\n",
    "        return chunk_pairs\n",
    "\n",
    "    def inference_mrpc(self, seq1, seq2):\n",
    "        paraphrase = paraphraseTokenizer.encode_plus(\n",
    "            seq1, seq2, return_tensors=\"pt\")\n",
    "        logits = paraphraseModel(**paraphrase)[0]\n",
    "        paraphrase_results = torch.softmax(logits, dim=1).tolist()[0]\n",
    "        return paraphrase_results[1]\n",
    "\n",
    "    def phrase_alignment(self, chunk_pairs):\n",
    "        alignments = []\n",
    "        for pair in chunk_pairs:\n",
    "            score = self.inference_mrpc(pair[0], pair[1])\n",
    "            print(pair, score)\n",
    "            if score > 0.80:\n",
    "                alignments.append(pair)\n",
    "\n",
    "        return alignments\n",
    "\n",
    "    def variate(self, P, H, p_tree, h_tree, sent=False):\n",
    "        p_chunks = self.chunking(p_tree)\n",
    "        h_chunks = self.chunking(h_tree)\n",
    "\n",
    "        if sent:\n",
    "            p_chunks.append(P)\n",
    "            h_chunks.append(H)\n",
    "\n",
    "        chunk_pairs = self.build_pairs(p_chunks, h_chunks)\n",
    "        alignments = self.phrase_alignment(chunk_pairs)\n",
    "\n",
    "        #print(*p_chunks, sep=\"\\n\")\n",
    "        #print(*h_chunks, sep=\"\\n\")\n",
    "\n",
    "        variates = set()\n",
    "        for align in alignments:\n",
    "            var_sentence = P.replace(align[0], align[1])\n",
    "            variates.add(var_sentence)\n",
    "\n",
    "        return variates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('are hanging on a large branch', 'a tree') 0.025378137826919556\n('are hanging on a large branch', 'are climing') 0.042720355093479156\n('are hanging on a large branch', 'are climing a tree') 0.32222479581832886\n('on a large branch', 'a tree') 0.06026909127831459\n('on a large branch', 'are climing a tree') 0.06066717207431793\n('Two children', 'Two children') 0.9947488903999329\nTwo children are hanging on a large branch tensor(0.7072)\n"
     ]
    }
   ],
   "source": [
    "premise = \"Two children are hanging on a large branch\"\n",
    "hypothesis = \"Two children are climing a tree\"\n",
    "\n",
    "pipeline = PolarizationPipeline()\n",
    "syntacticVariator = SyntacticVariator()\n",
    "\n",
    "h_parsed, replaced = dependency_parse(hypothesis, parser=\"stanza\")\n",
    "h_tree, _ = pipeline.run_binarization(h_parsed, hypothesis, {})\n",
    "pipeline.modify_replacement(h_tree, replaced)\n",
    "annotation = pipeline.single_polarization(premise)\n",
    "\n",
    "variates = syntacticVariator.variate(premise, hypothesis, annotation['polarized_tree'],  h_tree, sent=False)\n",
    "for v in variates:\n",
    "    similarity = inference_sts([v], [hypothesis])\n",
    "    print(v, similarity)"
   ]
  },
  {
   "source": [
    "## 7. A* Inference Search Engine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pqdict import pqdict\n",
    "\n",
    "class AStarPlanner:\n",
    "    def __init__(self):    \n",
    "        self.closed = []                  \n",
    "        self.entailments = set()\n",
    "        self.contradictions = set()\n",
    "        self.hypothesis = \"\"\n",
    "        self.h_tree = None\n",
    "\n",
    "        self.pipeline = PolarizationPipeline()\n",
    "        self.phrasalGenerator = PhrasalGenerator()\n",
    "        self.lexicalGenerator = LexicalGenerator()\n",
    "        self.syntacticVariator = SyntacticVariator() \n",
    "\n",
    "    def hypothesis_kb(self):\n",
    "        self.hypothesis = self.phrasalGenerator.preprocess(self.hypothesis)\n",
    "        h_parsed, replaced = dependency_parse(self.hypothesis, parser=\"stanza\")\n",
    "        h_tree, _ = self.pipeline.run_binarization(h_parsed, self.hypothesis, {})\n",
    "        self.pipeline.modify_replacement(h_tree, replaced)\n",
    "        phrases = {} \n",
    "        collect_modifiers(h_tree, phrases, mod_type=\"NN\")\n",
    "        collect_modifiers(h_tree, phrases, mod_type=\"VB\")\n",
    "        self.phrasalGenerator.kb = phrases\n",
    "        self.h_tree = h_tree\n",
    "\n",
    "    def generate_premises(self, start):\n",
    "        self.entailments.clear()\n",
    "        self.contradictions.clear()\n",
    "\n",
    "        start = self.phrasalGenerator.preprocess(start)\n",
    "        annotation = self.pipeline.single_polarization(start)\n",
    "        self.phrasalGenerator.hypothesis = self.hypothesis.replace(',', '')\n",
    "\n",
    "        tokenized = tokenizer(start).sentences[0].words\n",
    "        tokens = [tok.text for tok in tokenized]\n",
    "\n",
    "        self.phrasalGenerator.deptree_generate(\n",
    "        annotation['polarized_tree'], \n",
    "        annotation['annotated'], tokens)\n",
    "        \n",
    "        #print(start)\n",
    "        #print(*self.phrasalGenerator.sent_log, sep='\\n')\n",
    "        print(\"============================\")\n",
    "        #print(self.hop)\n",
    "        \n",
    "        #print(self.phrasalGenerator.sent_log)\n",
    "        \n",
    "        if self.phrasalGenerator.stop_critarion:\n",
    "            return True\n",
    "\n",
    "        for tree in self.phrasalGenerator.tree_log:\n",
    "            self.entailments.add((tree[1], tree[2]))\n",
    "        self.entailments |= set(self.phrasalGenerator.sent_log)\n",
    "\n",
    "        #print(*self.entailments, sep=\"\\n\")\n",
    "        sent_level = False\n",
    "        if self.current_optimal > 0.93 :\n",
    "            sent_level = True\n",
    "        variates = self.syntacticVariator.variate(\n",
    "            start, \n",
    "            self.hypothesis, \n",
    "            annotation['polarized_tree'], \n",
    "            self.h_tree, sent_level)\n",
    "        for v in variates:\n",
    "            similarity = inference_sts([v], [self.hypothesis])\n",
    "            if similarity > 0.98:\n",
    "                return True\n",
    "            elif similarity > 0.9:\n",
    "                self.entailments.add((v, similarity))\n",
    "\n",
    "        #self.lexicalGenerator.generate(annotation['annotated'])\n",
    "        #for gen_sent in self.lexicalGenerator.sent_log:\n",
    "        #    self.entailments.add(gen_sent)\n",
    "        #toc = time.perf_counter()\n",
    "        #print(f\"Lexical Generate 1 Premise: {toc - tic:0.4f} seconds\")\n",
    "\n",
    "        return False\n",
    "\n",
    "    def generate(self, start, opened):\n",
    "        terminate = self.generate_premises(start)\n",
    "        if terminate:\n",
    "            return True\n",
    "\n",
    "        for premise in self.entailments:\n",
    "            if premise in self.closed:\n",
    "                continue\n",
    "            cost = premise[1]\n",
    "            if premise[0] not in opened:\n",
    "                opened[premise[0]] = cost\n",
    "            if cost < opened[premise[0]]:\n",
    "                opened[premise[0]] = cost\n",
    "        return False\n",
    "\n",
    "    def search(self, premises, hypothesis):\n",
    "        self.closed = pqdict({})\n",
    "        self.hypothesis = hypothesis\n",
    "\n",
    "        self.hypothesis_kb()\n",
    "        self.phrasalGenerator.hypothesis = self.hypothesis\n",
    "        self.lexicalGenerator.hypothesis = self.hypothesis\n",
    "\n",
    "        open_lists = pqdict({}, reverse=True)\n",
    "        open_lists[premises] = inference_sts([premises], [hypothesis])\n",
    "\n",
    "        hop = 0\n",
    "        top_k = 2\n",
    "\n",
    "        while open_lists:\n",
    "            for _ in range(top_k):\n",
    "                if len(open_lists) > 0:\n",
    "                    optimal = open_lists.popitem()\n",
    "                    self.current_optimal = optimal[1]\n",
    "                    print(\"Optimal: \", optimal)\n",
    "                    goal_found = self.generate(optimal[0], open_lists)\n",
    "                    self.closed[optimal] = len(self.closed) + 1\n",
    "                    if goal_found:\n",
    "                        self.closed[(self.hypothesis, 1.0)] = len(self.closed) + 1\n",
    "                        return True\n",
    "                else: break   \n",
    "            hop += 1\n",
    "            if hop > 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = AStarPlanner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  ('You know that some life changing actions must be taken when grandma reacts with the sad emoji', tensor(0.9705))\n",
      "============================\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'NoneType' and 'int'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-c21e4658bd39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m entail = planner.search(\"You know that some life changing actions must be taken when grandma reacts with the sad emoji\",\n\u001b[0m\u001b[0;32m      2\u001b[0m              \"You know that some actions must be taken when grandma reacts with the sad emoji\")\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mplanner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\" =>\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentail\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-806733fd7783>\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, premises, hypothesis)\u001b[0m\n\u001b[0;32m    113\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_optimal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Optimal: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m                     \u001b[0mgoal_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen_lists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimal\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mgoal_found\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-806733fd7783>\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, start, opened)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mterminate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_premises\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mterminate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-806733fd7783>\u001b[0m in \u001b[0;36mgenerate_premises\u001b[1;34m(self, start)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_optimal\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.93\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0msent_level\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         variates = self.syntacticVariator.variate(\n\u001b[0m\u001b[0;32m     61\u001b[0m             \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-21c63b01da34>\u001b[0m in \u001b[0;36mvariate\u001b[1;34m(self, P, H, p_tree, h_tree, sent)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvariate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mp_chunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mh_chunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-21c63b01da34>\u001b[0m in \u001b[0;36mchunking\u001b[1;34m(self, tree)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mchunking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_chunks_byDepTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild_pairs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunks1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunks2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\UdepLog\\src\\chunker.py\u001b[0m in \u001b[0;36mget_chunks_byDepTree\u001b[1;34m(self, tree)\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[0mpipe1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGraphPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[0mg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmono2Graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\UdepLog\\src\\chunker.py\u001b[0m in \u001b[0;36mmake_chunks\u001b[1;34m(self, graph_or_root, results)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcont\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnexts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcontNode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnexts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcont\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m                 \u001b[0mcomp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_from_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontNode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcont\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcont_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                     \u001b[0mcont_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcont\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\UdepLog\\src\\chunker.py\u001b[0m in \u001b[0;36mchunk_from_nodes\u001b[1;34m(self, node, results)\u001b[0m\n\u001b[0;32m    403\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert_byOrder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnodeItem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtempList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert_byOrder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodeList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtempList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m         \u001b[0mcenter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert_byOrder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtempList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_nodesForChunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtempList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\UdepLog\\src\\chunker.py\u001b[0m in \u001b[0;36minsert_byOrder\u001b[1;34m(self, nodeList, totalList)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotalList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodeList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtotalList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"You know that some life changing actions must be taken when grandma reacts with the sad emoji\",\n",
    "             \"You know that some actions must be taken when grandma reacts with the sad emoji\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  ('A black and a white dog are joyfully running on the grass', tensor(0.6965))\n",
      "============================\n",
      "Optimal:  ('A black and a white dog are running on the grass', tensor(0.9178))\n",
      "============================\n",
      "Optimal:  ('A black and a white dog are running on the grass', tensor(0.9372))\n",
      "============================\n",
      "('A black and a white dog are joyfully running on the grass', tensor(0.6965)) =>\n",
      "('A black and a white dog are running on the grass', tensor(0.9178)) =>\n",
      "('A black and a white dog are running on the grass', tensor(0.9372)) =>\n",
      "('A dog, which has a black coat, and a white dog are running on the grass', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"A black and a white dog are joyfully running on the grass\", \n",
    "             \"A dog, which has a black coat, and a white dog are running on the grass\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  ('A motorcyclist with a red helmet is riding a blue motorcycle down the road', tensor(0.8065))\n",
      "============================\n",
      "Optimal:  ('A motorcyclist is riding a blue motorcycle down the road', tensor(0.8747))\n",
      "============================\n",
      "Optimal:  ('A motorcyclist is riding a motorbike down the road', tensor(0.9481))\n",
      "============================\n",
      "('A motorcyclist with a red helmet is riding a blue motorcycle down the road', tensor(0.8065)) =>\n",
      "('A motorcyclist is riding a blue motorcycle down the road', tensor(0.8747)) =>\n",
      "('A motorcyclist is riding a motorbike down the road', tensor(0.9481)) =>\n",
      "('A motorcyclist is riding a motorbike along a roadway', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"A motorcyclist with a red helmet is riding a blue motorcycle down the road\", \n",
    "             \"A motorcyclist is riding a motorbike along a roadway\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  ('A family is watching a little boy who is hitting a baseball', tensor(0.7123))\n",
      "============================\n",
      "Optimal:  ('a little boy who is hitting a baseball', tensor(0.9348))\n",
      "============================\n",
      "('A family is watching a little boy who is hitting a baseball', tensor(0.7123)) =>\n",
      "('a little boy who is hitting a baseball', tensor(0.9348)) =>\n",
      "('A child is hitting a baseball', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"A family is watching a little boy who is hitting a baseball\", \n",
    "             \"A child is hitting a baseball\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  ('A deer is jumping over a fence', tensor(0.9798))\n",
      "============================\n",
      "('A deer is jumping over a fence', tensor(0.9798)) =>\n",
      "('A deer is jumping a fence', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"A deer is jumping over a fence\", \n",
    "             \"A deer is jumping a fence\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  ('A boy is hitting a baseball', tensor(1.0000))\n",
      "============================\n",
      "('A boy is hitting a baseball', tensor(1.0000)) =>\n",
      "('A boy is hitting a baseball', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"A boy is hitting a baseball\", \n",
    "             \"A chil is hitting a baseball\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  ('A brown dog is attacking another animal in front of the tall man in pants', tensor(0.8783))\n",
      "============================\n",
      "Optimal:  ('A dog is attacking another animal in front of the tall man in pants', tensor(0.9582))\n",
      "============================\n",
      "('A brown dog is attacking another animal in front of the tall man in pants', tensor(0.8783)) =>\n",
      "('A dog is attacking another animal in front of the tall man in pants', tensor(0.9582)) =>\n",
      "('A dog is attacking another animal in front of the man in pants', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"A brown dog is attacking another animal in front of the tall man in pants\", \n",
    "             \"A dog is attacking another animal in front of the man in pants\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  ('A family is watching a little boy who is hitting a baseball', tensor(0.9915))\n",
      "============================\n",
      "('A family is watching a little boy who is hitting a baseball', tensor(0.9915)) =>\n",
      "('A family is watching a boy who is hitting a baseball', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"A family is watching a little boy who is hitting a baseball\", \n",
    "             \"A family is watching a boy who is hitting a baseball\")\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal:  (\"You can't park in front of my house on weekends.\", tensor(0.9529))\n",
      "============================\n",
      "(\"You can't park in front of my house on weekends.\", tensor(0.9529)) =>\n",
      "('You can not park in front of my large house on weekends', 1.0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "entail = planner.search(\"You can't park in front of my house on weekends.\", \n",
    "             \"You can't park in front of my large house on weekends.\")\n",
    "\n",
    "print(*planner.closed, sep=\" =>\\n\")\n",
    "print(entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}